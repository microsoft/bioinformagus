{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1728307406727
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import azure\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from openai import AzureOpenAI\n",
    "import evaluate\n",
    "import urllib.request\n",
    "import ssl\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Load configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1728217500289
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "snapshot_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "with open('config.yaml') as f:\n",
    "    d = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "AZURE_SUBSCRIPTION_ID = d['config']['AZURE_SUBSCRIPTION_ID']\n",
    "AZURE_RESOURCE_GROUP = d['config']['AZURE_RESOURCE_GROUP']\n",
    "AZURE_WORKSPACE = d['config']['AZURE_WORKSPACE']\n",
    "AZURE_DATA_NAME = d['config']['AZURE_DATA_NAME']    \n",
    "DATA_DIR = d['config']['DATA_DIR']\n",
    "CLOUD_DIR = d['config']['CLOUD_DIR']\n",
    "HF_MODEL_NAME_OR_PATH = d['config']['HF_MODEL_NAME_OR_PATH']\n",
    "IS_DEBUG = d['config']['IS_DEBUG']\n",
    "USE_LOWPRIORITY_VM = d['config']['USE_LOWPRIORITY_VM']\n",
    "\n",
    "\n",
    "rest_endpoint = d['evaluation']['rest_endpoint']\n",
    "evaluation_deployment_name = d['evaluation']['deployment_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Configure workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1728217504529
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /config.json\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient, Input\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml import load_component\n",
    "from azure.ai.ml import command\n",
    "from azure.ai.ml.entities import Data, Environment, BuildContext\n",
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml import Output\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.core.exceptions import ResourceNotFoundError, ResourceExistsError\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    ml_client = MLClient(credential, AZURE_SUBSCRIPTION_ID, AZURE_RESOURCE_GROUP, AZURE_WORKSPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Format csv to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1728217504665
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../analysis_and_tools_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1728217505572
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file created successfully.\n"
     ]
    }
   ],
   "source": [
    "#preprocess data\n",
    "\n",
    "input_string = []\n",
    "\n",
    "# Iterate through the rows of the dataframe\n",
    "for index, row in df.iterrows():\n",
    "    # 'content' is the column with the user questions\n",
    "    user_content = row['content']\n",
    "    # 'answer content' is the column with the ground truth answers\n",
    "    assistant_content = row['answer_content']\n",
    "\n",
    "    # Append only user content to the input_data\n",
    "    input_string.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "# Define the parameters for the model\n",
    "params = {\n",
    "    \"temperature\": 0.1,\n",
    "    \"max_new_tokens\": 4096, #output\n",
    "    \"do_sample\": True,\n",
    "    \"return_full_text\": False\n",
    "}\n",
    "\n",
    "# Combine input data and parameters into the final test data structure\n",
    "test_data = {\n",
    "    \"input_data\": input_string,\n",
    "    \"parameters\": params\n",
    "}\n",
    "\n",
    "# Save the JSON output to a file\n",
    "with open('test_data.json', 'w') as json_file:\n",
    "    json.dump(test_data, json_file, indent=4)\n",
    "\n",
    "print(\"JSON file created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Evaluate model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Evaulation real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1728217507300
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Define the path for saving the real request file\n",
    "test_src_dir = \"./phi3-inference-test\"\n",
    "os.makedirs(test_src_dir, exist_ok=True)\n",
    "real_data_path = os.path.join(test_src_dir, \"test_data.json\")\n",
    "\n",
    "# Save the real request data to a JSON file\n",
    "with open(real_data_path, \"w\") as f:\n",
    "    json.dump(test_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1728217508748
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Define paths and parameters\n",
    "timeout = 1000\n",
    "test_src_dir = \"./phi3-inference-test\"\n",
    "response_src_dir = \"./phi3-inference-responses\"\n",
    "batch_size = 1\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(test_src_dir, exist_ok=True)\n",
    "os.makedirs(response_src_dir, exist_ok=True)\n",
    "\n",
    "def batch_data(data, batch_size):\n",
    "    \"\"\"Split data into batches of given size.\"\"\"\n",
    "    return [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "\n",
    "\n",
    "# Create batches\n",
    "batches = batch_data(test_data[\"input_data\"], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1728217510534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1728217512559
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def submit_tasks(query, id):\n",
    "    data = {\n",
    "    \"input_data\": {\n",
    "        \"input_string\": batch,\n",
    "        \"parameters\": {\n",
    "        \"temperature\": 0.1,\n",
    "        \"max_new_tokens\": 4096\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    batch_file_path = os.path.join(test_src_dir, f\"batch_{id}.json\")\n",
    "    # Save the batch request data to a JSON file\n",
    "    with open(batch_file_path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "    body = str.encode(json.dumps(data))\n",
    "    ##print(f\"Batch request data saved to: {batch_file_path}\")\n",
    "\n",
    "\n",
    "    url = ''\n",
    "    api_key = ''\n",
    "    if not api_key:\n",
    "        raise Exception(\"A key should be provided to invoke the endpoint\")\n",
    "\n",
    "\n",
    "    headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "\n",
    "    req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "    try:\n",
    "        response = urllib.request.urlopen(req)\n",
    "\n",
    "        result = response.read()\n",
    "        result_parsed = json.loads(result)  # Convert string to dictionary\n",
    "        output = result_parsed['output']\n",
    "        \n",
    "        response_file_path = os.path.join(response_src_dir, f\"response_{id}.json\")\n",
    "        \n",
    "        # Save both input and response data\n",
    "        with open(response_file_path, \"w\") as f:\n",
    "            json.dump({\n",
    "                \"input_data\": batch,\n",
    "                \"response_data\": output  # Ensure result is JSON serializable\n",
    "            }, f, indent=4)\n",
    "        \n",
    "        ##print(f\"Result for batch {i} saved to: {response_file_path}\")\n",
    "    except urllib.error.HTTPError as error:\n",
    "        print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "        # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "        print(error.info())\n",
    "        print(error.read().decode(\"utf8\", 'ignore'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "gather": {
     "logged": 1728060903961
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch request data saved to: ./phi3-inference-test/batch_0.json\n",
      "Result for batch 0 saved to: ./phi3-inference-responses/response_0.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_1.json\n",
      "Result for batch 1 saved to: ./phi3-inference-responses/response_1.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_2.json\n",
      "Result for batch 2 saved to: ./phi3-inference-responses/response_2.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_3.json\n",
      "Result for batch 3 saved to: ./phi3-inference-responses/response_3.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_4.json\n",
      "Result for batch 4 saved to: ./phi3-inference-responses/response_4.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_5.json\n",
      "Result for batch 5 saved to: ./phi3-inference-responses/response_5.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_6.json\n",
      "Result for batch 6 saved to: ./phi3-inference-responses/response_6.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_7.json\n",
      "Result for batch 7 saved to: ./phi3-inference-responses/response_7.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_8.json\n",
      "Result for batch 8 saved to: ./phi3-inference-responses/response_8.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_9.json\n",
      "Result for batch 9 saved to: ./phi3-inference-responses/response_9.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_10.json\n",
      "Result for batch 10 saved to: ./phi3-inference-responses/response_10.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_11.json\n",
      "Result for batch 11 saved to: ./phi3-inference-responses/response_11.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_12.json\n",
      "Result for batch 12 saved to: ./phi3-inference-responses/response_12.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_13.json\n",
      "Result for batch 13 saved to: ./phi3-inference-responses/response_13.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_14.json\n",
      "Result for batch 14 saved to: ./phi3-inference-responses/response_14.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_15.json\n",
      "Result for batch 15 saved to: ./phi3-inference-responses/response_15.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_16.json\n",
      "Result for batch 16 saved to: ./phi3-inference-responses/response_16.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_17.json\n",
      "Result for batch 17 saved to: ./phi3-inference-responses/response_17.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_18.json\n",
      "Result for batch 18 saved to: ./phi3-inference-responses/response_18.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_19.json\n",
      "Result for batch 19 saved to: ./phi3-inference-responses/response_19.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_20.json\n",
      "Result for batch 20 saved to: ./phi3-inference-responses/response_20.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_21.json\n",
      "Result for batch 21 saved to: ./phi3-inference-responses/response_21.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_22.json\n",
      "Result for batch 22 saved to: ./phi3-inference-responses/response_22.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_23.json\n",
      "Result for batch 23 saved to: ./phi3-inference-responses/response_23.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_24.json\n",
      "Result for batch 24 saved to: ./phi3-inference-responses/response_24.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_25.json\n",
      "Result for batch 25 saved to: ./phi3-inference-responses/response_25.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_26.json\n",
      "Result for batch 26 saved to: ./phi3-inference-responses/response_26.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_27.json\n",
      "Result for batch 27 saved to: ./phi3-inference-responses/response_27.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_28.json\n",
      "Result for batch 28 saved to: ./phi3-inference-responses/response_28.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_29.json\n",
      "Result for batch 29 saved to: ./phi3-inference-responses/response_29.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_30.json\n",
      "Result for batch 30 saved to: ./phi3-inference-responses/response_30.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_31.json\n",
      "Result for batch 31 saved to: ./phi3-inference-responses/response_31.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_32.json\n",
      "Result for batch 32 saved to: ./phi3-inference-responses/response_32.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_33.json\n",
      "Result for batch 33 saved to: ./phi3-inference-responses/response_33.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_34.json\n",
      "Result for batch 34 saved to: ./phi3-inference-responses/response_34.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_35.json\n",
      "Result for batch 35 saved to: ./phi3-inference-responses/response_35.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_36.json\n",
      "Result for batch 36 saved to: ./phi3-inference-responses/response_36.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_37.json\n",
      "Result for batch 37 saved to: ./phi3-inference-responses/response_37.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_38.json\n",
      "Result for batch 38 saved to: ./phi3-inference-responses/response_38.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_39.json\n",
      "Result for batch 39 saved to: ./phi3-inference-responses/response_39.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_40.json\n",
      "Result for batch 40 saved to: ./phi3-inference-responses/response_40.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_41.json\n",
      "Result for batch 41 saved to: ./phi3-inference-responses/response_41.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_42.json\n",
      "Result for batch 42 saved to: ./phi3-inference-responses/response_42.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_43.json\n",
      "Result for batch 43 saved to: ./phi3-inference-responses/response_43.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_44.json\n",
      "Result for batch 44 saved to: ./phi3-inference-responses/response_44.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_45.json\n",
      "Result for batch 45 saved to: ./phi3-inference-responses/response_45.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_46.json\n",
      "Result for batch 46 saved to: ./phi3-inference-responses/response_46.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_47.json\n",
      "Result for batch 47 saved to: ./phi3-inference-responses/response_47.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_48.json\n",
      "Result for batch 48 saved to: ./phi3-inference-responses/response_48.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_49.json\n",
      "Result for batch 49 saved to: ./phi3-inference-responses/response_49.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_50.json\n",
      "Result for batch 50 saved to: ./phi3-inference-responses/response_50.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_51.json\n",
      "Result for batch 51 saved to: ./phi3-inference-responses/response_51.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_52.json\n",
      "Result for batch 52 saved to: ./phi3-inference-responses/response_52.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_53.json\n",
      "Result for batch 53 saved to: ./phi3-inference-responses/response_53.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_54.json\n",
      "Result for batch 54 saved to: ./phi3-inference-responses/response_54.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_55.json\n",
      "Result for batch 55 saved to: ./phi3-inference-responses/response_55.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_56.json\n",
      "Result for batch 56 saved to: ./phi3-inference-responses/response_56.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_57.json\n",
      "Result for batch 57 saved to: ./phi3-inference-responses/response_57.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_58.json\n",
      "Result for batch 58 saved to: ./phi3-inference-responses/response_58.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_59.json\n",
      "Result for batch 59 saved to: ./phi3-inference-responses/response_59.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_60.json\n",
      "Result for batch 60 saved to: ./phi3-inference-responses/response_60.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_61.json\n",
      "Result for batch 61 saved to: ./phi3-inference-responses/response_61.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_62.json\n",
      "Result for batch 62 saved to: ./phi3-inference-responses/response_62.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_63.json\n",
      "Result for batch 63 saved to: ./phi3-inference-responses/response_63.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_64.json\n",
      "Result for batch 64 saved to: ./phi3-inference-responses/response_64.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_65.json\n",
      "Result for batch 65 saved to: ./phi3-inference-responses/response_65.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_66.json\n",
      "Result for batch 66 saved to: ./phi3-inference-responses/response_66.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_67.json\n",
      "Result for batch 67 saved to: ./phi3-inference-responses/response_67.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_68.json\n",
      "Result for batch 68 saved to: ./phi3-inference-responses/response_68.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_69.json\n",
      "Result for batch 69 saved to: ./phi3-inference-responses/response_69.json\n",
      "Batch request data saved to: ./phi3-inference-test/batch_70.json\n",
      "Result for batch 70 saved to: ./phi3-inference-responses/response_70.json\n"
     ]
    }
   ],
   "source": [
    "## loop through batches\n",
    "for i, batch in enumerate(batches):\n",
    "    submit_tasks(batch,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "gather": {
     "logged": 1728061167864
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi Everyone. I was trying to add help section ...</td>\n",
       "      <td>To prevent the help message from being printe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am currently using BWA-MEM to map metagenomi...</td>\n",
       "      <td>BWA-MEM, like many other alignment tools, doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi all:I recently got quite confused with two ...</td>\n",
       "      <td>The SAM flags \"supplementary alignment\" and \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello, I am pretty new to bioinformatics and t...</td>\n",
       "      <td>Filtering uniquely mapped reads in bioinforma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samtools can be used to select reads above cer...</td>\n",
       "      <td>You can streamline the process by using `samt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Hi Everyone. I was trying to add help section ...   \n",
       "1  I am currently using BWA-MEM to map metagenomi...   \n",
       "2  Hi all:I recently got quite confused with two ...   \n",
       "3  Hello, I am pretty new to bioinformatics and t...   \n",
       "4  Samtools can be used to select reads above cer...   \n",
       "\n",
       "                                              Answer  \n",
       "0   To prevent the help message from being printe...  \n",
       "1   BWA-MEM, like many other alignment tools, doe...  \n",
       "2   The SAM flags \"supplementary alignment\" and \"...  \n",
       "3   Filtering uniquely mapped reads in bioinforma...  \n",
       "4   You can streamline the process by using `samt...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "file_pattern = \"./phi3-inference-responses/*.json\"\n",
    "\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for file_name in glob.glob(file_pattern): #glob lists all the text files in the current working dir.\n",
    "    with open(file_name, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "\n",
    "    if \"input_data\" in data: #retrieves list of dictionaries\n",
    "        for item in data[\"input_data\"]: #iterates over each dictionary in the list\n",
    "            if \"content\" in item:\n",
    "                questions.append(item[\"content\"])\n",
    "\n",
    "    if \"response_data\" in data:\n",
    "        response = data[\"response_data\"]\n",
    "        answers.append(response)\n",
    "\n",
    "final_df = pd.DataFrame({\"Question\": questions, \"Answer\": answers})\n",
    "\n",
    "# Save DataFrame to a CSV file (optional)\n",
    "final_df.to_csv('combined_questions_answers.csv', index=False)\n",
    "\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### ROUGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "########note: rouge captures (number of n-grams in prediction summary (fine-tuned phi-3 model) that match the reference summary (ground-truth)) / number of n-grams in reference summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "gather": {
     "logged": 1728061370310
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.127\n",
      "ROUGE-2: 0.016\n",
      "ROUGE-L: 0.073\n",
      "ROUGE-Lsum: 0.092\n"
     ]
    }
   ],
   "source": [
    "predictions = final_df[\"Answer\"].to_list()\n",
    "references = df[\"answer_content\"].to_list()\n",
    "\n",
    "rouge = evaluate.load('rouge') #https://huggingface.co/spaces/evaluate-metric/rouge\n",
    "\n",
    "\n",
    "results = rouge.compute(predictions=predictions,\n",
    "                         references=references,\n",
    "                        use_aggregator=True)\n",
    "\n",
    "print(\"ROUGE-1:\", round(results[\"rouge1\"], 3))\n",
    "print(\"ROUGE-2:\", round(results[\"rouge2\"], 3))\n",
    "print(\"ROUGE-L:\", round(results[\"rougeL\"], 3))\n",
    "print(\"ROUGE-Lsum:\", round(results[\"rougeLsum\"], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Loop 100 times for generating confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1728154705711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "Iteration 70\n",
      "Iteration 71\n",
      "Iteration 72\n",
      "Iteration 73\n",
      "Iteration 74\n",
      "Iteration 75\n",
      "Iteration 76\n",
      "Iteration 77\n",
      "Iteration 78\n",
      "Iteration 79\n",
      "Iteration 80\n",
      "Iteration 81\n",
      "Iteration 82\n",
      "Iteration 83\n",
      "Iteration 84\n",
      "Iteration 85\n",
      "Iteration 86\n",
      "Iteration 87\n",
      "Iteration 88\n",
      "Iteration 89\n",
      "Iteration 90\n",
      "Iteration 91\n",
      "Iteration 92\n",
      "Iteration 93\n",
      "Iteration 94\n",
      "Iteration 95\n",
      "Iteration 96\n",
      "Iteration 97\n",
      "Iteration 98\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "rouge_df = pd.DataFrame(columns=[\"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\", \"ROUGE-Lsum\"])\n",
    "\n",
    "for j in range(100):\n",
    "\n",
    "    print(f\"Iteration {j}\")\n",
    "\n",
    "    ## loop through batches\n",
    "    for i, batch in enumerate(batches):\n",
    "        submit_tasks(batch,i)\n",
    "\n",
    "    file_pattern = \"./phi3-inference-responses/*.json\"\n",
    "\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    for file_name in glob.glob(file_pattern): #glob lists all the text files in the current working dir.\n",
    "        with open(file_name, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "\n",
    "        if \"input_data\" in data: #retrieves list of dictionaries\n",
    "            for item in data[\"input_data\"]: #iterates over each dictionary in the list\n",
    "                if \"content\" in item:\n",
    "                    questions.append(item[\"content\"])\n",
    "\n",
    "        if \"response_data\" in data:\n",
    "            response = data[\"response_data\"]\n",
    "            answers.append(response)\n",
    "\n",
    "    final_df = pd.DataFrame({\"Question\": questions, \"Answer\": answers})\n",
    "\n",
    "    # Save DataFrame to a CSV file (optional)\n",
    "    final_df.to_csv('combined_questions_answers.csv', index=False)\n",
    "\n",
    "    final_df.head()\n",
    "\n",
    "    predictions = final_df[\"Answer\"].to_list()\n",
    "    references = df[\"answer_content\"].to_list()\n",
    "\n",
    "    rouge = evaluate.load('rouge') #https://huggingface.co/spaces/evaluate-metric/rouge\n",
    "\n",
    "\n",
    "    results = rouge.compute(predictions=predictions,\n",
    "                            references=references,\n",
    "                            use_aggregator=True)\n",
    "    rouge_df.loc[j] = [\n",
    "        round(results[\"rouge1\"], 3),\n",
    "        round(results[\"rouge2\"], 3),\n",
    "        round(results[\"rougeL\"], 3),\n",
    "        round(results[\"rougeLsum\"], 3)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1728307407700
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Calculate Confidence Interval\n",
    "def confidence_interval(data, confidence=0.95):\n",
    "    mean = np.mean(data)\n",
    "    sem = stats.sem(data)  # Standard Error of Mean\n",
    "    interval = sem * stats.t.ppf((1 + confidence) / 2., len(data) - 1)\n",
    "    return mean, interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "rouge_df.to_csv('./rouge_results.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1728307425720
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "rouge_df = pd.read_csv('./rouge_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1728307437679
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.129 ± 0.000\n",
      "ROUGE-2: 0.015 ± 0.000\n",
      "ROUGE-L: 0.074 ± 0.000\n",
      "ROUGE-Lsum: 0.092 ± 0.000\n"
     ]
    }
   ],
   "source": [
    "rouge1_mean, rouge1_ci = confidence_interval(rouge_df['ROUGE-1'])\n",
    "rouge2_mean, rouge2_ci = confidence_interval(rouge_df['ROUGE-2'])\n",
    "rougeL_mean, rougeL_ci = confidence_interval(rouge_df['ROUGE-L'])\n",
    "rougeLsum_mean, rougeLsum_ci = confidence_interval(rouge_df['ROUGE-Lsum'])\n",
    "\n",
    "print(f\"ROUGE-1: {rouge1_mean:.3f} ± {rouge1_ci:.3f}\")\n",
    "print(f\"ROUGE-2: {rouge2_mean:.3f} ± {rouge2_ci:.3f}\")\n",
    "print(f\"ROUGE-L: {rougeL_mean:.3f} ± {rougeL_ci:.3f}\")\n",
    "print(f\"ROUGE-Lsum: {rougeLsum_mean:.3f} ± {rougeLsum_ci:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
