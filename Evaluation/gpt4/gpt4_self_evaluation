Question,References,Predictions,Similarity_Rating,Accuracy,Similarity_Primed
"Hi Everyone. I was trying to add help section to my nextflow script as given below:pre><code class=""lang-bash"">nextflow.enable.dsl=2params.ref = ""resources/sequence.fasta""params.outdir=""results/00_indexes""params.runidx=""bwa""params.help = false    // Help Sectionlog.info """"""Step 0: Indexing=============================================Usage:    nextflow run idx.nf --ref ${params.ref} --outdir ${params.outdir} --runidx ${params.runidx}Input:    * --ref: Path of reference file. Defult [${params.ref}]    * --outdir: name of output directory. Default [${params.outdir}]    * --runidx: Name of tool to run indexing. Valid values are ""bwa"" and ""dragmap"". Default [${params.runidx}]""""""process DRAGMAPINDEX{    publishDir ""$params.outdir"", mode: 'copy'    input:    path (fasta)    output:    path ""*""    script:    """"""    mkdir dragmapidx    cp $fasta dragmapidx/    samtools faidx dragmapidx/$fasta     gatk CreateSequenceDictionary -R dragmapidx/$fasta      dragen-os --build-hash-table true --ht-reference dragmapidx/$fasta  --output-directory dragmapidx --ht-num-threads 20    gatk ComposeSTRTableFile -R dragmapidx/$fasta -O dragmapidx/str_table.tsv    """"""}process BWAINDEX{    publishDir ""$params.outdir"", mode: 'copy'    input:    path (fasta)    output:    path ""*""    script:    """"""    mkdir bwaidx    cp $fasta bwaidx/    bwa index bwaidx/$fasta    gatk CreateSequenceDictionary -R bwaidx/$fasta    samtools faidx bwaidx/$fasta    """"""}fa_ch=Channel.fromPath(params.ref, checkIfExists: true)if (params.help) {    log.info 'This is test pipeline'    exit 0}workflow {if (""${params.runidx}"" == ""bwa""){ BWAINDEX(fa_ch)} else if (""${params.runidx}"" == ""dragmap""){  DRAGMAPINDEX(fa_ch)  } else {  exit 1,  ""Invalid argument passed to --runidx""  }}/code></pre>This  pipeline behaves nicely when I run it with <code>nextflow run idx.nf --help</code> however it still prints the help message when I run <code>nextflow run idx.nf</code>. That is unnecessary printing of help section.pre><code>N E X T F L O W  ~  version 21.10.6Launching `idx.nf` [tender_monod] - revision: 5342c1bda0Step 0: Indexing=============================================Usage:    nextflow run idx.nf --ref resources/sequence.fasta --outdir results/00_indexes --runidx bwaInput:    * --ref: Path of reference file. Defult [resources/sequence.fasta]    * --outdir: name of output directory. Default [results/00_indexes]    * --runidx: Name of tool to run indexing. Valid values are ""bwa"" and ""dragmap"". Default [bwa]executor &gt;  local (1)[ce/99a3c5] process &gt; BWAINDEX (1) [100%] 1 of 1 ✔/code></pre>","there is no reserved word for 'help'. This is just another key of the associative map 'params'. So , just test the variable like for a regular programming language.pre><code>if( params.help ) {log.info """"""Step 0: Indexing=============================================Usage:    nextflow run idx.nf --ref ${params.ref} --outdir ${params.outdir} --runidx ${params.runidx}Input:    * --ref: Path of reference file. Defult [${params.ref}]    * --outdir: name of output directory. Default [${params.outdir}]    * --runidx: Name of tool to run indexing. Valid values are ""bwa"" and ""dragmap"". Default [${params.runidx}]""""""    exit 0}/code></pre>","The issue you're encountering with your Nextflow script is that the help message is always printed regardless of whether the `--help` flag is used or not. This happens because the help message is logged outside of any conditional statement that checks for the `--help` flag. In your script, you've set `params.help = false` by default, which is correct, but you haven't provided a mechanism for the user to set this flag to `true` via the command line. 

To resolve this issue, you need to add a condition to check if the `--help` flag is present and then set `params.help` to `true`. However, Nextflow doesn't directly support a `--help` flag in the same way it does for other parameters. Instead, you can use a workaround by checking for the presence of the `--help` flag in the script arguments and then manually setting the `params.help` to `true` before the help message is conditionally printed.

You can achieve this by adding a snippet at the beginning of your script that checks for the `--help` flag in the script's arguments and sets `params.help` accordingly. However, since Nextflow doesn't parse `--help` as a regular parameter, you might need to adjust your approach, such as using a custom parameter (e.g., `--showHelp`) or parsing the command line arguments before they are fully processed by Nextflow.

Remember, the key is to ensure that the help message is only printed when specifically requested by the user through the appropriate flag (whether it's `--help` or a custom alternative you define). This way, the help message won't be printed during regular execution of your pipeline, thus resolving the issue you've encountered.",4,5,5
"I am currently using BWA-MEM to map metagenomic reads to a small (~12kb) virus reference genome for a large number of samples. I have a lot of reads per sample - upwards of 10 million.The majority of the reads (~99%) do not match my reference - I am not interested in analysing these reads. However, the .sam file that BWA-MEM produces stores the unmapped reads, and I am stuck with these huge files that are taking up disk space (I do convert these into sorted .bam files and delete the .sam file, but they're still huge). Is there any way to stop BWA-MEM from storing the unmapped reads in the .sam file and only keep the mapped reads? Thank you for letting me know.","<pre class=""pre""><code class=""language-bash"">bwa mem (...) | samtools view -F 4 -o onlyMapped.bam/code></pre>See <a rel=""nofollow"" href=""http://broadinstitute.github.io/picard/explain-flags.html"">http://broadinstitute.github.io/picard/explain-flags.html</a> ","Yes, you can configure BWA-MEM to output only the mapped reads, thereby significantly reducing the size of your output files. When you run BWA-MEM, you can pipe its output directly to SAMtools to filter out unmapped reads on-the-fly, avoiding the creation of large intermediate files. After running BWA-MEM, use the SAMtools view command with the -F 4 flag, which tells SAMtools to exclude reads that are flagged as unmapped. The command would look something like this: `bwa mem reference.fasta reads.fastq | samtools view -b -F 4 - > mapped_reads.bam`. This command line first runs BWA-MEM to align your reads to the reference genome, then pipes the output (in SAM format) directly into SAMtools, which filters out the unmapped reads and converts the output to a compressed BAM format, containing only the mapped reads. This approach should help you manage disk space more efficiently by eliminating the storage of unmapped reads. Remember to index your BAM file afterwards with `samtools index mapped_reads.bam` if you need to quickly access or visualize the alignments.",5,5,5
"Hi all,I'm trying to align a fastq file to a reference fasta file using bwa mem and for the life of me I keep getting the following error message. Any thoughts? Thanks!pre class=""pre""><code class=""language-bash"">bwa index -a bwtsw myref.fasta -p myrefls/code></pre>blockquote>  <pre class=""pre""><code class=""language-bash"">myref.amb  myref.bwt  myref.pacmyref.ann  myref.fasta    myref.sa  </code></pre>/blockquote>pre class=""pre""><code class=""language-bash"">bwa mem -M 1 -R '@RG\tID:{foo}.{bar}\tPU:{foo}.{bar}.{999999}\tSM:{999999}\tPL:{foo}\tLB{bar}' myref myfastq.fastq.gz[E::bwa_idx_load_from_disk] fail to locate the index files/code></pre>","I am not sure, but I think the cause of the error is the <code>-M</code> parameter doesn't take any values:blockquote>  <pre class=""pre""><code class=""language-bash"">         -M        Mark shorter split hits as secondary (for Picard compatibility).  </code></pre>/blockquote>Try with:pre class=""pre""><code class=""language-bash"">bwa mem -M -R '@RG\tID:{foo}.{bar}\tPU:{foo}.{bar}.{999999}\tSM:{999999}\tPL:{foo}\tLB{bar}' myref myfastq.fastq.gz/code></pre>","It seems like you're encountering an issue where BWA MEM is unable to locate the index files for your reference genome. This problem typically arises when there's a mismatch between the specified reference in the BWA command and the actual names or locations of the index files generated by BWA index.

First, ensure that the index files (`myref.amb`, `myref.ann`, `myref.bwt`, `myref.pac`, and `myref.sa`) are in the same directory as your reference fasta file (`myref.fasta`). When you run the `bwa index` command, you've used `-p myref` to specify the prefix for the output files, which seems correct as your index files are named with the `myref` prefix.

Next, when you run the `bwa mem` command, make sure that the reference prefix (`myref` in your case) exactly matches the prefix used during indexing and that you're running the command from the directory containing both your reference and the index files, or provide the full path to the reference prefix. The error message `[E::bwa_idx_load_from_disk] fail to locate the index files` indicates that BWA MEM cannot find the index files with the prefix `myref`. This could be due to being in a different directory, a typo in the command, or an issue with file permissions.

Also, double-check the syntax and formatting of your command, especially the read group (`-R`) string, to ensure there are no typos or formatting issues that might be causing problems. However, the main issue seems to be with locating the index files rather than the read group string.

In summary, verify the location and naming of your index files, ensure you're in the correct directory or provide the full path to the reference prefix, and double-check your command syntax. This should resolve the issue and allow BWA MEM to locate the index files and proceed with the alignment.",2,5,5
"Hi,I wonder whether it's better to remove weakly aligned parts of proteins from MSA or keep them for building HMM?Case: Let's say I have a bunch of homologs and I want to generate HMM (hidden Markov-model) to be able to detect their homologs from distinct species. Questions:ol>li>Shall I use all available homologs or there is some reasonable limit (min: 5 or 15? max: 50, 100, 200)? I keep in mind that alignment gets worse the more sequnce is incorporate, plus MSA software has their limitations as well.</li>li>Which MSA program will you recommend? Personally, I like MUSCLE a lot, but I'm aware MAFFT or T-Coffee perform better (but slower).</li>li>Or shall I use more aligners and used consistency based alignment (M-coffee)?</li>li>Shall I trim badly align fragments (<a rel=""nofollow"" href=""http://trimal.cgenomics.org/"">trimAl</a> or <a rel=""nofollow"" href=""http://molevol.cmima.csic.es/castresana/Gblocks.html1.2.3."">gBlocks</a>)? </li>/ol>Cheers,","Unless your protein be something new, the best way to proceed is by looking for pre-aligned manually seeds in places like <a rel=""nofollow"" href=""http://pfam.sanger.ac.uk/"">Pfam</a> or Kadher Shameer's <a rel=""nofollow"" href=""http://caps.ncbs.res.in/3pfdb/"">3PFDB</a>. With a seed in hand, you don't need to align from scratch. And you could use it to search for homologs at a specified distance. Remember that packages like hmmbuild down-weight closely related sequences and up-weight distant ones during hmm building. So, you must select mostly distant candidates. Keep a few close ones just to sustain a little bit more of homology signal.The main question is: which aligment tool should I use? Well, if you have a seed then most aligners will return pretty the same result after a realigment. But, aligning from scratch can be painful. I do recommend <a rel=""nofollow"" href=""http://www.ebi.ac.uk/goldman-srv/webprank/"">PRANK</a> which is phylogeny-aware or ClustalW with iterate each step option turned on (very, very, very slow but way more reliable).Anyway you should consider the Pfam approach, i.e., searching piece by piece ((sub)domain, motifs, etc.). I've used this to reannotate selenoproteins in Kinetoplastida and was able to find things that even JGI crew missed.","When building a Hidden Markov Model (HMM) for detecting homologs from distinct species, the approach to selecting homologs and handling weakly aligned parts of proteins can significantly impact the model's performance. It's generally advisable to use a diverse set of homologs to capture the evolutionary breadth of the family you're interested in; however, the optimal number of sequences to include can vary. While there's no strict rule, incorporating a range from a minimum of 5 to 15 up to a maximum of 50 to 100 sequences is reasonable. This range helps balance between capturing diversity and managing the computational complexity, especially since the quality of multiple sequence alignment (MSA) can degrade with too many sequences, and MSA software may have limitations in handling large datasets.

Regarding the choice of MSA software, while MUSCLE is popular for its speed and good results in many cases, MAFFT and T-Coffee are known to perform better in terms of alignment quality, albeit at the cost of longer computation times. MAFFT, in particular, offers a good balance between speed and accuracy for large datasets. Using multiple aligners and a consistency-based alignment approach, such as M-coffee, can further improve alignment quality by leveraging the strengths of different algorithms, though at the expense of increased computational demand.

Trimming poorly aligned fragments of the alignment before building the HMM is generally recommended. Tools like trimAl and Gblocks can remove unreliable regions, which might otherwise introduce noise and reduce the accuracy of your HMM. By focusing on well-aligned regions, the resulting HMM is more likely to capture the essential features of the protein family and perform better in identifying homologs across different species. In summary, a balanced approach that considers the number and diversity of homologs, carefully selects MSA software or combines multiple aligners, and trims poorly aligned regions is crucial for building effective HMMs for homolog detection.",3,5,5
"Hello everybody, Could anyone tell me how to get SNPs using <a rel=""nofollow"" href=""http://samtools.sourceforge.net/"">SAMtools</a>???. I am learning how to do it but can´t get the SNPs, I only get the Indels. I am working with a mutant I created from an E coli genome (just for practice). The mutant was created with 5 mismatches, 5 insertions and 5 deletions (using Biopieces). The lenght and coverage is here: pre><code>read_fasta -i  &lt;fasta ref genome&gt;.fna | shred_seq -s 100 -c 50 | add_ident -k SEQ_NAME | write_fasta -x -o  &lt;rrreads&gt;.fna/code></pre>The alignment was made with <a rel=""nofollow"" href=""http://bio-bwa.sourceforge.net/"">BWA</a> . Then I used <a rel=""nofollow"" href=""http://samtools.sourceforge.net/"">SAMtools</a> protocol (as described in some of the posts) like this : pre><code>samtools mpileup -uf &lt;refgenome&gt;.fasta result.sort.bam &gt; results.bcf/code></pre>and then , pre><code>bcftools view -vcg results.bcf - &gt; test.vcf/code></pre>If anyone can help me .. Thanks!!! :)","First simple thing to try: <a rel=""nofollow"" href=""http://samtools.sourceforge.net/"">samtools</a> mpileup -Buf.  Sometimes, the BAQ calculations will wrongly believe real SNPs to be undiagnosed indels, and will drop their quality in the pileup step such that they can't be called as SNPsSince you know where your missing SNPs are, look at them in the pileup text file.  If the SNP is detected, but the quality score is terrible, despite being fine in the .bams, that's what happened.","It sounds like you're on the right track with using SAMtools and BWA for identifying SNPs in your E. coli genome project. After aligning your reads with BWA, you've correctly used `samtools mpileup` to generate a BCF file from your sorted BAM file. The command you've used with `bcftools view` to generate a VCF file from the BCF is also correct. However, if you're only getting indels in your output and not the SNPs, there might be a couple of reasons for this.

First, ensure that your reference genome and the reads are correctly prepared and aligned. Any discrepancies or errors in these steps could affect the variant calling process. Since you're specifically looking for SNPs in addition to indels, you might want to double-check the `bcftools` command options. The `-vcg` options you've used are generally correct; `-v` filters for variants, `-c` is for calling SNPs and indels by the old calling method, and `-g` calls genotypes at variant sites. However, the usage of options can slightly change with different versions of `bcftools`.

As of my last update, you might want to try using more recent options if you're using a newer version of `bcftools`. For example, `bcftools call` is now recommended for variant calling. The command would look something like this:

```bash
bcftools call -vmO v -o test.vcf results.bcf
```

This command explicitly calls both SNPs and indels. The `-m` option is for multiallelic caller, and `-O v` specifies the output format to be VCF. Ensure you're using the latest versions of SAMtools and bcftools, as updates often include improvements and bug fixes that could impact your results.

If you're still not seeing the SNPs, consider the possibility that the parameters used during the alignment or variant calling might be too stringent, or the quality of the reads might not be sufficient to confidently call SNPs. You could also try adjusting the quality score thresholds or the minimum mapping quality for reads considered in the pileup (`-q` option in `samtools mpileup`).

Lastly, ensure that the reference genome you're using matches the version and strain you're expecting. Any discrepancies here could lead to unexpected results in variant calling. If after these checks you're still facing issues, it might be helpful to consult the documentation for SAMtools and bcftools or seek advice from bioinformatics forums where you can share more details about your commands and outputs for more tailored advice.",2,5,5
Hi everyoneI have a question regarding BWA mem alignmentI was interested in finding out the performance gains I would obtain from creating a artificial reference where I masked everything I was not interested in my panel.In short I blated all my regions of interest on my panel and created a masked fasta file of the Human hg19 where I masked with N anyregion that would not have some degree of sequence similarity to my regions of interest This basicaly masked around 90% of the human genome. I then created a BWA index with that masked fasta file and aligned my samples (that I had already previously done with the normal human reference) to see if there was any performance gains in terms of the time it took to align them.To my surprise the alignment against this much smaller reference (same length as the human genome but with over 90% of bases MAsked) was slower than the normal alignment against the hg19 assembly.Can someone tell me why this is?Many thanksDuarte,"The masking doesnt make the reference genome smaller, it's the same basepair length. <br>What masking does however is let your reads possibly align in many more places. Every masked section could be a match to either end of your read. So rather than using BWA's intelligent ""seed"" technique to limit alignment time, you've forced it to look in many more places for candidate sites.I have seen this problem with GATK's HaplotypeCaller when looking near the centromere's run of many AAAA. The thing gets stuck in a loop trying millions of possible alignments for every read.","The observation that aligning your samples to a heavily masked version of the hg19 reference genome resulted in slower performance compared to the unmasked, complete hg19 reference might seem counterintuitive at first. However, this outcome can be attributed to several factors inherent to the design and optimization of alignment algorithms like BWA mem. BWA mem is optimized for speed and efficiency when aligning sequences to large, complex genomes. It employs sophisticated indexing (using the FM-index) and seeding strategies that are designed to efficiently handle the vast and varied genomic landscape of organisms like humans. When you mask a significant portion of the genome, turning 90% of it into 'N's, you essentially alter the reference in a way that might not be optimal for these algorithms. The presence of extensive masked regions could disrupt the algorithm's ability to efficiently find and extend seeds, potentially leading to more backtracking and re-evaluation of alignment paths. Additionally, the algorithm's optimizations for handling repetitive and low-complexity regions in a full genome might not translate well to a genome where such regions are masked, further impacting performance. Essentially, the modifications to the reference genome could inadvertently introduce complexities that the alignment algorithm is not optimized to handle, leading to slower performance despite the seemingly reduced complexity of the task.",4,5,5
"Hie NGS Geeks,Recently I observed some huge difference in mapping quality when aligned with bowtie &amp; bwa, after alignment I called variants using samtools mpileup. I thought someone might enlighten my knowledge about this, so my observations are1. With bowtie I got <strong>mapping quality 2 &amp; quality 6.98</strong> for particular position and when I called variants using samtools surprisingly it didn't report.Particular position in VCF file for reference:pre><code>SL2.50ch01      559045  .       G       .       6.98    .       DP=143;VDB=0.0001;AF1=1;AC1=2;DP4=0,0,64,71;MQ=2;FQ=-282        PL:DP27:135""/code></pre>ol>li>\but with bwa I got <strong>mapping quality 10 &amp; quality 78</strong> plus it reported variant i.e. alternate allele.</li>/ol>Particular position in VCF file for reference:pre><code>SL2.50ch01      559045  .       G       T       78      .       DP=58;VDB=0.0001;AF1=1;AC1=2;DP4=0,0,28,28;MQ=10;FQ=-196        GT:PL:DP:GQ   1/1:111,169,0:56:99""./code></pre>I think am not confusing anyone, if so please let me know &amp; thanks in advance","See section 3.3.2 in ""http://arxiv.org/pdf/1404.0929v1.pdf"" rel=""nofollow"">http://arxiv.org/pdf/1404.0929v1.pdf</a>","The differences you're observing in mapping quality and variant calling outcomes between Bowtie and BWA alignments, followed by variant calling with Samtools mpileup, can be attributed to the inherent differences in how these aligners work and their optimization for different types of sequencing data. Bowtie is typically more suited for short reads and is known for its speed and efficiency, particularly in aligning reads to large reference genomes. However, it might not handle mismatches and gaps as effectively as BWA, which can lead to lower mapping quality scores for certain positions. BWA, on the other hand, is optimized for longer reads and provides more sensitive alignment, which can handle small indels (insertions and deletions) more effectively than Bowtie. This can result in higher mapping quality scores and a better ability to accurately identify variants, as reflected in your observations. The mapping quality score is a measure of the confidence in the alignment of the read to the reference, and a higher score from BWA suggests it is more confident in its alignments compared to Bowtie for the data you are working with. Consequently, when you proceed to variant calling with Samtools mpileup, the higher quality alignments from BWA lead to the identification of a variant at the position you're interested in, with a significant quality score, whereas the lower quality alignments from Bowtie might not meet the threshold for variant calling, leading to the absence of the variant in your results. This highlights the importance of choosing the right aligner for your specific sequencing data and analysis goals, as it can have a significant impact on the downstream analyses such as variant calling.",4,5,4
"I've got a bam file of paired-end illumina sequences mapped to a reference sequence and I was wondering if when I call the samtools view command if the results represent only reads that completely span over the region of interest or if it also included reads that intersect it by one or two base pairs. If not are there any existing tools out there to <em>only</em> read thats completely span over the region of interest?with this visual example of what I mean I would want to only include sequences like case_2 and exclude case_1:pre class=""pre""><code class=""language-bash"">                                  [===================Region-of-Interest=====================]                 [---------------------------------------------------------------------------------------------------------] case_1                               [-------------------------------------------------------------------------------------------------------------------] case_2/code></pre>Thanks!","<a rel=""nofollow"" href=""http://bedtools.readthedocs.io/en/latest/content/tools/intersect.html"">bedtools intersect</a> with -f 1.0 or -F 1.0 should do what you want. Something like:pre class=""pre""><code class=""language-bash"">bedtools intersect -F 1.0 -a intervarls.bed -b file.bam/code></pre>I am not an expert on bedtools, though, so you may have to tweak / correct this command.","When you use the `samtools view` command to filter reads from a BAM file based on a specific region of interest, the tool includes reads that intersect with the specified region, not just those that completely span it. This means that both reads that partially overlap the region (even by just one or two base pairs) and those that fully cover the region will be returned by the command. This behavior is designed to ensure that you capture all potentially relevant reads for further analysis, but it does not directly allow you to filter reads based solely on whether they completely span a region of interest.

If your goal is to exclusively include reads that completely span a given region (like your case_2 example) and exclude reads that only partially overlap (like your case_1 example), you would need to use additional filtering criteria or tools. While `samtools` itself does not provide a direct option to filter reads in this manner, you can achieve this by using custom scripts or additional bioinformatics tools designed for more complex filtering tasks. For instance, you could write a script that parses the alignment information for each read (e.g., using pysam in Python), checks if the start and end positions of the read fully encompass your region of interest, and then retains only those reads that meet this criterion. This approach requires some programming knowledge but offers flexibility to precisely define and apply your filtering criteria.",3,5,5
"I have multiple single-sample VCF files, which I want to merge into a single multi-sample VCF file. When using <code>bcftools merge</code> I am getting duplicate records. pre class=""pre""><code class=""language-bash"">$ bcftools merge ms01e_phased.vcf.gz ms02g_phased.vcf.gz ms03g_phased.vcf.gz ms04h_phased.vcf.gz MA605_phased.vcf.gz MA611_phased.vcf.gz -O v -o RBphased_variants.SixSamples.Final.vcf # duplicate records at the same lines from the file ""RBphased_variants.SixSamples.Final.vcf""2   14691373    .   A   .   1153.31 PASS    BaseQRankSum=2.02;ClippingRankSum=0;ExcessHet=3.0103;FS=1.098;InbreedingCoeff=-0.0861;MQ=58.74;MQRankSum=-2.459;QD=19.22;ReadPosRankSum=-0.466;SOR=0.96;DP=68;AN=8  GT:AD:DP:GQ:PL:PG:PB:PI:PW:PC:PM    0/0:4:4:0:0:0/0:.:.:0/0:.:. 0/0:7:7:18:0:0/0:.:.:0/0:.:.    0/0:4:4:12:0:0/0:.:.:0/0:.:.    0/0:2:2:3:0:0/0:.:.:0/0:.:. ./.:.:.:.:.:.:.:.:.:.:. ./.:.:.:.:.:.:.:.:.:.:.2   14691373    .   A   AAG 1153.31 PASS    BaseQRankSum=2.02;ClippingRankSum=0;ExcessHet=3.0103;FS=1.098;InbreedingCoeff=-0.0861;MQ=58.74;MQRankSum=-2.459;QD=19.22;ReadPosRankSum=-0.466;SOR=0.96;set=InDels;DP=676;AF=0.042;AN=4;AC=0    GT:AD:DP:GQ:PGT:PID:PL:PG:PB:PI:PW:PC:PM    ./.:.:.:.:.:.:.:.:.:.:.:.:. ./.:.:.:.:.:.:.:.:.:.:.:.:. ./.:.:.:.:.:.:.:.:.:.:.:.:. ./.:.:.:.:.:.:.:.:.:.:.:.:. 0/0:12,0:12:9:.:.:0,9,135:0/0:.:.:0/0:.:.   0/0:22,0:22:12:.:.:0,12,180:0/0:.:.:0/0:.:.2   14691374    .   A   .   1320.25 PASS    BaseQRankSum=-1.049;ClippingRankSum=0;ExcessHet=0.2929;FS=0;InbreedingCoeff=0.4006;MQ=55.35;MQRankSum=0;QD=33.01;ReadPosRankSum=-0.671;SOR=0.892;DP=44;AN=2 GT:AD:DP:GQ:PL:PG:PB:PI:PW:PC:PM    0/0:4:4:0:0:0/0:.:.:0/0:.:. ./.:7:7:.:0:./.:.:.:./.:.:. ./.:0:0:.:0:./.:.:.:./.:.:. ./.:0:0:.:0:./.:.:.:./.:.:. ./.:.:.:.:.:.:.:.:.:.:. ./.:.:.:.:.:.:.:.:.:.:.2   14691374    .   A   G   1320.25 PASS    BaseQRankSum=-1.049;ClippingRankSum=0;ExcessHet=0.2929;FS=0;InbreedingCoeff=0.4006;MQ=55.35;MQRankSum=0;QD=33.01;ReadPosRankSum=-0.671;SOR=0.892;set=HignConfSNPs;DP=710;AF=0.115;MLEAC=3;MLEAF=0.115;AN=4;AC=0 GT:AD:DP:GQ:PGT:PID:PL:PG:PB:PI:PW:PC:PM    ./.:.:.:.:.:.:.:.:.:.:.:.:. ./.:.:.:.:.:.:.:.:.:.:.:.:. ./.:.:.:.:.:.:.:.:.:.:.:.:. ./.:.:.:.:.:.:.:.:.:.:.:.:. 0/0:12,0:12:9:.:.:0,9,135:0/0:.:.:0/0:.:.   0/0:22,0:22:12:.:.:0,12,180:0/0:.:.:0/0:.:./code></pre>I raised this issue in <code>bcftools</code> thinking if it was a bug <a rel=""nofollow"" href=""https://github.com/samtools/bcftools/issues/754"">https://github.com/samtools/bcftools/issues/754</a> . But, is there any other solution to the problem.","Hey kirannbishwa01,I would not call these duplicate records as they are different calls but at the same position.Just adding <code>--merge all</code> to your command should help to solve itSo:pre class=""pre""><code class=""language-bash"">bcftools merge --merge all ms01e_phased.vcf.gz ms02g_phased.vcf.gz ms03g_phased.vcf.gz ms04h_phased.vcf.gz MA605_phased.vcf.gz MA611_phased.vcf.gz -O v &gt; RBphased_variants.SixSamples.Final.vcf/code></pre>Kevin","The issue you're encountering with `bcftools merge` producing duplicate records seems to stem from the presence of variants at the same positions but with different alleles or variant types (e.g., SNPs vs. indels) across your input VCF files. This behavior is not necessarily a bug but rather how `bcftools merge` handles cases where variants are not exactly the same across files. When merging, `bcftools` treats these as distinct records because the alleles differ, leading to what appears as duplicate positions with different variant information.

To address this issue, you might consider preprocessing your VCF files to harmonize variant representations or to filter variants to ensure that only those with matching alleles are present before merging. This could involve using tools like `bcftools norm` to normalize indels or decompose complex alleles into simpler, consistent representations across your datasets. Additionally, carefully reviewing the VCF files to understand the nature of the discrepancies at these positions can help in deciding the best approach for preprocessing.

Another approach could be to use the `-m` option with `bcftools merge`, specifying how to handle multiallelic sites. For example, `-m none` will only merge records that are exactly the same, `-m snps` or `-m indels` can be used to merge only SNPs or indels, respectively, and `-m both` or `-m all` can merge both but handle multiallelic sites in different ways. However, this might not directly solve the issue of apparent duplicates due to different alleles but can be part of a strategy to manage how variants are merged.

Ultimately, the solution may involve a combination of careful preprocessing of your VCF files to ensure consistency in variant representation and thoughtful use of `bcftools merge` options to achieve the desired outcome.",3,5,4
"Hi,I have a somewhat high content of mitochondrial RNA in my RNA-seq experiment. Is there a way to use samtools to remove alignments to the 'MT' chromosome and keep all the rest?I'm considering using samtools view in combination with awk but perhaps there's a better/cleaner solution?Thanks!","You can use samtools to do it by selecting particular chromosomes and never leaving the binary format, for example:pre class=""pre""><code class=""language-bash"">samtools view -b input.bam chr1 chr2 chr3 chr4 &gt; output.bam/code></pre>That's a bit unwieldy to list all non-mitochondrial chromosomes manually, so you could try an ugly bash one-liner like:pre class=""pre""><code class=""language-bash"">samtools idxstats input.bam | cut -f 1 | grep -v MT | xargs samtools view -b input.bam &gt; output.bam/code></pre>","Yes, you can efficiently use `samtools` to filter out alignments to the mitochondrial chromosome ('MT') from your RNA-seq data. A straightforward and clean approach involves using `samtools view` with the `-U` option. This option allows you to specify a file to which the reads not matching the filter criteria will be written. For your case, you can use `samtools view` to exclude reads mapped to the 'MT' chromosome by specifying it with a ""!"" prefix, indicating that you want to exclude, rather than include, alignments to 'MT'. The command would look something like this: `samtools view -b -U keep.bam your_input.bam ""chrM"" > discard.bam`, where `your_input.bam` is your original BAM file, `discard.bam` will contain the reads mapped to 'MT' (which you may not need), and `keep.bam` will contain all the other reads, effectively excluding those mapped to 'MT'. This method is efficient and doesn't require additional scripting with tools like `awk`, making it a cleaner solution for your requirement.",3,5,5
"Hi all:I recently got quite confused with two SAM flags got from BWA alignment, which is ""<strong>supplementary alignment</strong>"" from chimeric alignments and ""<strong>not primary alignment</strong>"" (or ""secondary alignment"") from multiple mapping.strong>What samtools explain about these two flags is:</strong>(Refer to <a rel=""nofollow"" href=""https://samtools.github.io/hts-specs/SAMv1.pdf)"">https://samtools.github.io/hts-specs/SAMv1.pdf)</a>A chimeric alignment is primarily caused by structural variations, gene fusions, misassemblies, RNA-seq or experimental protocols. It is more frequent given longer reads. For a chimeric alignment, the linear alignments consisting of the alignment are largely non-overlapping. Typically, one of the linear alignments in a chimeric alignment is considered the ""representative"" alignment, and the others are called ""supplementary"" and are distinguished by the supplementary alignment flag.  In contrast, multiple mappings are caused primarily by repeats. They are less frequent given longer reads. If a read has multiple mappings, all these mappings are almost entirely overlapping with each other. In multiple mapping, One of these alignments is considered ""primary"". All the other alignments have the ""secondary"" alignment flag set in the SAM records that represent them.strong>However</strong>, I found in my ChIP-seq alignment results got from BWA(without -M option), alignments with ""supplementary"" flags are with overlaps with ""representative"" alignments,which I think should be ""secondary"" alignments as described. For example, I got four alignments for one pair of reads:HWI-C00135:237:CAR2BANXX:1:1101:6737:91207  163 chr6    144444720   60  61M40S  =   144444728   61  GTACACACATATACACAGTGCTAAGTTCATTGTACACACATATACACAGTGCTAACTTCATTGTACACACATATACACAGTGCTAAGTTCATTGTACACAC   BBBBBFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF   NM:i:1  MD:Z:1C59   AS:i:59 XS:i:0  SA:Z:chr6,144444722,+,33S59M9S,60,2;HWI-C00135:237:CAR2BANXX:1:1101:6737:91207  2131    chr6    144444722   11  56H45M  =   144444720   -47 ACACACATATACACAGTGCTAAGTTCATTGTACACACATATACAC   FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFBBBBB   NM:i:0  MD:Z:45 AS:i:45 XS:i:20 SA:Z:chr6,144444728,-,53M48S,11,0;HWI-C00135:237:CAR2BANXX:1:1101:6737:91207  2211    chr6    144444722   60  33H59M9H    =   144444728   59  ACACACATATACACAGTGCTAACTTCATTGTACACACATATACACAGTGCTAAGTTCAT FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF NM:i:2  MD:Z:22G30C5    AS:i:49 XS:i:0  SA:Z:chr6,144444720,+,61M40S,60,1;HWI-C00135:237:CAR2BANXX:1:1101:6737:91207  83  chr6    144444728   11  53M48S  =   144444720   -61 ATATACACAGTGCTAAGTTCATTGTACACACATATACACAGTGCTAACTTCATTGTACACACATATACACAGTGCTAAGTTCATTGTACACACATATACAC   FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFBBBBB   NM:i:0  MD:Z:53 AS:i:53 XS:i:49 SA:Z:chr6,144444722,-,56S45M,11,0;The 2nd and 3rd alignment with ""2131"" and ""2211"" flags are as ""supplementary"" alignments, however, they are fragments of the other two full-length alignments. I didn't find any reads with ""secondary"" flags in my results, but all alignments with ""supplementary"" flags I checked are cases like what I show above.Can anyone help explain this? Should I remove these ""supplementary"" alignments to keep uniquely mapped reads? Thanks very much.Best,Vanilla","Those are proper supplemental alignments, since there's no way to map the entire reads in a biologically coherent manner. A secondary alignment would occur if those reads mapped elsewhere in the genome (i.e., not overlapping like this).Anyway, yes, you can go ahead and remove those for most downstream applications. One caveat to this is that you might have a structural variation there (tandem repeat).","The confusion you're experiencing regarding ""supplementary"" and ""secondary"" alignments in your ChIP-seq data from BWA is understandable, given the nuanced differences between these two types of alignments as outlined in the SAM format specification. Supplementary alignments, marked by the SAM flag 2048, are typically used to represent parts of a read that map to different locations, often due to structural variations or other genomic complexities. These are not merely alternative mappings of the same segment but rather parts of a read that cannot be represented as a continuous linear alignment. On the other hand, secondary alignments, flagged by 256, represent alternative mapping locations for segments that could be mapped equally well to multiple places, often due to repetitive sequences.

In your case, the presence of supplementary alignments that overlap with their ""representative"" alignments might seem contradictory to the expectation that supplementary alignments are largely non-overlapping. However, this can occur in practice due to the complexities of genomic structures and the algorithms used by alignment tools like BWA. These tools attempt to represent the read's alignment in the most informative way, which can sometimes result in overlapping supplementary alignments, especially in regions with complex genomic features or in data from techniques like ChIP-seq that may capture fragmented or broken DNA segments.

Regarding whether to remove these supplementary alignments to keep uniquely mapped reads, it depends on your specific research goals and the analyses you plan to conduct. If your analysis requires only uniquely mapped reads to ensure the highest confidence in mapping locations, filtering out supplementary (and secondary) alignments might be appropriate. However, if you are interested in detecting structural variations, gene fusions, or other genomic rearrangements, retaining and analyzing supplementary alignments could provide valuable insights. It's essential to consider the biological context of your experiment and the implications of filtering out these alignments on your results.",4,5,4
"Hello, I am pretty new to bioinformatics and to this forum, and would very much appreciate any suggestions you could offer to help me with ways to filter my alignments (obtained using bwa mem) so I only have uniquely mapped reads, other than using q scores (which I have already done and doesn't solve my problem)? Here is a bit more explanation: I am trying to obtain uniquely mapped reads from my bwa mem alignments to use in downstream analyses. I realize that ""uniquely mapped reads"" is a loaded term, and that most sources I have found on the topic suggest filtering by q score should do the trick. My problem is that I have tried filtering by progressively higher q scores and I still have a (very small) number of reads that appear to not be uniquely mapped. Because I am aligning my reads from each sample to 96 different loci (in bwa), I want to make sure my reads are only mapped to one locus. For the one sample I am using to test out commands, I filtered my data so I only have properly paired reads and mapped reads (in the case of my unpaired reads) and also filtered by q score (I get nearly the same results at q of 10, 20, or 30, so it's not an issue of changing the q score level), merged all my bam files, and obtained 193,998 reads total for that sample. When I open the bam file in Geneious and count the number of reads for each locus they add up to 194, 050. I realize the difference between these two numbers is an incredibly small number of reads, and I am going to only use loci that have ~20 or 30 mapped reads for each sample (haven't yet decided on that threshold) so maybe this doesn't matter terribly much in the grand scheme, but I still would like to have these two numbers match so I am not incorrectly including loci that weren't actually sequenced for a particular sample. I have also seen suggestions to filter by XT tags, but none of my files have this tag. I DO have the XS tag (most seem to be XS:i:0). My understanding of what XS:i:0 means is a bit shaky, but I think it means that the secondary alignment has a score of zero so these would be reads that only have one alignment? And maybe this could be a good tag to use for filtering? strong>So my question is this: Does anyone have any suggestions for other tags or filtering steps I can use for my data so that my reads only map to one location, other than filtering for q score (which I have already done and will do in addition to any other filtering steps)?</strong> Here is the applicable portion of code that I am running on alignments obtained from bwa (sorted them by coordinate and converted them to bam already in a previous step). The first line is what I'm using on my paired-end file and the second line is what I am using on my unpaired read 1 file (using the same code for my unpaired read 2 file). Note that I used trimmomatic to remove low quality bases from my reads, which is why I have three different read files for each sample. pre class=""pre""><code class=""language-bash"">samtools view -q 10 -f 0x02 -b pe001_sorted.bam &gt; pe001_sorted_properlypaired.bamsamtools view -q 10 -F 0x04 -b unpaired1_sorted.bam &gt; unpaired1_sorted_mapped.bam/code></pre>Thank you very much for any help you can offer!","The XT tag was used by early versions of bwa but not bwa-mem, which is like the new version for all intents and purposes.The XT tag is mainly seen these days as the tag for marking adapter sequences in the GATK best practices workflow.Any tag that starts with an ""X"", ""Y"", or ""Z"" are user-defined, which means it's going to be unique to the tool that put them in the file. It's a real shame that tags have this 2-character limitation and can't just say what it is that they do, but meh. Bioinformatics amiright.The issue your having is most likely due to a totally non-intuitive aspect of the SAM format, where data is allowed to be wrong provided you can figure out that it's wrong. For example, a read can have ""mapped in a proper pair"" set, but if it's also unmapped, then you are supposed to recognise that the ""mapped in a proper pair == true"" is actually false.So long story short, you can't use 0x02 on it's own. You have to  say ""i don't want unmapped reads, and i do want properly paired reads"" which is -F 0x04 -f 0x02. As Devon points out you probably also want to get rid of secondary alignments, so the grand total is:pre class=""pre""><code class=""language-bash"">samtools view -q 10 -F 1284 -f 0x02 -b pe001_sorted.bam &gt; pe001_sorted_properlypaired.bam/code></pre>","Given your specific requirements for ensuring reads are uniquely mapped to a single locus, and considering that filtering by mapping quality (q score) alone hasn't resolved your issue, exploring additional SAM/BAM file tags and using them for filtering could indeed be beneficial. Since you've noticed that the XS tag is present in your alignments but not the XT tag, focusing on the XS tag could be a good strategy. The XS tag in BWA MEM outputs indicates the suboptimal alignment score. Specifically, an XS:i:0 might suggest that there are no suboptimal alignments with a positive score, which could imply uniqueness, but interpretation can vary based on the context of the alignment and the specific version of the aligner used. However, relying solely on XS:i:0 for determining uniqueness might not be entirely foolproof without understanding its context in your specific dataset.

Another approach to consider is utilizing the SAM flag to filter out secondary alignments (using `-F 0x100` with `samtools view`), as secondary alignments are alternative mappings provided by the aligner. This can help ensure that only primary alignments are considered, which might get you closer to having reads mapped uniquely to one locus. Additionally, exploring the use of tools designed for post-alignment filtering, such as `Picard` or `sambamba`, might offer more sophisticated filtering options that could address your needs more directly. These tools can provide functionalities like marking duplicates, which might indirectly help in your quest for uniquely mapped reads by removing reads that are exactly the same, potentially indicating multiple mappings.

In summary, while q score filtering is a common first step, leveraging additional tags like XS (with caution and understanding of its implications) and SAM flags to exclude secondary alignments, combined with potentially using more advanced post-processing tools, could provide a more refined approach to ensuring reads are uniquely mapped to a single locus in your dataset.",4,5,4
"Samtools can be used to select reads above certain mapping quality. pre class=""pre""><code class=""language-bash"">samtools view -h -b -q 30 aligned.bam -o above.mapQ30.bam/code></pre>strong>But, how to select a read below certain mapping quality - all aligned reads below mapQ 30?</strong>I know it can be done using awk. But, the pipeline gets lengthy and time consuming when first need to convert bam to sam - separate header - use awk for mapQ below 30 - add header - sam file - convert to bam.Really, its taking a lots of time.Thanks,","Use SAMtools with the -U flag to output reads that don't match your filter, e.g.blockquote>  samtools view -h -b -q 30 -U below_q30.bam aligned.bam/blockquote>","To select reads below a certain mapping quality, such as all aligned reads below mapQ 30, directly with samtools without the need for converting between BAM and SAM formats and manipulating with awk, you can use a combination of samtools view and a filtering expression. Unfortunately, as of my last update, samtools itself does not provide a direct option to filter reads below a specific mapping quality threshold with a simple command-line flag like it does for filtering reads above a certain quality with the `-q` option. However, you can achieve your goal by using other tools or scripting languages that can process BAM files or by employing samtools in combination with awk or similar, despite the concerns about efficiency and pipeline length you mentioned.

For a more efficient approach that avoids the lengthy pipeline you described, you might consider using `samtools view` to output the file in SAM format (which is text-based and thus easier to process with text manipulation tools) and then pipe the output to `awk` or a similar tool for filtering. For example:

```bash
samtools view -h aligned.bam | awk '($1 ~ /^@/ || $5 < 30)' | samtools view -b -o below.mapQ30.bam -
```

This command uses `samtools view -h` to output the BAM file in SAM format including the header. The output is then piped to `awk`, which filters for lines that either start with ""@"" (indicating a header line) or have a mapping quality (`$5`) less than 30. Finally, the filtered SAM output is piped back into `samtools view -b` to convert it back to BAM format and written to `below.mapQ30.bam`.

While this approach still involves converting between BAM and SAM formats, it streamlines the process by using pipes and avoids the need to separately handle the header and conversion steps in a more manual and time-consuming manner.",3,4,4
"Hi,I came across this in STAR aligner:--outSAMattributes Allthe manual says it includes: NH HI AS NM NM MD jM jIwhere can I find what these mean?Thanks,","""Sequence Alignment/Map Optional Fields Specication"" <a rel=""nofollow"" href=""http://samtools.github.io/hts-specs/SAMtags.pdf"">http://samtools.github.io/hts-specs/SAMtags.pdf</a> ","The STAR aligner, a popular tool for aligning RNA sequencing reads to a reference genome, offers a wide range of options for customizing output, including the `--outSAMattributes` option. When you use `--outSAMattributes All`, STAR includes a comprehensive set of attributes in the SAM file output. Here's a brief explanation of what these abbreviations mean: 

- **NH**: Number of reported alignments that contain the query in the current record.
- **HI**: Hit index, representing the rank of this alignment among other alignments that have the same query name.
- **AS**: Alignment score generated by the aligner, indicating how well the read aligns to the reference.
- **NM**: Edit distance to the reference, which includes substitutions, insertions, and deletions needed to change the read into the exact sequence found in the reference.
- **MD**: String for mismatching positions, providing information about mismatches and deletions in the alignment.
- **jM** and **jI**: These attributes are specific to STAR and relate to the splice junctions. **jM** (junction motif) indicates the motif type of the splice junction, and **jI** (junction intron) provides the start and end positions of the intron for the splice junction.

For a detailed explanation of each attribute, it's best to consult the SAM format specification, which provides comprehensive details on these and other attributes used in SAM/BAM files. The STAR aligner documentation and user forums can also be valuable resources for understanding how STAR uses these attributes specifically.",1,5,5
"Hi,Once again, I'm bothering the knowledgeable people from this site :) I'm currently analyzing some RNAseq data from mouse, and after running TopHat on my paired-end files, I wanted to look at any form of program that could let me know how many reads from my dataset aligned, and how many of them properly aligned to the ref mouse genome annotation.After performing the <a rel=""nofollow"" href=""http://samtools.sourceforge.net/"">samtools</a> flagstat on the accepted hits <a rel=""nofollow"" href=""http://samtools.sourceforge.net/SAM1.pdf"">bam</a> file, I get the following:pre><code>20968800 + 0 in total (QC-passed reads + QC-failed reads)0 + 0 duplicates20968800 + 0 mapped (100.00%:nan%)20968800 + 0 paired in sequencing11431237 + 0 read19537563 + 0 read271098 + 0 properly paired (0.34%:nan%)6633306 + 0 with itself and mate mapped14335494 + 0 singletons (68.37%:nan%)0 + 0 with mate mapped to a different chr0 + 0 with mate mapped to a different chr (mapQ&gt;=5)/code></pre>I've been trying to look on how to interpret these numbers, and what does that properly paired (0.34%:nan%) means, but so far I haven't been lucky. I don't really know how to interpret the final flagstat output, and whether my alignment conditions worked at all.I'd appreciate any piece of information on this issue, thanks!!!!","Here is the C code in <a rel=""nofollow"" href=""http://samtools.sourceforge.net/"">samtools</a>:pre class=""pre""><code class=""language-bash"">typedef struct {    long long n_reads[2], n_mapped[2], n_pair_all[2], n_pair_map[2], n_pair_good[2];    long long n_sgltn[2], n_read1[2], n_read2[2];    long long n_dup[2];    long long n_diffchr[2], n_diffhigh[2];} bam_flagstat_t; (...)    printf(""%lld + %lld in total (QC-passed reads + QC-failed reads)\n"", s-&gt;n_reads[0], s-&gt;n_reads[1]);    printf(""%lld + %lld duplicates\n"", s-&gt;n_dup[0], s-&gt;n_dup[1]);    printf(""%lld + %lld mapped (%.2f%%:%.2f%%)\n"", s-&gt;n_mapped[0], s-&gt;n_mapped[1], (float)s-&gt;n_mapped[0] / s-&gt;n_reads[0] * 100.0, (float)s-&gt;n_mapped[1] / s-&gt;n_reads[1] * 100.0);    printf(""%lld + %lld paired in sequencing\n"", s-&gt;n_pair_all[0], s-&gt;n_pair_all[1]);    printf(""%lld + %lld read1\n"", s-&gt;n_read1[0], s-&gt;n_read1[1]);    printf(""%lld + %lld read2\n"", s-&gt;n_read2[0], s-&gt;n_read2[1]);    printf(""%lld + %lld properly paired (%.2f%%:%.2f%%)\n"", s-&gt;n_pair_good[0], s-&gt;n_pair_good[1], (float)s-&gt;n_pair_good[0] / s-&gt;n_pair_all[0] * 100.0, (float)s-&gt;n_pair_good[1] / s-&gt;n_pair_all[1] * 100.0);    printf(""%lld + %lld with itself and mate mapped\n"", s-&gt;n_pair_map[0], s-&gt;n_pair_map[1]);    printf(""%lld + %lld singletons (%.2f%%:%.2f%%)\n"", s-&gt;n_sgltn[0], s-&gt;n_sgltn[1], (float)s-&gt;n_sgltn[0] / s-&gt;n_pair_all[0] * 100.0, (float)s-&gt;n_sgltn[1] / s-&gt;n_pair_all[1] * 100.0);    printf(""%lld + %lld with mate mapped to a different chr\n"", s-&gt;n_diffchr[0], s-&gt;n_diffchr[1]);    printf(""%lld + %lld with mate mapped to a different chr (mapQ&gt;=5)\n"", s-&gt;n_diffhigh[0], s-&gt;n_diffhigh[1]);(...)        ++(s)-&gt;n_reads[w];                                                \        if ((c)-&gt;flag &amp; BAM_FPAIRED) {                                    \            ++(s)-&gt;n_pair_all[w];                                        \            if ((c)-&gt;flag &amp; BAM_FPROPER_PAIR) ++(s)-&gt;n_pair_good[w];    \            if ((c)-&gt;flag &amp; BAM_FREAD1) ++(s)-&gt;n_read1[w];                \            if ((c)-&gt;flag &amp; BAM_FREAD2) ++(s)-&gt;n_read2[w];                \            if (((c)-&gt;flag &amp; BAM_FMUNMAP) &amp;&amp; !((c)-&gt;flag &amp; BAM_FUNMAP)) ++(s)-&gt;n_sgltn[w];    \            if (!((c)-&gt;flag &amp; BAM_FUNMAP) &amp;&amp; !((c)-&gt;flag &amp; BAM_FMUNMAP)) { \                ++(s)-&gt;n_pair_map[w];                                    \                if ((c)-&gt;mtid != (c)-&gt;tid) {                            \                    ++(s)-&gt;n_diffchr[w];                                \                    if ((c)-&gt;qual &gt;= 5) ++(s)-&gt;n_diffhigh[w];            \                }/code></pre>ul>li><code>[2]</code> is  an array of two elements storing the number of reads and the number of 'QC-failed reads'.</li>li>'NAN' means 'Not A Number' (e.g: div by 0)</li>li><code>n_reads</code> are the total number of reads</li>li><code>n_pair_all</code> : the read is paired in sequencing, no matter whether it is mapped in a pair</li>li><code>n_pair_good</code> : the read is mapped in a proper pair</li>li><code>n_read1</code> : count read1</li>li><code>n_read2</code> : count read2</li>li><code>n_sgltn</code> : the read itself is unmapped the mate is mapped</li>li><code>n_pair_map</code>: the read itself is mapped the mate is unmapped</li>li><code>n_diffchr</code>: number of reads with a mate mapped on a different chromosome</li>li><code>n_diffhigh</code>: number of reads with a mate  on a different chromosome having a quality greater than 5</li>/ul>for more information, see <a rel=""nofollow"" href=""http://samtools.sourceforge.net/SAM1.pdf"">the spec</a>","Certainly! Your samtools flagstat output provides a comprehensive overview of your RNAseq data alignment statistics after running TopHat. The key figures to note are that out of 20,968,800 total reads, all of them (100%) have been mapped to the reference mouse genome, which indicates a successful alignment process. However, there are a couple of points that might raise concerns.

Firstly, the ""properly paired"" statistic is notably low at only 0.34%. In paired-end sequencing, reads are expected to align in a specific orientation and distance from each other that matches the library preparation parameters. A low percentage of properly paired reads suggests that the vast majority of your reads do not align according to these expected parameters. This could be due to various factors such as incorrect library preparation, sequencing errors, or issues with the reference genome.

Secondly, the report indicates that 68.37% of your reads are singletons. Singletons are reads where one read of the pair is aligned to the reference genome, but its mate does not align properly. A high percentage of singletons could further indicate issues with the sequencing data quality, the alignment process, or the reference genome used.

The absence of reads with mates mapped to different chromosomes (indicative of translocations or other large-scale genomic rearrangements) is expected in most normal conditions and does not typically raise concern.

In summary, while your alignment rate is excellent, the low percentage of properly paired reads and the high percentage of singletons suggest that there may be underlying issues with your data or the alignment process. It would be advisable to review the sequencing protocol, check the quality of your sequencing data, and ensure that the reference genome and alignment parameters are appropriate for your experiment. Further analysis and possibly consulting with a bioinformatics specialist might be necessary to resolve these issues and ensure the reliability of your downstream analyses.",1,5,5
"I can extract reads mapped to a single reference sequence by first aligning the reads using, say, BWA, and processing with SAMtools:pre class=""pre""><code class=""language-bash"">samtools view -b -f 0x2 alignment.sam | samtools fastq - -1 mapped_1.fastq -2 mapped_2.fastq/code></pre>Is there a similar pipeline I can use to extract reads mapped to multiple references? That is, if a read was found in any of the given references, it should be included in the output. Here's an idea I have: ol>li>align the reads to each reference separately (producingmultiple SAM files)</li>li>extract the reads mapped to eachreference using the above pipeline</li>li><code>sort</code> and <code>uniq</code> the names of the reads from all output files, storing the names in file.txt</li>li><code>grep</code> the names in file.txt from one of the SAM files and store in a new SAM file</li>li>convert SAM to FASTQ </li>/ol>I'm guessing this is probably not the most efficient way to solve the problem. It also doesn't catch when a read might be mapped to one of the references without its pair. In this case, I'd like to extract both reads.","The most efficient way would be to map to all the references at once.  You can do this with any aligner if you just concatenate the references.  Alternatively you could map to all at once using BBSplit, which can produce one fastq output file per reference, containing all the reads (or pairs) that best map to that reference.  But if you simply want all reads that map to any reference in a single fastq file, along with their unmapped mates, you can do this:pre class=""pre""><code class=""language-bash"">1) Concatenate the references with cat.2) Map the reads with this command:bbmap.sh ref=references.fa in1=read1.fq.gz in2=read2.fq.gz outm=mapped.fq.gz outu=unmapped.fq.gz/code></pre>If one or both reads in a pair map to anything, both will go to ""outm""; if neither map, both will go to ""outu"".  The output files will be interleaved, but if you use ""outm1"" and ""outm2"" (and etc.) you can get the output in dual files.","Your approach to extracting reads mapped to multiple references is logical but indeed might not be the most efficient way, especially considering the computational overhead of handling multiple files and the potential for very large datasets. A more streamlined approach could involve aligning your reads to a combined reference that includes all your target references concatenated together. This way, you only need to perform the alignment step once, which can significantly save time and computational resources.

After aligning to the combined reference using a tool like BWA, you can proceed with SAMtools to filter and extract the mapped reads. The command you provided, `samtools view -b -f 0x2 alignment.sam | samtools fastq - -1 mapped_1.fastq -2 mapped_2.fastq`, is a good start for extracting properly paired reads. To ensure you also capture reads where only one mate is mapped, you might consider adjusting the flags you use with `samtools view`. For instance, using `-F 0x4` will include reads that are not flagged as unmapped, thus capturing any read that has been mapped, regardless of its pair's status.

To address the issue of extracting reads based on their mapping to any of the given references within the combined reference, you would typically not need to sort and uniq the read names unless you have a specific need to deduplicate reads across different reference sequences. If deduplication is necessary, your proposed method of extracting read names, sorting, and using `uniq` before selecting reads from the SAM file could work but might be cumbersome for large datasets. Tools like `samtools view` and `awk` can be used more directly to filter reads by their reference sequence name if needed.

In summary, aligning once to a combined reference and then using SAMtools to filter and extract mapped reads, while adjusting flags to ensure you capture both members of read pairs even if only one is mapped, can be a more efficient pipeline. This approach minimizes the number of alignment steps and file handling operations, making it more suitable for large-scale analyses.",4,5,4
"Hi,I've got fold change data for samples 1 and 2 from time point t1 to time point t2. I want to create a heat map using pheatmap for subsets of genes (~50-100 per set) but I want to be able to define the colour scale to be the same for all.At the moment, R picks the range based on the highest fold change e.g. Heat map 1: this subset has a 200 fold  upregulation but no downregulation so 0 is blue and +200 is red. Heat map 2: this subset has 100 fold down regulation in one gene and only 2 fold upregulation for another, so the range will be -100 is blue and +2 is red. Is there a way that I can say +200 is always red and -100 is always blue and keep this range for all heat maps?Thanks.","This is sample code for the ALL dataset I downloaded from Bioconductor:pre class=""pre""><code class=""language-bash"">library(ALL)library(pheatmap)library(RColorBrewer)# Imports the sample expression datadata(""ALL"")expressionData = exprs(ALL)# Sets the minimum (0), the maximum (15), and the increasing steps (+1) for the color scale# Note: if some of your genes are outside of this range, they will appear white on the heatmapbreaksList = seq(0, 15, by = 1)# Plots the first heatmappheatmap(expressionData[1:10, ], # Plots the first 10 genes of the dataset         color = colorRampPalette(rev(brewer.pal(n = 7, name = ""RdYlBu"")))(length(breaksList)), # Defines the vector of colors for the legend (it has to be of the same lenght of breaksList)         breaks = breaksList) # Sets the breaks of the color scale as in breaksList# Plots the second heatmap with the same color and breaks optionspheatmap(expressionData[20:30, ], # Plots the third 10 genes of the dataset         color = colorRampPalette(rev(brewer.pal(n = 7, name = ""RdYlBu"")))(length(breaksList)),         breaks = breaksList)/code></pre>First heatmap <img src=""http://s32.postimg.org/ycaa1akcl/heat1.png"" alt=""enter image description here"">Second heatmap <img src=""http://s32.postimg.org/xsioeoqyt/heat2.png"" alt=""enter image description here""> ","Yes, you can standardize the color scale across multiple heat maps in R using the `pheatmap` package by specifying the `breaks` argument to define the color scale range consistently across all your heat maps. To achieve a consistent color scale where +200 is always red and -100 is always blue for all your heat maps, you first need to determine the range of fold changes you want to represent across all subsets. In your case, this range is from -100 to +200. You can then create a sequence of values from -100 to +200 and use this sequence as the `breaks` argument in `pheatmap`. Additionally, you will need to specify the `color` argument to define the color gradient. For example, you might use `colorRampPalette(c(""blue"", ""white"", ""red""))(length(breaks) - 1)` to generate a gradient from blue to white to red, where white represents a fold change close to 0. By setting these arguments consistently in your `pheatmap` calls for each subset of genes, you ensure that the color scale remains the same across all heat maps, allowing for direct comparison between them. This approach enhances interpretability, as the color intensity will represent the same fold change magnitude across all subsets.",4,5,5
"I am looking for a good workflows, readings or tutorial for SNP calling. I read <a rel=""nofollow"" href=""http://biostar.stackexchange.com/questions/4277/a-workflow-of-population-genomic-operations-analysis-for-newcomers"">some</a> <a rel=""nofollow"" href=""http://biostar.stackexchange.com/questions/613/what-methods-do-you-use-for-in-del-snp-calling"">other</a> <a rel=""nofollow"" href=""http://biostar.stackexchange.com/questions/4277/a-workflow-of-population-genomic-operations-analysis-for-newcomers"">posts</a> on this topic, but I would like a more detailed explanation. Population genomics and sequence data are new to me (I have a general CS and biology background). It might just be me, but these tools are not as straightforward or as documented as I'd like. Any links or explanations would be good!So far, my situation is as follows:ul>    <li>I have Illumina sequence reads for a highly polymorphic species</li>    <li>I aligned these reads using <a rel=""nofollow"" href=""http://bio-bwa.sourceforge.net/"">BWA</a> against a reference genome with default parameters, but I am not sure if I should change parameters (if so, which ones?) due to the highly polymorphic data</li>    <li>I am unsure of the next step, I will probably be using <a rel=""nofollow"" href=""http://samtools.sourceforge.net/"">SAMtools</a> or GATK... I tried making an mpile up but got really confused after that.</li>    <li>I should also be accessing SNP quality..what tools are used for that? I already see some sequencing errors when browsing the data.</li>/ul>As you can tell, I am totally new with this. It is pretty exciting so I want to learn and be able to do some of these things! Thanks in advance.edit: I also get so confused with some of the output, more detailed documentation on that would be nice as well!","GATK is certainly the best variant caller and it's the difference is important because with indels in particular, they can be hugely different.I've spoken to a few people who have had issues with GATK so I've actually written a blog post with a workflow that works for GATK. The major issues seemed to be using GATK's best practices, particularly their add or replace read groups module which sometimes causes it to fall over later. By adding the read group (you can make it whatever you like) when you run bwa, then this workflow actually works.This was written for microbes so ploidy is set to 1 for HaplotypeCaller, but this can be set to whatever you like (do check the documentation). Originally posted here(""https://approachedinthelimit.wordpress.com/2015/10/09/variant-calling-with-gatk/"" rel=""nofollow"">https://approachedinthelimit.wordpress.com/2015/10/09/variant-calling-with-gatk/</a>)hr>ul>li>Dependencies:</li>/ul>You'll need to install picardtools, GATK, bwa and optionally, vcffilter for this workflow. Picardtools and GATK are simply .jar files so that's no problem while you probably already have bwa installed, otherwise installation is well documented!ul>li>The workflow</li>/ul>This workflow begins with short read (fastq) files and a fasta reference. First a sequence dictionary is created, short reads are aligned to the reference and read group information provided, resulting sequence alignment map (sam) file sorted and converted to binary alignment map (bam) format, duplicates marked, bam file sorted, indel targets identified, indels realigned and variants called. Simple!For simplicity an example set of commands are provided here, where the reference is reference.fasta and the short reads are R1.fastq.gz and R2.fastq.gz. You will need to enter the paths and versions of the software being used at each step and your actual file names.strong>Create sequence dictionary</strong>pre><code>java -jar~/bin/picard-tools-1.8.5/CreateSequenceDictionary.jar REFERENCE=reference.fasta OUTPUT=reference.dict/code></pre>strong>Align reads and assign read group</strong>pre><code>bwa mem -R ""@RG\tID:FLOWCELL1.LANE1\tPL:ILLUMINA\tLB:test\tSM:PA01"" reference.fasta R1.fastq.gz R2.fastq.gz &gt; aln.sam/code></pre>strong>Sort sam file</strong>pre><code>java -jar ~/bin/picard-tools-1.8.5/SortSam.jar I=aln.sam O=sorted.bam SORT_ORDER=coordinate/code></pre>strong>Mark duplicates</strong>pre><code>java -jar ~/bin/picard-tools-version/MarkDuplicates.jar I=sorted.bam O=dedup.bam METRICS_FILE=metrics.txt/code></pre>strong>Sort bam file</strong>pre><code>java -jar ~/bin/picard-tools-version/BuildBamIndex.jar INPUT=dedup.bam/code></pre>strong>Create realignment targets</strong>pre><code>java -jar ~/bin/GATK3.3/GenomeAnalysisTK.jar -T RealignerTargetCreator -R reference.fasta -I dedup.bam -o targetintervals.list/code></pre>strong>Indel realignment</strong>pre><code>java -jar ~/bin/GATK3.3/GenomeAnalysisTK.jar -T IndelRealigner -R PA01.fasta -I dedup.bam -targetIntervals targetintervals.list -o realigned.bam/code></pre>strong>Call variants (HaplotypeCaller)</strong>pre><code>java -jar ~/bin/GATK3.3/GenomeAnalysisTK.jar -T HaplotypeCaller -R reference.fasta -I realigned.bam -ploidy 1 -stand_call_conf 30 -stand_emit_conf 10 -o raw.vcf/code></pre>The resulting vcf file will contain your variant calls!Then you can optionally filter the variants:strong>Filter variants</strong>pre><code>~/bin/vcflib/bin/vcffilter -f 'DP &gt; 9' -f 'QUAL &gt; 10' raw.vcf &gt; filtered.vcf/code></pre>Or first split the raw.vcf file into SNPs and indels:strong>Extract SNPs</strong>pre><code>java -jar ~/bin/GATK3.3/GenomeAnalysisTK.jar -T SelectVariants -R reference.fasta -V raw.vcf -selectType SNP -o snps.vcf/code></pre>strong>Extract Indels</strong>pre><code>java -jar ~/bin/GATK/GenomeAnalysisTK.jar -T SelectVariants -R reference.fasta -V raw.vcf -selectType INDEL -o indels.vcf/code></pre>I also have a neat perl wrapper to automate this workflow over many short read files and would be happy to make this available if people are interested! Please do comment with any questions or issues and I'll do my best to resolve them!","Embarking on SNP calling, especially in a highly polymorphic species, can indeed be a complex and daunting task, but with a solid workflow and the right tools, it becomes manageable. Given your background in CS and biology, you're well-positioned to navigate this process. Since you've already aligned your Illumina sequence reads to a reference genome using BWA, you're off to a good start. While BWA's default parameters are generally robust, for highly polymorphic species, you might want to explore adjusting the alignment scoring parameters to better tolerate mismatches, which could be more common in such species. This adjustment helps in accurately mapping reads to the reference genome despite the high variability.

The next step involves processing the aligned reads to identify SNPs, for which both SAMtools and GATK are excellent choices. GATK, in particular, offers a more comprehensive suite of tools for SNP calling and has extensive documentation to guide users through its best practices workflow. This workflow includes pre-processing steps like marking duplicates and recalibrating base quality scores, followed by variant calling and filtering to ensure high-quality SNP calls.

For assessing SNP quality, tools like GATK's Variant Quality Score Recalibration (VQSR) or filtering based on quality metrics provided in the VCF file generated by SAMtools or GATK can be used. These metrics include depth of coverage, quality by depth, and strand bias, among others, which help in distinguishing true SNPs from sequencing errors or artifacts.

Understanding the output from these tools can be challenging initially. VCF (Variant Call Format) files, which are the standard output format for SNP calling, contain detailed information about each variant, including its location, the reference and alternate alleles, quality scores, and genotype information for each sample. Familiarizing yourself with the VCF file format and using tools like bcftools for viewing and filtering VCF files can be incredibly helpful.

For a more structured approach to learning, consider tutorials and resources provided by the developers of these tools. The GATK Best Practices (available on the Broad Institute's website) and SAMtools documentation offer step-by-step guides and are excellent starting points. Additionally, online courses and workshops on bioinformatics, specifically those focusing on variant calling and population genomics, can provide structured and detailed explanations, often with hands-on exercises that can enhance your understanding.

In summary, while the process of SNP calling in highly polymorphic species involves several steps and considerations, starting with proper alignment, followed by variant calling with tools like SAMtools or GATK, and quality assessment of SNPs, there are ample resources and tutorials available to guide you through each step. With your background and a bit of persistence, you'll find that these tools and workflows become more intuitive over time.",3,5,4
"Hi,I would like to obtain a pileup (from a bam file) that also includes the read names. samtools mpileup command only gives the bases: samtools mpileup --positions ctg2.bed  -f reference_genomic2.fasta  reads.bam  ctg2_left_rc    177692  C       53      ,,.,.,..,....,...,,,,.....,.............AAAAAAAAAaaaa   ]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]O]]]]]]]]]]]]]]]]]ctg2_left_rc    177721  T       55      ,,,.,.,<em>.,....,...,,,,....</em>,......<em>..</em>.*.CCCCCCCCCCcccc ]]]]]]]]]]]K]]]]]]]]]]]R]]]L]]]]]]]]]]]]]]]]]]]]N]]]]]]Checking in the IGV browser, I saw that samtools mpileup  correctly identified the deletions in the reads (with '*') Since I need the read names and could not find a suitable command in samtools, I  wrote a script in python, using  pysam (I am a newbie in both). However, it is not correctly handling indels, and instead of reporting them with '*' as samtools mpileup, it gives the previous base. My script follows; any suggestion will be greatly appreciated.the command line:samtools_view.py   --bam reads.bam  --fasta reference_genomic2.fasta  --chr ctg2_left_rc --start 177721 --end 177722the script:pre class=""pre""><code class=""language-bash"">#! /usr/local/bin/python2.7 import pysamimport argparseparser = argparse.ArgumentParser(description='usage: python samtools_view.py  --bam reads.bam --fasta reference_genomic.fasta  --chr ctg2_right --start 100140 --end 100142 ')parser.add_argument('--bam', help='Input bam file name',required=True)parser.add_argument('--fasta', help='Input reference fasta file name',required=True)parser.add_argument('--chr',help='target contig or chromosome', required=True)parser.add_argument('--start',help='target region start (bp)', required=True)parser.add_argument('--end',help='target region end (bp)', required=True)args = parser.parse_args()args.start = int(args.start) args.end = int(args.end)samfile = pysam.AlignmentFile(args.bam, ""rb"")fastafile = pysam.FastaFile( args.fasta )for pileupcolumn in samfile.pileup(args.chr, args.start, args.end):    for pileupread in pileupcolumn.pileups:        if (pileupcolumn.pos &gt;= args.start) and (pileupcolumn.pos &lt;= args.end):           print ('%s\t%s\t%s\t%s\t%s\t%s' %                 (args.chr,          pileupcolumn.pos,                     fastafile.fetch(args.chr,pileupcolumn.reference_pos -1,pileupcolumn.reference_pos), # -1 needed because pysam is 0-based and most programs (and human heads) are 1-based          pileupread.alignment.query_name,          pileupread.query_position,                    pileupread.alignment.query_sequence[pileupread.query_position -1]))samfile.close()fastafile.close()/code></pre>","Internally, <code>samtools mpileup</code> is also getting the wrong base. The difference is that it also checks something of the form:pre class=""pre""><code class=""language-bash"">if not pileupread.is_del and not pileupread.is_refskip:/code></pre>The deletion/splicing status can be checked and handled in this way. Note that you're not the first pysam user to get confused by this. This isn't really pysam's fault, it's just exposing the underlying C functions which work in this way.","Your Python script using pysam is a good start for customizing the output of a pileup to include read names, which is not directly supported by `samtools mpileup`. However, as you've noticed, handling indels (insertions and deletions) correctly requires special attention. In the pysam library, `PileupRead` objects have attributes that can help you identify and correctly report indels.

When iterating over `pileupcolumn.pileups`, each `pileupread` object can be checked for an indel or a deletion. The `pileupread.indel` attribute will be positive for insertions, negative for deletions, and zero otherwise. You can use this attribute to adjust your output accordingly.

Here's an improved version of the relevant part of your script that attempts to handle indels:

```python
for pileupcolumn in samfile.pileup(args.chr, args.start, args.end):
    for pileupread in pileupcolumn.pileups:
        if (pileupcolumn.pos >= args.start) and (pileupcolumn.pos <= args.end):
            base = fastafile.fetch(args.chr, pileupcolumn.reference_pos - 1, pileupcolumn.reference_pos)
            read_name = pileupread.alignment.query_name
            query_position = pileupread.query_position
            if pileupread.indel > 0:
                indel_seq = pileupread.alignment.query_sequence[query_position:query_position + pileupread.indel + 1]
                print(f'{args.chr}\t{pileupcolumn.pos}\t{base}\t{read_name}\t{query_position}\t{indel_seq} [Insertion]')
            elif pileupread.indel < 0:
                print(f'{args.chr}\t{pileupcolumn.pos}\t{base}\t{read_name}\t{query_position}\t* [Deletion]')
            else:
                if query_position is not None:
                    base_at_pos = pileupread.alignment.query_sequence[query_position - 1]
                    print(f'{args.chr}\t{pileupcolumn.pos}\t{base}\t{read_name}\t{query_position}\t{base_at_pos}')
                else:
                    # This handles cases where the read has a deletion at this position
                    print(f'{args.chr}\t{pileupcolumn.pos}\t{base}\t{read_name}\t{query_position}\t* [Deletion]')
```

This code snippet checks if there's an indel at the current position for each read. If there's an insertion (`pileupread.indel > 0`), it prints the sequence of the insertion. For deletions (`pileupread.indel < 0`), it simply prints a `*` to indicate the deletion, similar to `samtools mpileup`. Note that `query_position` might be `None` for reads that do not cover the position due to a deletion; this case is also handled by printing a `*`.

Remember, this is a basic approach and might need further refinement based on your specific requirements, especially for complex regions with overlapping indels. Testing with known cases and comparing against `samtools mpileup` output can help ensure accuracy.",3,5,4
"I ran HISAT2 (index built using a transcriptome multi fasta) intending that it won't perform gapped alignment. I use following script to run HISAT:pre class=""pre""><code class=""language-bash"">INDEX=./indices/hisat/transcriptomeFASTQ=$1OUTPUT=./transcriptome_aligned/$2.sam./software/hisat-0.1.6-beta/hisat \    -q \    -p 2 \    --no-spliced-alignment \    --end-to-end \    -x $INDEX \    -U $FASTQ \    -S $OUTPUT/code></pre>Should I still expect gapped alignment in my SAM file?I have records like this in the SAM output.pre class=""pre""><code class=""language-bash"">SRR2144041.255  0   YCL025C 274 255 16M1I33M    *   0   0   CAGGCTCAAGAACTAGAAAAAAAATGAAAGTTCGGACAACATAGGCGCTA  CCCFFFFFHHHHHJJJJJJJJJJJJJJJIJGIIIIJJJJJIJJIIJJJHH  AS:i:-8 XN:i:0  XM:i:0  XO:i:1  XG:i:1  NM:i:1  MD:Z:49 YT:Z:UU NH:i:1/code></pre>This shows that HISAT2 is still performing gapped alignment even with <code>--end-to-end</code> and <code>--no-splice-alignment</code> parameters.I'm trying to use the output SAM for <code>rsem-calculate-expression</code> but it returns following error due to presence of gapped alignment:pre class=""pre""><code class=""language-bash"">rsem-parse-alignments ./indices/rsem/rsem ./rsem_output/sample.temp/sample ./rsem_output/sample.stat/sample ./transcriptome_aligned/sample.bam 1 -tag XMRead SRR2144041.836747: RSEM currently does not support gapped alignments, sorry!""rsem-parse-alignments ./indices/rsem/rsem ./rsem_output/sample.temp/sample ./rsem_output/sample.stat/sample ./transcriptome_aligned/sample.bam 1 -tag XM"" failed! Plase check if you provide correct parameters/options for the pipeline!/code></pre>How do I make sure that HISAT2 doesn't perform gapped alignment? Should I filter the output for using <code>grep -v XO:i:0</code>?strong>EDIT:</strong> I checked RSEM manual and found that in order to avoid gapped alignments using Bowtie2, RSEM uses following Bowtie2 parameters:pre class=""pre""><code class=""language-bash"">--sensitive --dpad 0 --gbar 99999999 --mp 1,1 --np 1 --score-min L,0,-0.1/code></pre>I wonder what is the equivalent of <code>--gbar</code> in HISAT2Thanks","Solved it:Included following two parameters in HISAT2 run command to make gap opening and extension insanely difficult.pre class=""pre""><code class=""language-bash"">--rdg 10000,10000--rfg 10000,10000/code></pre>My HISAT2 script now looks like this:pre class=""pre""><code class=""language-bash"">INDEX=./indices/hisat/transcriptomeFASTQ=$1OUTPUT=./transcriptome_aligned/$2.sam./software/hisat-0.1.6-beta/hisat \    -q \    -p 2 \    --no-spliced-alignment \    --end-to-end \    --rdg 10000,10000 \    --rfg 10000,10000 \    -x $INDEX \    -U $FASTQ \    -S $OUTPUT/code></pre>Hope it helps, if anybody is trying to run RSEM downstream of HISAT2.This solution might not be foolproof. Improvements on this answer are invited.","In your scenario, despite using the `--no-spliced-alignment` and `--end-to-end` options with HISAT2, you are still observing gapped alignments in your SAM file, as indicated by the presence of insertions (e.g., `16M1I33M`). This is problematic for your downstream analysis with RSEM, which does not support gapped alignments. The `--end-to-end` option in HISAT2 is designed to ensure that reads are aligned end-to-end without soft clipping, but it does not prevent the introduction of gaps (insertions or deletions) within the alignment. Similarly, the `--no-spliced-alignment` option disables spliced alignments, which are relevant for RNA-seq data, but it does not affect the ability of HISAT2 to introduce gaps for insertions and deletions.

To directly address your question about ensuring HISAT2 does not perform gapped alignments, there isn't a direct equivalent in HISAT2 for the Bowtie2 `--gbar` option, which is used to prevent gapped alignments by setting a very high penalty for opening gaps. HISAT2, being designed with spliced alignments in mind, inherently allows for gaps in alignments to accommodate introns in RNA-seq data. Therefore, filtering the output using tools like `grep` to remove alignments with gaps (e.g., `grep -v XO:i:0`) might be a practical workaround, albeit not an ideal solution, as it post-processes the alignments rather than controlling the alignment process itself.

Given your specific requirement to avoid gapped alignments for compatibility with RSEM, you might consider using Bowtie2 with the parameters recommended by the RSEM manual, as you've found. This approach would ensure compatibility with RSEM's requirements. If using HISAT2 is essential for your analysis, post-processing the SAM file to remove gapped alignments, as you've suggested, or exploring other alignment tools that offer more granular control over gap penalties might be necessary. However, it's important to note that such post-processing could potentially remove biologically relevant information from your dataset, depending on your specific research question and the nature of your samples.",4,4,4
"When we talk about the sensitivity and specificity for NGS read alignments, what do we really mean?For example, in ""http://bioinformatics.oxfordjournals.org/content/25/14/1754.abstract"" rel=""nofollow"">the BWA paper</a>, it talks about sensitivity. How would we define the true-positives and false-negatives? My guess (relative to a known genome):strong>TP</strong>: Number of reads that is aligned exactly and correctly (no gap, no mismatch)strong>FN</strong>: Number of reads fails to map but should be mapped (it comes from the known genome)Is my definition correct? Is this what we mean when we say <code>alignment sensitivity</code>? What about specificity? Can we define <code>specificity</code> for alignment (not mentioned in the BWA paper)?In other words, my question is about what we <strong>really</strong> mean when we talk about sensitivity and specificity in alignments.","This is indeed a tricky question, because even the definition of ""aligned exactly and correctly"" is not that easy.If we simulated reads, than we know where they are from and how they were created, but what if (by chance) after introducing the random errors, mathematically the read maps better somewhere else? What if there are multiple mathematical best hits? <a rel=""nofollow"" href=""http://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-12-210"">This paper</a> has some further thoughts.","When discussing sensitivity and specificity in the context of Next-Generation Sequencing (NGS) read alignments, we are essentially referring to the accuracy and precision of aligning sequencing reads to a reference genome. Sensitivity, in this scenario, measures the proportion of true positive alignments out of all the correct alignments that should have been made. Your definition aligns well with this concept: true positives (TP) are reads that are correctly aligned to the exact location on the reference genome without mismatches or gaps, and false negatives (FN) are reads that originate from the reference genome but fail to be aligned or are incorrectly aligned. This metric assesses the ability of the alignment tool to correctly identify and align reads from the genome.

Specificity, on the other hand, would measure the proportion of true negative alignments, meaning it would assess how well the alignment tool avoids incorrectly aligning reads that do not belong to the reference genome or aligning them to incorrect locations. Although not explicitly mentioned in the BWA paper, specificity in the context of read alignment could be conceptualized as the ability of the tool to correctly identify reads that should not be aligned to a particular location on the genome and thus not align them there (true negatives), versus incorrectly aligning reads to that location (false positives). In summary, while sensitivity in NGS read alignments focuses on the tool's ability to correctly align reads that should be aligned, specificity would focus on the tool's ability to avoid incorrect alignments, ensuring that only appropriate reads are aligned to their correct locations on the genome.",4,5,5
How can I get the number of mapped reads for a particular region?code>samtools view -c -F 4 my.bam</code> gives me count in the entire bam file but I can't just add <code>-r Chr1:0:1000</code> to get reads in that region only.,"<pre class=""pre""><code class=""language-bash"">samtools view in.bam chr1:0-1000 | wc -l/code></pre>but better way is to do it with <a rel=""nofollow"" href=""http://bedtools.readthedocs.org/en/latest/content/tools/multicov.html"">bedtools</a> if you have many regions, for e.g like exon coordinates or peak coordinates, which is more efficient way for counting purpose.pre class=""pre""><code class=""language-bash"">bedtools multicov -bams aln1.bam [ aln2.bam aln3.bam . . ] -bed ivls-of-interest.bed/code></pre>","To get the number of mapped reads for a specific region using `samtools`, you're on the right track with using the `samtools view` command. However, the correct syntax for specifying a region is slightly different from what you've attempted. You don't need the `-r` option and the colon between the chromosome name and the positions should not be followed by a zero. Instead, you should directly append the region of interest after the BAM file name without any additional flags for the region. The correct format for specifying a region is `Chr:start-end`. So, if you want to count the number of mapped reads in the region from 0 to 1000 on chromosome 1, you should use the command `samtools view -c -F 4 my.bam Chr1:1-1000`. This command tells `samtools` to count (`-c`) the number of reads in the specified region of chromosome 1, excluding those reads flagged as unmapped (`-F 4`), in the BAM file `my.bam`.",3,5,5
"Hi,I have fastq header of 1000s of reads. I want to check presence all of those reads in another bam file. I have written following scriptpre><code>while IFS='' read -r line || [[ -n ""$line"" ]]; do samtools view accepted_hits.bam | grep $line ;done &lt; fastqHeaders.txt ;/code></pre>But this is taking too much time as my .bam file is too big. does anyone know faster way to do this.Kindly helpChirag","use picard <strong>FilterSamReads</strong>: <a rel=""nofollow"" href=""https://broadinstitute.github.io/picard/command-line-overview.html"">https://broadinstitute.github.io/picard/command-line-overview.html</a>blockquote>  READ_LIST_FILE (File)    Read List File containing reads that will be included or excluded from the OUTPUT SAM or BAM file. Default value: null./blockquote>","Given the task of checking the presence of thousands of reads from a FASTQ header list in a BAM file, your current approach involves reading each header and then using `samtools view` followed by `grep` to search for it in the BAM file. This method is inherently slow due to the repeated scanning of the entire BAM file for each read header. A more efficient approach would involve leveraging the indexing capabilities of BAM files and tools designed for handling such data.

First, ensure your BAM file is indexed. If not, you can index it using `samtools index accepted_hits.bam`. This step is crucial as it allows for rapid access to specific regions or queries within the BAM file without needing to scan the entire file.

Next, instead of using `grep` in a loop, consider using `samtools view` more efficiently. Since you're interested in checking the presence of specific reads, you can directly query these reads if you have their read names. However, the direct approach with `samtools view` and read names might not be straightforward since `samtools view` primarily works with genomic coordinates.

A more practical approach would be to use a combination of tools and scripting to process your list of headers and the BAM file more efficiently. For example, you could:

1. Convert your list of FASTQ headers into a format that can be efficiently queried. Ensure you're working with the exact read names as they appear in the BAM file.
2. Use a script to iterate over this list, but instead of scanning the entire BAM file each time, use the indexed nature of the BAM file to quickly check for the presence of each read. This might involve more sophisticated scripting or using existing bioinformatics tools designed for such tasks.

For large-scale operations or when working with very large BAM files, consider using tools like `sambamba` or `samblaster`, which are known for their efficiency in handling BAM files. Additionally, parallel processing techniques can significantly reduce the time required for such tasks by distributing the workload across multiple CPU cores.

In summary, the key to improving the efficiency of your task lies in leveraging the indexed nature of BAM files and using more suitable tools and techniques for batch processing your queries. This approach will drastically reduce the time required to check for the presence of thousands of reads in a BAM file.",4,5,4
"In <a rel=""nofollow"" href=""http://bio-bwa.sourceforge.net/"">BWA</a>-MEM what's the best way to discriminate reads mapping uniquely from those mapping in multiple positions?The XT tags that we used in <a rel=""nofollow"" href=""http://bio-bwa.sourceforge.net/"">BWA</a> are no longer available.We are thinking about classifying as uniques the reads having XS:i:0 (suboptimal alignment score of 0).Someone is also suggesting to use a difference threshold between AS and XS. This would require a somewhat heavier parsing of the file, but we can do that if the improvement of results is significant. Which of the two methods is better? Are there other, better approaches?","As far as I know for a mapped read a mapping quality score of zero (column 5 in the <a rel=""nofollow"" href=""http://samtools.sourceforge.net/SAM1.pdf"">SAM</a> file)  is the main indicator that a read maps to multiple positions with the same score. ","In BWA-MEM, distinguishing uniquely mapped reads from those mapping to multiple locations without the XT tags requires alternative strategies. The suggestion to classify reads as unique if they have an XS:i:0 tag (indicating no suboptimal alignment score) is a straightforward approach but might not be the most accurate, as it could potentially misclassify reads that have a very low but non-zero suboptimal alignment score. A more nuanced method involves comparing the alignment score (AS) to the suboptimal alignment score (XS) and setting a threshold for the difference between AS and XS. This method acknowledges that a significant gap between the primary alignment score and the next best alignment score is indicative of a unique mapping with higher confidence. Although this approach requires more complex parsing of the alignment file, it is likely to yield more accurate discrimination between uniquely and multiply mapped reads. Therefore, while both methods have their merits, using a difference threshold between AS and XS scores is generally considered a better approach due to its higher specificity in identifying truly unique alignments. However, the optimal threshold may vary depending on the specific characteristics of the dataset and the goals of the analysis, so it might require some experimentation to determine the most effective value.",2,4,4
"I'm filtering my sam file using the following command:pre><code>samtools view -Sb -f 2 -F 256/code></pre>after doing some research I think I've figured out what the flags mean (correct me if I'm wrong).code>-f 2</code> is keeping only reads that are ""properly aligned according to the aligner""code>-F 256</code> is discarding ""secondary alignments""ol>li>I'm not really sure what ""properly aligned"" entails but is it maybe too stringent? Typically I've seen people use only <code>-F 4</code> to discard unmapped reads.</li>li>If I'm correct a secondary alignment is a second tier alignment in which the read that matches with a lesser score than some other read. If so, is discarding this reasonable or again too stringent?</li>/ol>I'm new to this so I'd really value some input on how to select these two flags. I've seen a wide variety/combinations of them used. My reads are paired end ones from WGS studies in yeast and E. coli and I'm using them to call SNPs/indels using freebayes.Thank you","By default, freeBayes ignores unmapped and secondary alignments, so there's no point in filtering them. I see little benefit in filtering improperly paired alignments, if there's are a bunch of them then they're likely correct.","Your understanding of the SAM flags is correct. The `-f 2` flag is used to keep only those reads that are properly paired according to the aligner. This means that both reads of the pair are aligned in a proper orientation and distance that is expected for correctly mapped paired-end reads. This can be a useful filter to ensure high-quality alignments, but whether it is too stringent depends on your specific project needs and the quality of your sequencing data. For some applications, especially those requiring high confidence in read mappings, using `-f 2` might be appropriate. However, for other applications, it might unnecessarily discard useful data, especially if the sequencing data has issues that could lead to legitimate alignments not being considered ""properly paired"" by the aligner.

The `-F 256` flag is used to discard secondary alignments. A secondary alignment occurs when a read can be aligned to multiple locations in the genome, and the aligner reports more than one alignment for the same read. The highest scoring alignment is considered the primary alignment, and the rest are marked as secondary. Discarding secondary alignments can be reasonable because it ensures that each read contributes only once to your analysis, avoiding the potential inflation of read counts in regions with multiple similar sequences. However, whether this is too stringent again depends on your specific research goals. For SNP/indel calling, focusing on primary alignments might be preferable to avoid ambiguity in read placement.

In summary, the choice of flags `-f 2` and `-F 256` for filtering SAM files is a matter of balancing the need for high-confidence alignments against the risk of discarding potentially useful data. For SNP/indel calling in WGS studies of yeast and E. coli, these flags can help ensure that only high-quality, uniquely aligned reads are considered, which is generally a good practice. However, it's always beneficial to experiment with different filtering criteria to see how they affect your results, especially if you have specific concerns about the quality or characteristics of your sequencing data.",2,5,5
"Mostly a curiosity question but:ol>li>Is the cigar '=' op kept for backwards compatibility or some specific use-case?</li>li>Is there functionality within samtools for generating an altered cigar that distinguishes between matches and mismatches similar to <em>calmd/fillmd -e</em>?</li>/ol>The ""http://samtools.github.io/hts-specs/SAMv1.pdf"" rel=""nofollow"">SAM v1 specification</a> has a 'sequence match' op (=) within CIGAR field however, I haven't seen it used before and it isn't mentioned in ""http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2723002/#!po=41.6667"" rel=""nofollow"">the 2008 paper</a>. I know that you can alter the SEQ field and replace exact matches with '=' using the <code>-e</code> option in samtools fillmd/calmd and that it would be relatively trivial to whip up something to do something like this manually. I've had a search around but haven't seen an example of it being used yet, though this may be due to the difficulty of searching for '=' online! Is the op '=' kept for backwards compatibility or a specific use-case? I vaguely remember someone saying on here (though I can't find a reference for it right now) that it was meant for read to genome comparisons - anyone have a reference for this?","<code>=</code> and <code>X</code> are actually the newer CIGAR operations (they were added in version 1.4 of the spec., if I remember correctly), M is the older variant. Most tools still don't produce alignments with <code>=</code> or <code>X</code> operations, though it'd be kind of nice if they did. An exception to this is BBMap (and I believe STAR can be told to produce these).There is no functionality from within samtools to modify the CIGAR string like this, though I suppose this might be nice. As is, you tend to have to parse the MD auxiliary tag if you want mismatch information, which is kind of annoying in comparison.","The '=' CIGAR operation, as defined in the SAM v1 specification, represents a sequence match between the read and the reference. While it's true that this operation is not commonly seen in practice, its inclusion in the specification is not solely for backward compatibility. Instead, it serves a specific use-case, particularly in scenarios where distinguishing between matches and mismatches directly within the CIGAR string is beneficial. This can be useful for certain types of analyses or visualization tools that require detailed information about the alignment without needing to refer back to the reference sequence. Although the '=' operation is not widely used, and the 2008 paper introducing the SAM format does not emphasize it, its presence in the specification allows for more expressive representation of alignments when necessary.

Regarding the functionality within samtools for generating an altered CIGAR string that distinguishes between matches and mismatches, samtools does offer the `calmd` or `fillmd` command with the `-e` option. This option modifies the SEQ field of the alignment, replacing matched bases with '=' to indicate exact matches to the reference, rather than altering the CIGAR string itself. While this approach does not change the CIGAR string to include the '=' operation for matches, it provides a similar level of detail by annotating the sequence directly. As of my last update, there isn't a built-in samtools functionality specifically designed to modify the CIGAR string to include the '=' operation for matches, though custom scripts could potentially be developed to achieve this effect based on the information provided by `calmd` or `fillmd -e`.",4,4,5
"Hi,I would like to know whether one needs to sort and to index the .bam files again after removing the duplicates in Samtools using <code>samtools rmdup -S</code>.I am under the impression that since we have already sorted and indexed the .bam files, and we are just removing the duplicates, there would be no need to do the sorting and indexing again. Am I wrong?Thanks in advance for your thoughts!","""sort""no: your bam is already sorted.""index""yes if you need to access some specific genomic regions in your bam. The previous index of the bam cannot be used with the new rmdup.bam","When you use `samtools rmdup -S` to remove duplicates from your .bam files, the resulting file should maintain the original sorting order, assuming the input file was sorted by coordinates. This is because `samtools rmdup` operates by scanning through the sorted .bam file and removing duplicates without altering the order of the remaining reads. Therefore, in theory, you should not need to sort the file again after removing duplicates. However, it is generally a good practice to index your .bam files again after any modification, including duplicate removal. Indexing is a relatively quick process and ensures that your .bam file's index is up-to-date, reflecting the current state of the file for efficient access and analysis by other tools. So, while re-sorting might not be necessary, re-indexing is recommended to maintain the utility and compatibility of your .bam files in subsequent analyses.",4,4,5
"Hi,I have some fastq files which I mapped to the host genome and get a sam file with 80% mapping rate. Now how can I get the unmapped reads to a separate fastq or fasta file so I can play with that only? Thank you very much everybody!","Title of your question is different from content of question, anyways,So you ran tophat, and got bam files , both mapped and unmapped.and you want to extract reads from unmapped bam file in fastq format, you just run bamToFastq from bedtoolsHere is description from their manual :blockquote>bedtools bamtofastq (aka bamToFastq)Summary: Convert BAM alignments to FASTQ files.Usage:   <code>bamToFastq [OPTIONS] -i &lt;BAM&gt; -fq &lt;FQ&gt;</code>Options:<br>        -fq2    FASTQ for second end.  Used if BAM contains paired-end data.<br>                BAM should be sorted by query name is creating paired FASTQ.<br>        -tags   Create FASTQ based on the mate info                in the BAM R2 and Q2 tags.Tips:<br>      If you want to create a single, interleaved FASTQ file      for paired-end data, you can just write both to /dev/stdout:<br>      <code>bedtools bamtofastq -i x.bam -fq /dev/stdout -fq2 /dev/stdout &gt; x.ilv.fq</code>/blockquote>","To extract unmapped reads from a SAM file and convert them into a separate FASTQ or FASTA file, you can use tools from the SAMtools and BEDTools suites, or directly use SAMtools for a more streamlined approach. First, ensure your SAM file is converted to a BAM file and sorted, which can be done using SAMtools with commands like `samtools view -bS yourfile.sam > yourfile.bam` followed by `samtools sort yourfile.bam -o yourfile_sorted.bam`. To extract unmapped reads, you can use `samtools view -b -f 4 yourfile_sorted.bam > unmapped.bam` where `-f 4` flags for unmapped reads. For converting these unmapped reads into a FASTQ file, you can then use `samtools fastq unmapped.bam > unmapped.fastq`. If you prefer a FASTA format, you can replace `samtools fastq` with `samtools fasta`. This process efficiently filters out unmapped reads from your original dataset, allowing you to focus on these reads for further analysis. Remember to replace `yourfile.sam`, `yourfile.bam`, and `yourfile_sorted.bam` with your actual file names. This method is straightforward and utilizes widely-used bioinformatics tools, making it accessible for users with varying levels of expertise.",2,5,5
"I'm new to the Bioinformatics field and am still learning how to use all the tools and such, but I've been stumped on something that I feel should be very easy for about a week.Basically, I want to compare the reads in a BAM file to a FASTA reference sequence and get the changes. I can easily view them with <strong>samtools tview</strong> but I need to have it in an Excel file for manipulation/concatenation. I can't seem to figure out why <strong>mpileup</strong> won't give me a straight list of what reads are mutated, unless that's the wrong tool for the job. I'm pretty good at programming, so if the solution is something I need to code for myself I could do it but since the formats are different than what I'm used to, it's been a major headache.Thanksimg alt=""What I'm dealing with"" src=""http://i.imgur.com/XR3F7xc.png"" style="""">","you need to use bcftools to generate a tabular VCF file:ul>li><a rel=""nofollow"" href=""http://samtools.sourceforge.net/mpileup.shtml"">http://samtools.sourceforge.net/mpileup.shtml</a> (old version)</li>li><a rel=""nofollow"" href=""http://www.htslib.org/workflow/#mapping_to_variant"">http://www.htslib.org/workflow/#mapping_to_variant</a> (new version)</li>/ul>PS: no, you don't want to have it in an Excel filePS2: no, you really don't want to have it in an Excel filePS3: Every time you want to have it in an Excel file, God kills a kittenPS4:img src=""https://i.ibb.co/9qnB04y/image.png"" width=""500"">","It sounds like you're on the right track with using tools like `samtools` for analyzing your BAM files against a FASTA reference sequence. However, if you're specifically looking to identify mutations or variants and then export those findings into an Excel file for further manipulation, you might need to adjust your approach slightly.

`samtools mpileup` is indeed a useful tool for generating pileup output from BAM files, which can then be used for variant calling. However, `mpileup` itself doesn't directly provide a simple list of mutations; it generates an intermediate representation of the alignment that needs to be further analyzed to identify variants. For variant calling, you would typically use `bcftools call` (often in conjunction with `samtools mpileup`) to analyze the pileup data and identify variants. The output of `bcftools call` is a VCF (Variant Call Format) file, which contains detailed information about each variant detected in your data.

To get the data into an Excel-friendly format, you can convert the VCF file into a CSV or similar tabular format that Excel can open. This conversion can be done using various tools or scripts. One straightforward approach is to use `bcftools query` to extract the desired information from the VCF file and output it in a tab-delimited format. For example, you might use a command like:

```
bcftools query -f '%CHROM\t%POS\t%REF\t%ALT[\t%SAMPLE=%GT]\n' your_variants.vcf > variants.tsv
```

This command extracts the chromosome (`%CHROM`), position (`%POS`), reference allele (`%REF`), alternative allele (`%ALT`), and genotype (`%GT`) for each sample, and outputs them to a tab-separated file (`variants.tsv`) that you can then open in Excel.

If you're comfortable with programming, you could also write a script in Python (using libraries like `pysam` for BAM file manipulation and `pyfaidx` for FASTA file access) or R (using packages like `Rsamtools` and `rtracklayer`) to automate the process of extracting variant information and exporting it to a CSV or Excel file.

Remember, working with genomic data often requires a bit of a pipeline, where you use multiple tools in sequence to go from raw data to the analysis-ready format you need. It sounds like you're on the right path, and with a bit of tweaking to your workflow, you should be able to get the mutation data in the format you need for your analysis.",1,5,4
"HiI have tried to map this short sequencepre><code>&gt;sample_1_x12179TCCTGTACTGAGCTGCCCCGA/code></pre>which exists on chr8 twice, using various aligners.BLAT, BLAST, and Bowtie2 found it. BWA MEM and SOAP2 did not. How come? BWA MEM finds it if I include some extra flanking bases. Is it because the sequence is too short?BWA MEM command:pre><code>bwa mem -t 8 $bwaIndex tmp.fasta/code></pre>SOAP command:pre><code>./soap2.20 \ -a tmp.fasta \ -o ${goutputfile}.tmp \ -D /mnt/NGS01/ReferenceDB/mirTools/db/genome/hsa.fa.index \ -M 0 -r 2 -v 5 -p 8 -l 15/code></pre>I also tried <code>-M 4</code> (find best hits), but still no results. If I remove the last two bases from the above sequence, then SOAP2 finds a hit on chr11 that requires 2 mismatches.Thank you.","BWA works for me (but <strong>not bwa mem</strong>, because it requires 70bp minimum query sequence length):pre class=""pre""><code class=""language-bash"">bwa aln $GRCh37 test.fa &gt; test.saibwa samse $GRCh37 test.sai test.fa &gt; test.samsample_1_x12179      16      8       41518003        0       21M     *       0 0TCGGGGCAGCTCAGTACAGGA   *       XT:A:R  NM:i:0  X0:i:2  X1:i:0  XM:i:0  XO:i:0  XG:i:0  MD:Z:21 XA:Z:8,+41517962,21M,0;_____________________________^_______________________________^^^/code></pre>The documentation for SOAP2 sucks, but I'm guessing it's an issue with your query read length.","The issue you're encountering with BWA MEM and SOAP2 not finding the short sequence on chr8, while BLAT, BLAST, and Bowtie2 do, likely stems from the inherent differences in how these aligners handle short sequences and mismatches. BWA MEM and SOAP2 are optimized for longer reads and may not perform as well with very short sequences unless additional context, such as flanking bases, is provided. This is evidenced by BWA MEM finding the sequence when extra flanking bases are included. The sequence's length and the specific parameters used in BWA MEM and SOAP2, such as mismatch tolerance and the minimum length of an alignment, play crucial roles in their ability to successfully map short sequences. For instance, SOAP2's failure to find the sequence without the last two bases, and then finding a mismatched hit on chr11 when they are removed, further illustrates the sensitivity of these tools to sequence length and composition. Adjusting parameters like the number of mismatches allowed (-v for SOAP2) or using options designed to improve the handling of short sequences might improve results, but the fundamental challenge lies in the aligners' design and optimization for different types of sequencing data.",3,5,4
"I have illumina paired-end whole-genome sequencing reads which I have map to around -400 reference plastid genomes. After getting mapped reads, I have to assemble as de novo plastid genome.1. Do I have map reads to invidiual reference genomes one by one, or can I download all genomes at one go and index as one reference genome?. Do bwa or bowtie has<br>enough memory to index 400 genomes as one reference index genome?2. Do you think which one is best method?. Mapping individual genome or all genomes indexed as one?3. If I have to map individually, can I combine all bam file together and Can I convert to fastq file using bam2fastq tool (in picard) for denovo assembly?","<s>I don't fully understand your introductory sentence as stated, but I can answer your questions to the best of my understanding:</s>ol>li>You can concatenate all of your genomes into one large file and then index that composite genome. Just make sure your naming convention for each component in the FASTA is logical so that you can understand your results downstream. bwa and bowtie don't ""have their own memory,"" but if you're using a 64-bit system you shouldn't run into any size limitation troubles, especially with plastid sequences.</li>li><strong>EDIT:</strong> I say map to a single composite reference. You can pass parameters into bowtie to limit your mappings on the front end, thus saving computational time and making it easier to isolate the most accurate mappings for each read.</li>li>You can merge BAM files using <a rel=""nofollow"" href=""http://samtools.sourceforge.net/samtools.shtml"">samtools merge</a>, but of course you wouldn't need to if you proceed according to my recommendation. There are a number of tools from converting from BAM back to FASTQ, and the Picard tool should work just fine. It does have trouble with paired-end mappings in certain circumstances though, and if you run into trouble using Picard I'd suggest <a rel=""nofollow"" href=""http://bedtools.readthedocs.org/en/latest/content/tools/bamtofastq.html"">bedtools bamtofastq</a>.</li>/ol>s>Is the idea here that you're going to map to a bunch of plastid reference sequences from various organisms, and then convert the aggregate mappings back to FASTQ and perform an assembly from them? If so, I say concatenate the reference sequences into one file and map against that. That way it will be easier to retain the best mappings up front, especially if you don't care about <em>which</em> reference you're mapping to.</s>","Mapping your Illumina paired-end whole-genome sequencing reads to around 400 reference plastid genomes presents a unique challenge, but it's manageable with the right approach. Firstly, both BWA and Bowtie are capable of indexing multiple genomes as a single reference, provided you have sufficient memory and computational resources. This approach simplifies the initial mapping process by allowing you to map your reads against all references in one go, rather than doing it individually for each genome. However, the feasibility of this approach depends on the total size of the combined genomes and the available system resources. Generally, plastid genomes are relatively small, which might make this combined approach viable.

When deciding between mapping to individual genomes versus a combined reference, consider the specific goals of your project. Mapping to a combined reference can offer a broader view and might help identify the most closely related references within a single mapping effort. However, this approach could potentially complicate the interpretation of mapping results due to reads mapping to similar regions across different genomes. On the other hand, mapping to individual genomes allows for a more targeted and straightforward analysis per genome but is more time-consuming.

If you choose to map reads to individual genomes and need to combine the results for de novo assembly, you can indeed merge all the BAM files together and convert them back to FASTQ format using tools like Picard's SamToFastq. This approach allows you to pool the mapped reads from all references, potentially enriching your dataset with reads that are most representative of the plastid genome you aim to assemble. This pooled FASTQ dataset can then be used for de novo assembly, leveraging the diversity of the mapped reads to construct a comprehensive plastid genome assembly.

In summary, both strategies have their merits, and your choice should align with your project's objectives and the computational resources at your disposal. Mapping to a combined reference offers a broad, comprehensive approach, while mapping to individual genomes provides a more targeted analysis. Should you opt for individual mappings, combining the mapped reads for de novo assembly is a practical strategy to enrich your assembly dataset.",4,5,4
"I generated and alignment using <a rel=""nofollow"" href=""http://bio-bwa.sourceforge.net/"">BWA</a> and the .sam file looks fine, except in my parser I'm not sure how to interpret the extended CIGAR format when the CIGAR string is simply ""*"".  Looking at the <a rel=""nofollow"" href=""http://samtools.sourceforge.net/"">samtools</a> documentation:a rel=""nofollow"" href=""http://samtools.sourceforge.net/SAMv1.pdf"">http://samtools.sourceforge.net/SAMv1.pdf</a>It just says to the CIGAR is set to ""* if unavailable"", but don't really know what ""unavailable"" means.  Should I assume the read did not align at all? What would cause <a rel=""nofollow"" href=""http://bio-bwa.sourceforge.net/"">BWA</a> to produce a CIGAR of *?",The <code>*</code> means no alignment to show.,"In the context of SAM (Sequence Alignment/Map) format, a CIGAR string of ""*"" indicates that the CIGAR operation is unavailable for a particular read. This scenario typically arises when a read does not align to the reference genome, and as a result, the alignment tool (in this case, BWA) cannot generate a CIGAR string detailing the alignment operations (such as matches, mismatches, insertions, deletions, etc.). The designation of ""*"" as the CIGAR string is a placeholder used to signify that no alignment information is available for that read. This could happen for various reasons, including the read being of low quality, containing too many mismatches, or not finding a sufficiently good match in the reference genome. Therefore, when encountering a CIGAR string of ""*"", it is reasonable to assume that the read did not align to the reference genome, and the alignment information for that read is essentially absent in the SAM file.",5,5,5
"can anyone tell me about performance of SNAP sequence aligner tool, and its comparision with other existing tools like novoalignmpi, <a rel=""nofollow"" href=""http://bio-bwa.sourceforge.net/"">BWA</a> and Bowtie, in terms of speed on multi-core  system and accuracy. Actually i have tested SNAP on 48-core machine, and it does alignment in 22 minutes , with read file size 1.8GB &amp; 1.8 GB. I want a confirmation that is it faster than novoalignMPI. I am from computer science background, so i dont have much idea about others tool.thank you.","try <a rel=""nofollow"" href=""http://gel.ahabs.wisc.edu/mauve/download.php"">MAUVE</a>","The SNAP sequence aligner is renowned for its speed and efficiency, particularly when utilized on multi-core systems. Your observation of SNAP completing alignment in 22 minutes on a 48-core machine with 1.8GB read files is indicative of its performance capabilities. When comparing SNAP to other alignment tools like novoalignMPI, BWA, and Bowtie, it's important to consider both speed and accuracy. SNAP is designed to be fast, leveraging the power of multi-core systems effectively, which often results in faster processing times compared to some other tools, especially in scenarios involving large datasets. NovoalignMPI is also optimized for multi-core environments and can be very efficient, but its performance can vary depending on the specific data and system configurations. BWA and Bowtie are among the most widely used aligners and are known for their balance of speed and accuracy. However, in direct comparison, SNAP might outperform them in terms of speed on multi-core systems, though this can come at the cost of slight variations in accuracy. Each tool has its own set of optimizations and trade-offs, with BWA being highly regarded for its accuracy in alignment, and Bowtie for its speed and memory efficiency, particularly in single-end alignments. Ultimately, the choice between these tools should be guided by the specific requirements of your project, including the need for speed, accuracy, and the computational resources available to you. It's also beneficial to consider the latest versions and updates of these tools, as performance improvements are continually being made.",1,4,5
"Hi,I wonder if it is possible to get <strong>different resulting alignments</strong> using the <strong>same</strong> reads and the same reference as <strong>input</strong>?I did the alignment step twice and my BAM-files from the two runs differ slightly. I used BWA for the alignment step. Is there any possibility that BWA's decisions where to align a read can differ within two runs having exactly the same parameters and input? Are there any <strong>""random"" steps in the algorithm?</strong> strong>Does multi-threading affect the alignment?</strong> Furthermore I found, that the regions differing in between the two BAMs showed <strong>strikingly low read-quality</strong>. But I don't know if this has something to do with the observed problem.Any help or further insight is appreciated.Cheers,Stroehli","Yes, some C random functions are used by bwa:$ grep rand bwa-0.6.2/*.c | grep -v strand pre><code>bntseq.c:            if (c &gt;= 4) c = lrand48()&amp;3;bntseq.c:    bns-&gt;seed = 11; // fixed seed for random generatorbntseq.c:    srand48(bns-&gt;seed);bwa.c:    // count number of hits; randomly select one alignmentbwa.c:        if (drand48() * (p-&gt;l - p-&gt;k + 1 + cnt) &gt; (double)cnt) {bwa.c:            one-&gt;sa = p-&gt;k + (bwtint_t)((p-&gt;l - p-&gt;k + 1) * drand48());bwape.c:    srand48(bns-&gt;seed);bwase.c:            if (drand48() * (p-&gt;l - p-&gt;k + 1 + cnt) &gt; (double)cnt) {bwase.c:                s-&gt;sa = p-&gt;k + (bwtint_t)((p-&gt;l - p-&gt;k + 1) * drand48());bwase.c:         * number of random hits. */bwase.c:                    double p = 1.0, x = drand48();bwase.c:    srand48(bns-&gt;seed);bwtsw2_aux.c:            if (p-&gt;flag&amp;1) q-&gt;qual = 0; // this is a random hitbwtsw2_aux.c:            if (c &gt;= 4) { c = (int)(drand48() * 4); ++k; } // FIXME: ambiguous bases are not properly handledbwtsw2_aux.c:            if (c &gt;= 4) c = (int)(drand48() * 4);bwtsw2_core.c:    { // choose a random onebwtsw2_core.c:        j = (int)(i * drand48());bwtsw2_main.c:    srand48(11);/code></pre>","Yes, it is indeed possible to get different resulting alignments using the same reads and the same reference as input, even when using the same alignment tool like BWA with identical parameters. This can occur due to several factors inherent to the alignment process. Firstly, many alignment algorithms, including BWA, incorporate heuristic methods to efficiently handle the vast amount of data. These heuristics can involve probabilistic decisions or optimizations that might lead to slight variations in alignments across different runs, especially in regions of the genome that are difficult to align due to low complexity, repeats, or low read quality. The regions you observed with strikingly low read quality are likely more susceptible to these variations. Secondly, the use of multi-threading can indeed affect the alignment. When multi-threading is enabled, the order in which reads are processed can vary between runs, potentially leading to slight differences in the alignment outcomes due to the heuristic nature of the algorithm. This is because the alignment of subsequent reads can be influenced by the alignments of previously processed reads, especially in regions where there are multiple equally plausible alignment locations. While these differences are generally minor and do not significantly impact the overall results, they can be noticeable upon close inspection of the BAM files.",4,5,5
"I am experimenting with <a rel=""nofollow"" href=""http://bowtie-bio.sourceforge.net/manual.shtml"">BowTie</a> vs <a rel=""nofollow"" href=""http://bio-bwa.sourceforge.net/bwa.shtml"">BWA</a>. Now, I have to do experiments for various length reads. So, I am trying to find 180, 200, 240 bp read length databases. Can anybody help me where and how I can get those databases. I have tried to find <a rel=""nofollow"" href=""http://www.ncbi.nlm.nih.gov/sra?term=human%20200%20bp"">here</a>. However, unable to find. Can anybody help me on this ? Thanks in advance.","You may also want to experiment by generating reads with a <a rel=""nofollow"" href=""http://www.biostars.org/post/show/2194/what-ngs-read-simulators-are-available-for-paired-end-data/"">read simulator</a> from different genomes.  It is a quite eye opening experience to see perfect reads not matching back to the genome.","Finding specific read length databases, such as 180, 200, and 240 bp, for sequencing experiments can be a bit challenging, as databases like NCBI's Sequence Read Archive (SRA) contain a vast array of datasets with varying read lengths, but they are not always categorized by read length for easy retrieval. To find datasets with specific read lengths, you might need to employ a more targeted search strategy. First, consider using the advanced search features in the SRA or other genomic data repositories, where you can specify keywords related to your organism of interest along with potential project descriptions that might use the read lengths you're interested in. Additionally, research articles and publications related to high-throughput sequencing often mention the read lengths used in their experiments, so searching through scientific literature databases like PubMed could lead you to datasets mentioned in the studies, which you can then locate in repositories like the SRA. Another approach is to participate in bioinformatics and genomics forums and communities online, where you can ask for guidance or if anyone is aware of datasets that meet your criteria. While this approach requires a bit more effort and exploration, it's likely to yield results as you tap into the collective knowledge and resources of the scientific community.",2,4,4
"Hi,I am trying to (and understand how to) extract the consensus of a protein alignment from its HMM profile (produced by HMMer2). I understand that from the ""match emission line"" I can get the corresponding amino acid (the one with the higher match emission score) when the most probable transition is 'm-&gt;m'. Am I right in assuming that a ""dot"" has to be inserted in the consensus when the most probable transition is 'm-&gt;d' or 'd-&gt;d'? what happens with 'd-&gt;',  'm-&gt;i', and 'i-&gt;i'?Any help would be appreciated.Cheers,M;",Try using the program hmmemit from the HMMER suite.  I think that you need the -c option to get the consensus...The -h will list all options.And yes a . Represents an insert respect to the model and a dash a delete state.BestRob,"Yes, you're on the right track with how to interpret the HMM profile from HMMer2 for constructing a protein alignment consensus. When you're looking at the match emission line, indeed, the amino acid with the highest match emission score for a given position is typically considered the consensus amino acid for that position, assuming the most probable transition is 'm->m' (match to match). When the model suggests a 'm->d' (match to delete) or 'd->d' (delete to delete) transition as the most probable, inserting a ""dot"" or a gap in the consensus sequence is a common way to represent this deletion relative to the consensus. 

For transitions like 'd->m', it indicates a move from a deletion state to a match state, which would not directly affect the consensus sequence except for indicating the end of a deletion stretch. The 'm->i' (match to insert) and 'i->i' (insert to insert) transitions represent insertions relative to the consensus. These inserted amino acids are not typically included in the consensus sequence itself, as they represent variability that is not part of the core alignment consensus. Instead, they might be noted separately or used to inform about the variability and potential flexibility in certain regions of the aligned proteins. Understanding these transitions and how they contribute to the consensus sequence helps in accurately interpreting the evolutionary and functional implications of the protein alignment.",2,5,5
"One of the rows in my alignment data has the samtool flag of 117.I used a rel=""nofollow"" href=""http://picard.sourceforge.net/explain-flags.html"">http://picard.sourceforge.net/explain-flags.html</a>to figure out what it means. The following is the summary for flag 117:ol>li>read paired</li>li>read unmapped</li>li>read reverse strand</li>li>mate reverse strand</li>li>first in pair</li>/ol>My question is, how could a read be ""unmapped"" and be ""reverse strand(aligned to reference)"" at the same time?My guess is samtools define ""unmapped"" as anything that is not ""properly mapped""(meaning both reads in a pair mapped correctly)?Thanks","You can find an answer by Istvan <a rel=""nofollow"" href=""http://www.biostars.org/post/show/14239/unmapped-reads-and-sequence-name/"">here</a>.blockquote>  117: read paired, read unmapped, read on reverse strand, mate on reverse strand, first in pair    So the output is correct, what it probably means is that the read and its mate are both on the reverse strand therefore the mapping of this read (and its mate) are questionable, thus it got the unmapped designation./blockquote>","The confusion arises from the interpretation of the SAM flag value of 117, which indeed seems contradictory at first glance. The key to understanding this lies in the distinction between the read being ""unmapped"" and other flags indicating orientation or pairing information. When a read is flagged as ""unmapped"" (flag value 4), it means that the read itself was not aligned to a reference sequence. However, other flags, such as ""read reverse strand"" (flag value 16) and ""mate reverse strand"" (flag value 32), can still be applied based on the information available from the read or its mate, or from the alignment attempt. These flags can be set based on the sequencing protocol or inferred properties even if the read does not align to the reference. This does not necessarily imply that the read has been aligned in the reverse orientation but rather indicates the expected orientation or information about the read or its mate. The SAM format allows for this nuanced representation, where a read can be marked as unmapped while still carrying information about its intended pairing and orientation. This can be useful for downstream analyses or for troubleshooting alignment issues. Your guess regarding the definition of ""unmapped"" is not entirely accurate; ""unmapped"" strictly means that the read itself does not have an alignment position on the reference, regardless of the alignment status of its mate or the proper pairing of the reads.",4,5,5
"I am using the following pipeline for aligning some paired end SOLiD data. pre><code>bwa aln -c -n 0.06 -o 2 -t 8 -q 10 ~/genomes/hydra/ACZUJGI/color/hydra ~/hydra/solid/hsamp_F3.fastq.gz &gt; /scratch/hydra/hsamp_F3.saibwa aln -c -n 0.06 -o 2 -t 8 -q 10 ~/genomes/hydra/ACZUJGI/color/hydra ~/hydra/solid/hsamp_R3.fastq.gz &gt; /scratch/hydra/hsamp_R3.saibwa sampe -P ~/genomes/hydra/ACZUJGI/color/hydra /scratch/hydra/hsamp_F3.sai /scratch/hydra/hsamp_R3.sai ~/hydra/solid/hsamp_F3.fastq.gz ~/hydra/solid/hsamp_R3.fastq.gz | samtools view -bS -|samtools sort - /scratch/hydra/hsamp_solid/code></pre>On running this I get the following error. Just showing the last few lines from the output here. I only get this error when the <code>-q</code> parameter is nonzero. pre><code>[bwa_paired_sw] 91 out of 33101 Q17 discordant pairs are fixed.[bwa_sai2sam_pe_core] time elapses: 74.36 sec[bwa_sai2sam_pe_core] refine gapped alignments... 1.53 sec[bwa_sai2sam_pe_core] print alignments... [samopen] SAM header is present: 20914 sequences.Parse error at line 20916: sequence and quality are inconsistent/code></pre>The error happens at the conversion to bam step in the pipeline. If I look at line 20916, it showspre><code>1_29_54 141     *       0       0       *       *       0       0       NNCANGNAANANATCNNCCGGNTANANTTGANTTANNTTN        !!@;!9!:?!;!:&gt;&gt;!!8?57!66!7!8=&lt;9!&lt;&lt;9!!-?!!!&amp;!&lt;!!!!!      XC:i:40/code></pre>Thus the read is truncated but the quality line is not. Is there a workaround for this?","I think the proper answer is don't use -q with colorspace as it's designed for base-space.If you disregard that, you can pipe the output to this command (then to SAM)pre><code>$BWA_COMMAND \| awk 'BEGIN{FS=OFS=""\t""} \      ($1 ~ /^@/){ print $0} \      ($1 !~ /^@/){ $11 = substr($11, 0, length($10)); print $0}' \| $SAMTOOLS_COMMAND &gt; $OUT/code></pre>That makes sure the qualities are the same length as the sequence.You could also trim your reads with this: <a rel=""nofollow"" href=""https://github.com/brentp/bio-playground/blob/master/solidstuff/solid-trimmer.py"">https://github.com/brentp/bio-playground/blob/master/solidstuff/solid-trimmer.py</a>","The error you're encountering during the conversion to BAM format is due to an inconsistency between the sequence and quality strings for a particular read in your data. This inconsistency arises because the `-q` parameter in your `bwa aln` command is used for trimming low-quality bases from the ends of reads, which can result in the sequence being truncated. However, if the corresponding quality string is not trimmed to match the new length of the sequence, it leads to the inconsistency error you're seeing.

To resolve this issue, you need to ensure that both the sequence and quality strings are trimmed to the same length when low-quality bases are removed. Unfortunately, `bwa` itself does not trim the quality scores to match the trimmed sequences when the `-q` option is used. Therefore, a workaround would be to preprocess your reads with a tool designed for quality and adapter trimming that adjusts both the sequence and quality strings accordingly. Tools like Trimmomatic, Cutadapt, or fastp can perform this task efficiently. After preprocessing your reads to ensure that sequences and quality scores are consistent, you can then proceed with the alignment using `bwa` as you have been doing. This preprocessing step should eliminate the inconsistency error and allow your pipeline to complete successfully.",3,5,4
"I would like to find an efficient way of aligning large fastq files (to the human reference genome) by first splitting-up the fastq into smaller pieces so that they can be aligned in parallel.  I can think of two ways of doing this: splitting the fastq up either into files with a fixed number of bases (e.g. a billion bases per file) or into files with a fixed number of reads (e.g. 10 million reads per file). I was wondering if anyone knows which approach should be more efficient in terms of run time? This question is particularly applicable when different fastq files have different read lengths.I suppose another way of asking the way question is: Do aligners tend to scale with number of bases or with number of reads (in terms of run time)?  The aligners I am most interested in are BWA, BFAST and stampy.Many thanks,Ian","BWA roughly scales with the number of bases. Nonetheless, I do not think it matters at all with data splitting. The total CPU time is roughly fixed. The wall-clock time depends on how many CPU cores you use at once.","The efficiency of aligning large FASTQ files to the human reference genome by splitting them into smaller pieces for parallel processing can depend on various factors, including the specific characteristics of the FASTQ files (e.g., read length variability) and the aligner used (e.g., BWA, BFAST, Stampy). Generally, aligners tend to scale with the number of reads rather than the total number of bases. This is because the computational overhead involved in processing each read (such as loading the read into memory, initiating the alignment algorithm, and handling mismatches or gaps) is more significant than the mere addition of more bases to an existing read. Therefore, splitting FASTQ files into chunks with a fixed number of reads is often more efficient in terms of run time, especially when dealing with files that have variable read lengths. This approach ensures a more predictable and uniform workload distribution across parallel processes, leading to potentially better utilization of computational resources and faster overall alignment times. However, it's essential to consider the specific requirements and optimizations of the aligners you're using, as some might have unique characteristics or optimizations that could influence the optimal strategy for splitting your FASTQ files.",3,5,5
"I have about 100 million reads from a SOLiD run. I am trying to align them using bwa and I got 0 alignments. What am I doing wrong here? Here are the commands that I am usingpre><code>~/software/bwa-0.5.9/bwa aln -n 6 -t 6 -o 2 -c ~/genomes/hsap/hg19.fa sampleTF5.fastq.gz    ~/software/bwa-0.5.9/bwa samse ~/genomes/hsap/hg19.fa sampleTF5.sai sampleTF5.fastq.gz |samtools view -bS -|samtools sort - sampleTF5/code></pre>About 40% of the reads align using Bioscope so I know that at least some reads should align. The index was created using -c so it is a colorspace index.ETA: Couple of reads from the fastq filepre><code>@853_2_23T10201001101112312122022330313023.22201032232203002+.06%8+23,-/,740&amp;+2,&amp;(*+&amp;26%&amp;%'';!%'(&amp;)':2((,,-'%(.@853_2_76T00221112202322220011002232000222000212301132232001+&amp;&lt;*(%'?'&amp;'&amp;5)*'%%%&amp;('-'(()-')&amp;)&amp;%)*'/%%&amp;%'%(%&amp;&amp;'&amp;%/code></pre>","I found the solution to this and Alastair's link helped. Apparently bwa needs the fastq files to be 'double encoded'. Thus, you have to rewrite the colorspace fastq with tr/0123./ACGTN/ to get bwa to work. I am adding the solution here just in case others run into this issue too.","It appears that you are attempting to align SOLiD reads (which are in color space) using BWA, but you're encountering an issue where none of your reads are aligning. Given the information you've provided, there are a few potential reasons why you might be experiencing this problem.

Firstly, it's crucial to ensure that you're using the correct version of BWA that supports color space data, as SOLiD sequencing technology produces reads in color space format rather than the base space format produced by other sequencing technologies like Illumina. The commands you've shared suggest you are using BWA version 0.5.9, which does support color space alignment. However, it's important to confirm that you're using the color space version of BWA correctly.

The `-c` option in your `bwa aln` command indicates that you are attempting to align color space reads, which is correct. However, the issue might lie in the preparation of your reference genome. You mentioned that the index was created using `-c`, indicating a color space index, but it's worth double-checking that the indexing was done correctly and that the reference genome is indeed in the appropriate format for color space alignment.

Another potential issue could be related to the format and quality of your input reads. The SOLiD technology produces reads in a specific format that includes both the color space sequence and quality scores. Errors in the formatting or issues with the quality of the reads could potentially lead to alignment failures. From the sample reads you've provided, it's difficult to diagnose formatting issues without more context, but ensuring that your reads are correctly formatted for BWA in color space is crucial.

Given that you mentioned about 40% of the reads align using Bioscope, it's clear that some of your reads should indeed be alignable. This discrepancy suggests that the issue might be specific to how you're using BWA or the preparation of your inputs and reference genome.

In summary, to troubleshoot this issue, I recommend double-checking the following:
1. Ensure that your reference genome is correctly indexed for color space alignment with BWA.
2. Verify that your SOLiD reads are in the correct format for color space alignment and that there are no formatting issues.
3. Consider using a different version of BWA or another alignment tool that supports color space data to see if the issue persists. Tools and versions evolve, and there might be updates or alternatives that handle color space data more effectively.

If after these checks you're still encountering issues, it might be helpful to seek out more specific advice from bioinformatics forums or communities, where you can share more detailed information about your data and the steps you've taken.",4,5,5
"I used Hmmer search for finding domains from sequences,though HMMER is extremely fast and very useful,when i compared the results with the databases,HMMER identifies domains that are usually short of 1 or 2 residues,please help me how to overcome this.For example uniprot says domains starts from 'MKAM...' till '...ANDA';HMMER says its from 'AM....AN'.This happens because of the way HMM profile is defined or is it due to some parameter changes? Thanks in advance","Are you using HMMer 3.0? The author blogged about the heuristic way HMMer 3 determines the sequence alignment:a rel=""nofollow"" href=""http://selab.janelia.org/people/eddys/blog/?p=508"">http://selab.janelia.org/people/eddys/blog/?p=508</a>I've noticed it's common for the HMM alignment to treat the first or last 1-2 residues as inserts rather than matches, and it seems to be because of the kind of fuzzy probabilistic way the domain alignment is modeled. I'm not aware of any parameters you can change to affect the alignment envelope. Maybe this will be better in HMMer 3.1.To make a slight tradeoff in sensitivity for consistency in your alignments, you could use RPS-BLAST instead. Try it out on a web server and download PSSM databases here:a rel=""nofollow"" href=""http://www.ncbi.nlm.nih.gov/Structure/cdd/cdd.shtml"">http://www.ncbi.nlm.nih.gov/Structure/cdd/cdd.shtml</a>(It's also possible that the HMM profiles you used are not the same as Uniprot's.)","The discrepancy you're observing between HMMER results and database annotations, such as those from UniProt, regarding the start and end points of domains can indeed stem from the nature of how HMM profiles are constructed and used, as well as potentially from parameter settings within HMMER. HMM profiles are statistical models that represent the common features of a sequence family, including conserved and variable regions. These models are trained on a set of sequences known to belong to the domain, capturing the essence of sequence variability and conservation within the domain. However, the exact boundaries of a domain in a specific sequence can be somewhat fuzzy due to this variability, leading to slight differences in the predicted domain boundaries compared to curated database entries.

To mitigate this issue, you might consider adjusting certain parameters in HMMER. For instance, playing with the domain and sequence E-value thresholds can influence the sensitivity and specificity of your searches, potentially capturing those missing residues at the domain boundaries. Additionally, the `--domtblout` option provides domain-specific alignment information that might help in manually adjusting the boundaries based on alignment scores and positions. It's also worth exploring the `--trim` option, which can adjust how HMMER handles domain boundary predictions. Beyond parameter adjustments, integrating results from multiple sources, including other domain prediction tools or databases, can provide a more comprehensive view and help reconcile differences in domain boundary predictions. Remember, though, that no computational tool is perfect, and there will always be a balance between sensitivity (finding all true positives) and specificity (not predicting false positives), which can affect the exact domain boundaries predicted.",3,4,5
"im analyzing a miRNA run from illumina genome analyzer. i received the data with the adapter already trimmed off, and im now at the point of aligning my reads against a reference. <br>when i try and align the reads using bwa's default params: bwa aln ref.fasta read.fasta &gt; read.saiim getting &lt;10% alignment (~90% of the reads are not getting aligned). when i tried aligning using novoalign (that has the -s parameter to allow trimming) around 50% of the reads were aligned. this leads me to believe there is a parameter set in bwa that is more suitable for short RNA (including miRNA) alignment.thoughts?","Some details worth considering:How long are your reads? How long are the miRNAs you are looking for?I have also seen on my data that bwa reported fewer alignments than some other aligners (even blat and lastz) given the standard parameters.There are some parameters worth a check:pre class=""pre""><code class=""language-bash"">-n NUM    max #diff (int) or missing prob under 0.02 err rate (float) [0.04]/code></pre>Try increasing <code>-n</code>pre class=""pre""><code class=""language-bash"">-o INT    maximum number or fraction of gap opens [1]/code></pre>Try increasing to 2 or 3pre class=""pre""><code class=""language-bash"">-l INT    seed length [32]/code></pre>the default 32 seems a little large to me especially if your query is short, try reducing towards 8 if that is possibleI would also try bowtie, bfast and maybe some others. For all the seed length parameter is important to increase sensitivity.","When working with miRNA sequencing data, especially from platforms like Illumina, it's crucial to use alignment tools and parameters that are optimized for short reads. The default parameters of BWA are generally not tailored for the unique characteristics of miRNA, such as their short length, which can lead to a low alignment rate as you've observed. Your experience, where only about 10% of reads aligned using BWA's default settings versus 50% with Novoalign (which allows for trimming with the -s parameter), underscores this point. This discrepancy suggests that for miRNA data, using alignment tools that either are specifically designed for short reads or have customizable parameters that can be adjusted to accommodate the short length of miRNA sequences is essential. Tools like Novoalign, Bowtie, or even BWA with adjusted parameters (such as reducing the seed length, allowing more mismatches, or using the BWA-MEM algorithm, which is better suited for shorter sequences) might yield better alignment rates. It's also important to ensure that the reference database is comprehensive and up-to-date, as missing sequences could also contribute to lower alignment rates. Fine-tuning these parameters and possibly experimenting with different tools will likely improve your alignment percentages significantly.",4,5,5
"Hi,BWA usually reports one  line for each read even when the read don't mapped the reference sequence.There are some way to print in the sam file only the alignment when the read are aligned with the reference sequence?Thanks in advanceCris  ","samtools view -F 4 your.bamThis is directly from the manual of Samtools.  I recommend reading all the options.  It tried to avoid it, but really knowing Samtools is worth the time!","Certainly, Cris. When using BWA to align reads to a reference sequence, it indeed outputs a line for each read in the SAM file, including those that do not align to the reference. However, if you wish to have a SAM file that only contains reads that successfully aligned to the reference, you can achieve this by filtering the output using SAMtools. After generating the SAM file with BWA, you can pipe the output directly to SAMtools or use it on the generated SAM file to filter out the unaligned reads. The command `samtools view -S -F 4 yourfile.sam > aligned_reads.sam` can be used for this purpose. Here, `-S` indicates the input is in SAM format (omit if your input is BAM), `-F 4` filters out reads with the flag 4 set (reads not aligned), and `yourfile.sam` is your original SAM file generated by BWA. The output, `aligned_reads.sam`, will contain only those reads that have aligned to the reference sequence. This approach is efficient and widely used for focusing analyses on aligned reads.",4,5,5
"I'm using bwa to align reads, and I have to choose the indexing method to use.  The documentation says to use <code>-a is</code> for small genomes, and <code>-a bwtsw</code> for large genomes.  I've used <code>is</code>, but sometimes this will crash with a segmentation fault, and <code>bwtsw</code> seems to work.  Surely there is a better way to decide this than by trial and error?  At what size is a genome ""large"", meaning I should use <code>bwtsw</code>?  What is really the difference here?","From <a rel=""nofollow"" href=""http://bio-bwa.sourceforge.net/bwa.shtml"">BWA</a> manualpre><code> IS     is moderately fast, but does not work with database larger than 2GB./code></pre>blockquote>  bwtsw Algorithm implemented in BWT-SW. This method works with the whole human genome, but it does not work with database smaller than 10MB and it is usually slower than IS./blockquote>","The choice between the `-a is` and `-a bwtsw` indexing methods in BWA primarily hinges on the size of the genome you are working with. The `is` (infix-Sorted Suffix Array) method is generally recommended for smaller genomes due to its efficiency in handling shorter sequences, but it can run into issues, such as segmentation faults, when applied to larger genomes. This is because the `is` method requires more memory as the genome size increases, and it may exceed the available memory, leading to crashes. On the other hand, the `bwtsw` (Burrows-Wheeler Transform by Suffix Array) method is designed for larger genomes, typically those larger than 2 or 3 gigabases (Gb). The `bwtsw` algorithm is more memory-efficient for large genomes, making it the preferred choice for organisms with large genomes, such as humans. The exact threshold for what constitutes a ""large"" genome can be somewhat fluid, but a good rule of thumb is to use `bwtsw` for genomes larger than 2-3 Gb. The fundamental difference between these two methods lies in their memory usage and efficiency in handling genomes of different sizes, with `is` being more suitable for small to medium-sized genomes and `bwtsw` being optimized for large genomes.",5,5,5
"iBWA looks Awesome!A few questions:ol>li>Are there any scripts or tool recommendations for creating custom reference/remap files?  Specifically, something that takes a VCF as input?</li>li>What strategy do you recommend for using custom references based on sample genotypes?  Would the primary be hs37lite.fa and the the alternate be all the additional observed alleles similar to the dbsnp137 provided reference?  Or should I be doing something more complicated i.e. phasing to get the two alternate haplotype references.</li>li>Roughly, what's your variant calling pipeline when using iBWA?  Do you think I can drop GATK and the indel realignment step and just use <a rel=""nofollow"" href=""http://samtools.sourceforge.net/"">samtools</a>? </li>li>Are there any recommended methods/caveats to improve iBWA alignment accuracy (i.e. fastq trim/filter), speed (i.e. pBWA) or <a rel=""nofollow"" href=""http://samtools.sourceforge.net/SAM1.pdf"">bam</a> size (gobiBWA). </li>/ol>Best,Daryl","(1) <strong>Reference/remap files</strong>We use joinx to create these: <a rel=""nofollow"" href=""http://gmt.genome.wustl.edu/joinx/current/."">http://gmt.genome.wustl.edu/joinx/current/.</a> The usage is as follows:pre><code>joinx create-contigs -v my_variants.vcf -r my_refseq.fa -o my_new_contigs.fa -R my_new_contigs.fa.remap --flank=99/code></pre>This creates a new reference/remap pair with one sequence per variant* in my<em>variants.vcf (variants are relative to my</em>refseq.fa) with 99bp flanking on either side of the variant.*The command is currently set up to only create sequences for variants that have an identifier (e.g., rsid). This was fine for making the dbsnp reference but is probably not ideal for general use cases. I will make the identifier requirement optional and maybe add a few more options (like skipping sites that fail filters and some things described in the next point) shortly.(2) <strong>Refs based on sample genotypes</strong>What you said (hs37lite.fa as the primary, output of joinx create-contigs as the alternate) is how we do it. Right now, joinx doesn't look at the genotype data; contigs are created for every alternate allele in the ALT field for each site in the vcf file (whether or not the variants appear in a GT call). I will add some options to do things like only process alleles that are present in GT calls, and maybe allow some basic filtering based on INFO/FORMAT fields (e.g., DP &gt; 20). In any case, I don't think you need to worry about phasing in the vcf sample data (GT=1/2 vs GT=1|2); you will get both sequences created either way.(3) <strong>Variant calling pipeline</strong>I wouldn't change what you're doing right away. I would suggest running things through your existing pipeline to see how the results vary. Most of the testing I have done personally has just used samtools for variant calling after aligning with ibwa (not necessarily because I feel like that is the best thing to do). If you are wanting to generate sequences from existing sample data in a vcf, then I would definitely not suggest simplifying your existing calling strategy for generating the initial set of variants as you will want your alternate hypotheses to be as accurate as possible.(4) <strong>Optimizations</strong>Any pre-processing that works for bwa (trimming, filtering) should work the same for ibwa. The only differences between ibwa and stock bwa 0.5.9 are in sampe, so any methods that speed up ""bwa aln"" that yield equivalent .sai files are applicable (pbwa might be an option here). GobyBWA looks like it has its own file formats, so that will not work well. Lastly, ibwa sampe does have a -t option to support multi-threading. There have been some other sampe threading patches to bwa that work a bit better (at the expense of using more memory) than what I did in ibwa, but the -t option is worth trying if you become angry about the wall clock time used by ibwa sampe.","Creating custom reference or remap files based on VCF inputs can be achieved using tools like GATK's FastaAlternateReferenceMaker or bcftools consensus. These tools allow you to incorporate variants from a VCF file into a reference genome, creating a personalized reference genome that reflects the specific alleles present in your sample or population of interest.

When using custom references based on sample genotypes, the strategy largely depends on the goals of your study and the complexity of the genomic regions of interest. For many applications, starting with a standard reference such as hs37lite.fa and then incorporating observed alleles to create an alternate reference can be sufficient. However, for studies where haplotype information is crucial, such as those involving complex genomic regions or where allele-specific expression is of interest, phasing the variants to generate two haplotype-specific references might be more appropriate. Tools like ShapeIt or Eagle can be used for phasing, although this adds complexity to the reference preparation process.

Regarding the variant calling pipeline when using iBWA, it's designed to work well with various downstream tools, including samtools for variant calling. While iBWA improves alignment accuracy, especially in regions with indels or structural variants, the need to drop GATK and its indel realignment step depends on the specific requirements of your project. GATK offers advanced functionalities for variant discovery and genotyping, especially in complex regions. However, for many applications, especially those not focused on challenging genomic regions, using samtools for variant calling after iBWA alignment can be a streamlined and effective approach.

To improve iBWA alignment accuracy, quality control steps such as trimming low-quality bases and filtering reads based on quality scores are recommended. Tools like Trimmomatic or fastp can be used for this purpose. For speed improvements, parallelized versions of BWA, such as pBWA, can significantly reduce alignment time. Regarding bam file size, using tools like sambamba or samtools view with compression options can help manage file sizes without losing important information.

In summary, the choice of tools and strategies for creating custom references, variant calling, and optimizing iBWA workflows depends on the specific goals and complexities of your project. Incorporating VCF-based variants into a reference genome, deciding between a simple alternate reference or phased haplotypes, and choosing the appropriate downstream variant calling and optimization techniques are all critical considerations that can impact the success of your analyses.",1,5,5
"Hi.I would like to understand the output screen produced by a ""samtools tview"". I may not googling with good keywords, but I just can't find any document explaining the meaining of ""."", "","" underlined characters, etc. Thanks in advance.","I disagree with @Pierre.code>,</code> : negative strand,code>.</code> : positive strand.You could try to separate the reads by its strand using the bitwise flag.code>samtools -f 0x10 -b aln.bam&gt; aln.neg.bam</code> would give you all the reads mapped to negative strand,code>samtools -F 0x10 -b aln.bam&gt;aln.pos.bam</code> would give the positive reads.Then you could use <code>samtools tview</code> to see them. Due to alternative splicing, the RNA-seq reads would normally have <code>123N</code>, for example, in their cigar string, which means skipped reads, a.k.a splicing junction spanning reads.You would see the following for positive strand:pre class=""pre""><code class=""language-bash"">CATCACTGGTTTAAAGACAAACTTGCATTGTGAGATTCCAAAATAACAACAACAAAAAACAATTTGCATTGAGAACATTTTGAAG.........A............&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;.....&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;/code></pre>You would see for negative strand.pre class=""pre""><code class=""language-bash"">TTTCATTTGCAAGTAATCGATTTAGGTTTTTGATTTTAGGGTTTTTTTTTGTTTTGAACAGTCCAGTCAAAGTACAAATCGAGAG...KK....KKK..KK.K.K...K........K....K..................KKKK.........K...K...........&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;,,,,,,,,t,,,c,,,,,,,,,,/code></pre>","The ""samtools tview"" command is a text-based viewer for sequence alignments in SAM/BAM format, commonly used in bioinformatics for visualizing how reads align to a reference sequence. When you look at the output screen of ""samtools tview,"" you'll notice various characters that represent the alignment of sequences. The characters ""."", "","", and underlined characters each have specific meanings. The ""."" (dot) and "","" (comma) symbols represent bases that match the reference sequence, with the dot indicating a match on the forward strand and the comma indicating a match on the reverse strand. This distinction helps users quickly identify the strand orientation of the reads. Underlined characters are used to highlight differences between the read and the reference sequence, indicating mismatches. These mismatches are crucial for identifying variations and potential mutations in the aligned sequences. Additionally, you might see other symbols such as ""*"", which typically represents a deletion in the read relative to the reference sequence. Understanding these symbols allows researchers to quickly assess the quality of alignments and identify variations within the aligned sequences.",2,5,5
"Hi.If you want to remove reads mapped on a certain chr, how would you do that?I know 'samtools' can extract reads on a chr. Extraction of each chr and combining chr data I want would solve the problem, but I have multiple bam files to run it.So, if anyone of you know how to REMOVE a single chr (e.g. chr1 only), please tell me.Thank you!","See this post: ""https://www.biostars.org/p/128967/"" rel=""nofollow"">Remove mitochondrial reads from BAM files</a>","To remove reads mapped to a specific chromosome, such as chr1, from multiple BAM files without extracting each chromosome individually, you can use `samtools view` in a more efficient way. Instead of extracting each chromosome and then combining them, you can directly exclude the chromosome you're not interested in. For example, to remove reads from chr1, you can use the command `samtools view -h input.bam | awk '{if($3!=""chr1"") print $0}' | samtools view -bS - > output.bam`. This command works by first using `samtools view -h` to output the BAM file as SAM format including the header. The `awk` command then filters out any lines (reads) where the third column (which represents the chromosome) is ""chr1"". Finally, the filtered SAM is converted back to BAM format with `samtools view -bS - > output.bam`. This method is efficient and can be easily scripted to loop over multiple BAM files, allowing you to remove reads from a specific chromosome across all your files without the need to extract and recombine chromosome-specific data.",4,5,5
"I have read many posts regarding this question. The XT, XA tag doesn't seem to be used anymore by BWA mem, so I can't use them to identify uniquely mapped reads.Some posts said that multiple hits are to be assigned a quality score of 0. However, I don't have any links to confirm if this is still true. Does anyone know where I can confirm this?Does anyone know how to tell if a read is uniquely map from the result of BWA-mem alignment? Thank you.","You can filter out the secondary alignments in your file by excluding reads with the ""secondary"" flag (0x100 binary or 256 decimal) set. You can use samtools for this:pre>samtools view -F 256 file.bam</pre>","To determine if a read is uniquely mapped in BWA-mem alignment results, you can no longer rely on the XT or XA tags, as these are not used in the latest versions of BWA-mem. Instead, the mapping quality (MAPQ) score is a critical indicator. Reads that are not uniquely mapped are typically assigned a MAPQ score of 0. This approach is based on the SAM format specification, where the MAPQ score reflects the confidence in the mapping location of the read. A MAPQ of 0 indicates that the read maps equally well to multiple locations. To confirm this behavior and for the most accurate and up-to-date information, it's advisable to consult the official BWA documentation and the SAM format specification. These resources provide detailed explanations of the output format and the meaning of various flags and scores, including the MAPQ score, which is essential for interpreting the uniqueness of read mappings in BWA-mem results.",2,5,5
"Can anyone, in a simple, explicit way, point out the trick which improve aligning speed/efficiency by burrow-wheeler transform (BWA/Bowtie compared to MAQ)?I read the paper about MAQ,BWA,Bowtie, and also review, but only become more confused. What's the trick here?thx","Let's consider exact matching and inexact matching separately.For the exact matching problem, it is true that BWT-based algorithms are faster. Suppose we have a read of length ""l"" (letter ell, not one) and a genome of length ""L"". If we use a naive k-mer hash table, each k-mer appears L/4^k times. Thus the time complexity is O(l*L/4^k). For human, L=3e9 and typically k=13. L/4^k is about ~50, which is not a small number already. In practice, a hash-table based method does even worse because the human genome is much more repetitive than a random string. A lot of k-mer have thousands of occurrences. Visiting each of them is quite slow. In contrast, with BWT (more exactly FM-Index), we can always tell if the read has a perfect match in O(l) time, no matter how long or how repetitive the genome is. Essentially, FM-index collapses all the copies of a substring. We simultaneously align a sequence to all copies, rather than align to each copy like what we do with a hash table. This is why BWT-based algorithms are faster.On the other hand, I do not think BWT-based algorithms are faster for inexact matching problem. For inexact matching, we may still need to visit multiple copies similar to the read sequence. Although with BWT we still do better than with a hash table in theory, as each BWT operation is more expensive, the advantage of BWT is reduced. Moreover, for longer short reads, we can start to use multiple seeds, which may greatly boost the performance of hash table based algorithms. In fact, for 100bp reads, several hash table based mappers compete BWT-based ones on speed.Most of us get the impression that BWT-based algorithms are faster because for 30bp reads they were by far faster than the first-generation hash-based short-read mappers such as SOAP1 and MAQ. This is not necessarily true nowadays. In addition, we may misbelieve BWT-based ones are faster because they are popular, but this may be more related to the fact they are relatively well developed (e.g. user friendliness, memory and even reputation), instead of speed. Another fact we frequently overlook is that the most accurate short-read mappers are still based on hash tables. For BWT-based methods, differentiating subtle hits dramatically increases the computing time. It is very difficult to get an extreme accuracy while maintaining a reasonable speed.","The key trick that improves aligning speed and efficiency in algorithms like BWA and Bowtie, compared to MAQ, lies in the use of the Burrows-Wheeler Transform (BWT). The BWT reorganizes the reference genome in such a way that similar sequences are grouped together, creating a highly compressible and efficient structure for searching. This transformation allows these algorithms to quickly find potential matching positions for a read within the reference genome by performing efficient backward searches. Essentially, it reduces the search space dramatically by taking advantage of the repetitive nature of genomes. While MAQ uses hash tables to store and search the reference genome, which can be memory-intensive and slower for large genomes, BWA and Bowtie leverage the compact, transformed index to rapidly align sequences. This approach significantly speeds up the alignment process and reduces the computational resources required, making it more efficient for handling large-scale sequencing data.",4,5,5
"Dear Members,Is there a way I can removes reads associated with a region (chr, start, end) from a .bam file (RNASeq data) prior to the application of HTSeq?I will greatly appreciate your feedbackNoushin","<pre class=""pre""><code class=""language-bash"">bedtools intersect -abam file.bam -b filter.bed -v &gt; filtered.bam/code></pre>filter.bed should containpre class=""pre""><code class=""language-bash"">chr    start     end/code></pre>","Dear Noushin,

Yes, you can remove reads associated with a specific region (chr, start, end) from a .bam file before applying HTSeq for your RNASeq data analysis. This can be achieved by using tools like SAMtools or BEDTools, which are widely used for manipulating alignments in the SAM/BAM format. First, you would use SAMtools to index your BAM file if it's not already indexed. Then, you can use the 'view' command in SAMtools with the '-U' option to specify an output file for reads not matching the region you want to exclude. Alternatively, BEDTools' 'intersect' function allows you to exclude reads overlapping with a given region when you use the '-v' option. This approach requires you to create a BED file containing the regions you wish to exclude. After filtering out the unwanted reads, you can proceed with your analysis using HTSeq. It's important to ensure that the resulting BAM file is properly sorted and indexed, if necessary, before using it with HTSeq. This preprocessing step can help improve the accuracy of your gene expression analysis by removing reads that might not be relevant to your study.

Best regards.",4,5,5
"Hello, I've noticed that bwa mem outputs results to be inconsistent under following setting.  I'd have expected this to be not the case, and would appreciate if someone can comment on why this is happening. I have tested this with both bwa mem v0.7.5 and 0.7.15.Steps to reproduce:1. Create multiple FASTQ paired-end files from a reference FASTQ set of files. So, if there are 10000 read in our reference FASTQ files (s1.fastq, and s2.fastq), I generate another set of fastq files which also have the same 10000 reads but in a different order. I used the following script to do so.pre><code class=""lang-py"">#!/usr/bin/env pythonimport Bioimport Bio.SeqIOimport sysimport randomfile1 = sys.argv[1]file2 = sys.argv[2]record1 = []record2 = []for s in Bio.SeqIO.parse(file1,""fastq""):    record1.append(s)for s in Bio.SeqIO.parse(file2,""fastq""):    record2.append(s)# Lets make sure both files have same number recordsassert(len(record1) == len(record2))rand_idx = random.sample(xrange(len(record1)), len(record1))r1 = open(""reorder1.fastq"", ""w"")r2 = open(""reorder2.fastq"", ""w"")for idx in rand_idx:    Bio.SeqIO.write(record1[idx], r1, ""fastq"")    Bio.SeqIO.write(record2[idx], r2, ""fastq"")r1.close()r2.close()print(""Wrote %d records"" % len(record1))/code></pre>This will say output the following files:pre><code>$ lsreorder1.fastq  reorder2.fastq  s1.fastq  s2.fastq  shuffle_fastq.py/code></pre>The original files were s1.fastq, s2.fastq.  The newly generated shuffled files are reorder1.fastq, reorder2.fastq.  I made sure reorder1.fastq has all the entries in s1.fastq (and the same for reorder2.fastq/s2.fastq) using this:pre><code class=""lang-py"">#!/usr/bin/env pythonimport Bioimport Bio.SeqIOimport sysfile1 = sys.argv[1]file2 = sys.argv[2]results = []records = {}for s in Bio.SeqIO.parse(file1,""fastq""):    records[s.id] = sfor s in Bio.SeqIO.parse(file2,""fastq""):    if not records[s.id].seq == s.seq:        results.append(s)print ""Unmatched records"", len(results)/code></pre>2. Run BWA mem on the output FASTQ file pairs r1.fastq/r2.fastq and s1.fastq / s2.fastqpre><code>$ bwa mem -R ""@RG\tID:foo\tLB:bar\tPL:illumina\tPU:illumina\tSM:ERR000589"" /share/BWA_Index/hg19.all_chr.fa s1.fastq s2.fastq &gt; s.sam$ bwa mem -R ""@RG\tID:foo\tLB:bar\tPL:illumina\tPU:illumina\tSM:ERR000589"" /share/BWA_Index/hg19.all_chr.fa reorder1.fastq reorder2.fastq &gt; reorder.sam # Sort sam files so we can compare them with diff $ cat reorder.sam | samtools view -Sb - | samtools sort - reorder_sort &amp;&amp; samtools view reorder_sort.bam &gt; reorder_sort.sam  $ cat s.sam | samtools view -Sb - | samtools sort - s_sort &amp;&amp; samtools view s_sort.bam &gt; s_sort.sam/code></pre>3. Compare the output sam files s.sam and r.sam, and I see different alignments!!pre><code>diff reorder_sort.sam s_sort.sam/code></pre>Is anyone aware of why this could happen? I've tried this experiment several times with the following results:pre><code>Total# FASTQ Reads....   Inconsistent Alignments2500                     13512500                    660125000                   6830/code></pre>","There are two sources of randomness. The first is caused by the insert size estimate. Different batches of reads have slightly different insert size distribution, which affects paired-end alignment. You can in principle feed the insert size distribution to bwa-mem, but the bwa-mem estimate is usually better than a naive estimate and is at least more convenient.The second source is the ""random"" placement of repetitive hits. Bwa-mem is not really using a random number generator. It instead hashes deterministic information, such that the i-th read in the input is always associated with the same hash and has the same mapping. Reordering obviously breaks the deterministic behavior. I later learned that Bowtie2 hashes read names instead of the index of read. That is usually a better strategy except when you change read names.","The observation of inconsistent alignments when comparing the results of BWA MEM on the original and reordered FASTQ files, despite the files containing the same reads, can be attributed to several factors inherent to the alignment process and the algorithm used by BWA MEM. BWA MEM, like many other alignment tools, employs heuristics and probabilistic models to map reads to a reference genome efficiently. These models often involve seed selection, scoring alignments, and choosing the best alignment or reporting multiple alignments for reads that can map to multiple locations.

When the order of reads in the FASTQ files is altered, it can subtly influence the alignment process in a few ways. First, the seeding process, which is a critical step in identifying potential alignment locations by matching short subsequences of the read to the reference, might prioritize different seeds based on the context provided by adjacent reads in the input file. Although each read is aligned independently, the selection of seeds and the allocation of computational resources can be influenced by the order of processing, especially in cases where memory and processing optimizations are at play.

Second, the alignment scoring and the decision-making process for reads that can map to multiple locations might be affected by the order of reads. BWA MEM can report different alignments for reads with multiple equally good mapping locations, and the order of reads might influence which of these locations is reported in the final output.

Third, the alignment process is not purely deterministic in the sense that given the same input, slight variations in the computational environment or the way the algorithm explores alignment possibilities can lead to different outcomes. This is especially true for complex genomes with repetitive regions where multiple alignments are possible.

Lastly, the version of BWA MEM and the specific parameters used can also influence the alignment results. Different versions of the tool might have optimizations or algorithmic adjustments that change how alignments are computed and reported.

In summary, the observed inconsistencies in alignments between the original and reordered FASTQ files are likely due to the complex interplay of the alignment algorithm's heuristics, seed selection, scoring mechanisms, and the handling of reads with multiple potential alignments. These factors, combined with the inherent variability introduced by changing the order of reads, can lead to different alignment outcomes even though the input reads are identical.",4,5,5
Samtools has the options of sorting alignments by read name or by chromosomal coordinate. Why would someone choose one over the other? What are some practical aspects to consider for each sorting method for downstream applications (e.g. counting the number of hits vs. the reference genome).,"Many programs require bam files to be sorted by coordinates; this can save memory when doing specific operations like variant-calling and coverage calculation.  Also, programs like IGV need sorted, indexed bam files so that when you display a certain genomic area, they can rapidly access and display the relevant reads.Name-sorting is useful when doing operations that require reads to be paired.  Sam files often break interleaved pairing order, and coordinate-sorted bam files always do.  With a coordinate-sorted bam, it can take a lot of time and memory to restore the original fastq read order (the original fastq cannot typically be fully restored).  Name-sorting the file makes restoring pairing trivial, since the original reads are adjacent.So - some downstream programs require a sorted, indexed bam.  For those programs, that's what you need to provide.  But when programs are capable of handling unsorted sam output, I suggest using a gzipped sam file with reads in the original order, which makes recovery or remapping of the original data much easier (aside from the inherent lossiness of the sam format, which will discard the original names), and generally makes pipelines faster compared to using bam files as an intermediate stage.Note that as of samtools 1.4, the bam format is much faster and may be competitive with gzipped sam files, depending on the situation.","Choosing between sorting alignments by read name or chromosomal coordinate in Samtools depends on the specific requirements of downstream applications. Sorting by read name groups all alignments for a particular read together, which is particularly useful for applications involving paired-end reads or multi-mapping reads where it's important to analyze all alignments of a read collectively. This method facilitates tasks such as duplicate marking or identifying properly paired reads, as it makes it easier to compare and contrast the alignments of each read pair. On the other hand, sorting by chromosomal coordinates organizes the alignments based on their position in the reference genome. This approach is essential for variant calling, coverage analysis, and generating genome-wide visualizations, as it allows for efficient access and analysis of alignments in a genomic context. For instance, when counting the number of hits to the reference genome or assessing the coverage depth across different genomic regions, sorting by chromosomal coordinates streamlines the process by enabling sequential processing of alignments. Therefore, the choice between sorting methods hinges on the nature of the downstream analysis, where considerations include the need for read-centric operations versus genomic region-centric analyses, and the computational efficiency in accessing and processing alignment data for the intended purpose.",4,5,5
"Does anyone know what the <code>MAPQ</code> values produced by <a rel=""nofollow"" href=""http://bio-bwa.sourceforge.net/""><code>BWA-MEM</code></a> mean? I'm looking for something similar to what <a rel=""nofollow"" href=""http://www.acgt.me/blog/2015/3/17/more-madness-with-mapq-scores-aka-why-bioinformaticians-hate-poor-and-incomplete-software-documentation%20"">Keith Bradnam discovered for TopHat v1.4.1</a>, where he realized that:blockquote>  0 = maps to 5 or more locations     1 = maps to 3-4 locations     3 = maps to  2 locations     255 = unique mapping/blockquote>I'm familiar with the notion that MAPQ should be theoretically be related to the probability of an ""incorrect"" alignment (10^(-<code>MAPQ</code>/10)), although this is vaguely-specified enough that aligners in practice tend to actually just use something like the above. Note that this is different than the <code>BWA</code> <code>MAPQ</code> scoring interpretation, because <code>BWA-MEM</code> gives <code>MAPQ</code> scores in the range [0,60], rather than [0,37] as has <a rel=""nofollow"" href=""http://www.acgt.me/blog/2014/12/16/understanding-mapq-scores-in-sam-files-does-37-42"">been established for <code>BWA</code></a>.","MAPQ scores are not meaningful because BAM is not meaningful - or rather, the field has yet to define the difference between read-alignments (what BAM officially stores) and fragment-alignments (what most aligners produce).The issue goes far deeper than MAPQ scores, but if you want to read about MAPQ this is a good resource:a rel=""nofollow"" href=""https://sequencing.qcfail.com/articles/mapq-values-are-really-useful-but-their-implementation-is-a-mess/"">https://sequencing.qcfail.com/articles/mapq-values-are-really-useful-but-their-implementation-is-a-mess/</a>But attempting to create a common standard is impossible. People want different things out of the MAPQ score, and so there can not be a single standard. Some people want it to represent how well the alignment aligns, others how well the fragment in it's entirety aligns, others a combination of both, sometimes with and sometimes without taking into account how many other possible alignments there might be for the read/fragment. It's a mess, and it all stems from the fact that pretty much every aligner produces non-standard BAMs except BWA, which produces BAMs no one would use if they needed to store more than one alignment per sequencing event.","The `MAPQ` values produced by `BWA-MEM` are intended to provide an estimate of the quality of the alignment, where a higher `MAPQ` score suggests a higher confidence in the alignment's accuracy. Unlike the specific `MAPQ` scoring interpretation provided by Keith Bradnam for TopHat v1.4.1, `BWA-MEM` does not have a fixed mapping of `MAPQ` scores to the number of locations a read maps to. Instead, `BWA-MEM` uses a more complex algorithm to calculate `MAPQ` scores, which can range from 0 to 60. The `MAPQ` score in `BWA-MEM` is somewhat related to the probability of an alignment being incorrect, with the formula 10^(-`MAPQ`/10), but the exact interpretation of individual scores can vary. The scoring system is designed to reflect the aligner's confidence in each alignment, with 0 indicating the lowest confidence (potentially mapping to multiple locations) and 60 indicating very high confidence in a unique or highly accurate mapping. However, the specific thresholds and calculations behind these scores are more nuanced and depend on various factors, including the alignment's quality, the number of potential mapping locations, and the sequence data's complexity. Unlike the simpler, more direct mapping of scores to the number of locations in some other tools, `BWA-MEM`'s `MAPQ` scoring requires a deeper understanding of the algorithm's behavior and the nature of the sequence data being aligned.",2,5,4
"I have two fastq files.  I want to use bwa to produce two sam files as this is more efficent for me than merging the fastq files and running bwa on the bigger file.  If I run bwa separately on the fastq files and merge the sam files later, will the result be different?  (I don't know if this is an important detail, but I know a priori that the fastq files have reads from separate chromosomes.)","Individual reads are mapped independently of each other. So mapping the reads in two chunks should produce the same mappings as a single file. However, I wouldn't expect mapping runs to always be identical as there is a random element to mapping repetitive hits.","Running BWA separately on two FASTQ files and then merging the resulting SAM files should, in principle, give you a similar outcome to merging the FASTQ files first and then running BWA, especially since you mentioned that the reads in the FASTQ files are from separate chromosomes. BWA aligns reads independently, meaning it treats each read in isolation during the alignment process. Therefore, whether the reads are presented together or separately should not affect how each individual read is aligned to the reference genome. However, there are a few caveats to consider. First, the header information in the SAM files might need to be merged or adjusted appropriately when combining the SAM files to ensure consistency and compatibility with downstream analysis tools. Second, if there are any read pairs that span the boundary of the chromosomes you mentioned (though you've indicated this is not the case), aligning them separately could potentially affect the alignment quality or pairing information. Lastly, some downstream analyses or tools might expect certain ordering or pairing information that could be disrupted by handling the files separately. Therefore, while the alignment results per se might not be significantly different, careful attention should be paid to post-alignment processing to ensure the final merged file is correctly formatted and annotated.",4,4,5
"Hi,I'm looking for a nice way to calculate the percentage of reads on specifique chromosomes (MT und (1-23,X,Y) und unplaced scaffold).I know I can get the read counts per chromosome with <code>samtools idxstats</code>, however I have a lot of bam files and I would like to automate the calculation. The problem is, I'm struggling with basic batch text maniplulation and would therefore appreciate any help you can give me (specific or general).Edit: I forgot to mention, that I have multiple bam files, which are indexed and only consist of uniquely mapped reads.","I'd suggest to also having a look at <a rel=""nofollow"" href=""https://github.com/brentp/mosdepth"">mosdepth</a> and <a rel=""nofollow"" href=""https://github.com/brentp/goleft/tree/master/indexcov"">indexcov</a>.","To automate the calculation of the percentage of reads on specific chromosomes across multiple BAM files, you can use a combination of `samtools idxstats`, `awk`, and a simple shell script. First, ensure all your BAM files are indexed, as you've mentioned they are. You can then use `samtools idxstats` to get read counts per chromosome for each BAM file. 

Here's a general approach you can follow:

1. **Iterate Over BAM Files**: Use a `for` loop in a shell script to iterate over each BAM file in your directory. You can do this by using `for file in *.bam; do ... done`.

2. **Extract Read Counts**: Within the loop, use `samtools idxstats $file` to get the read counts for each chromosome in the current BAM file. Pipe this output to `awk` for processing.

3. **Calculate Percentages with `awk`**: Use `awk` to sum the total reads and calculate the percentage of reads for the chromosomes of interest (MT, 1-23, X, Y, and unplaced scaffolds). You can do this by checking the chromosome name in the first column and performing the necessary arithmetic operations. Remember, `awk` can perform text manipulation and arithmetic operations, making it powerful for tasks like this.

4. **Output or Save Your Results**: Print or save the results to a file. You can redirect the output of your calculations in the script to a new file for each BAM or append to a collective file, depending on your preference.

Here's a simplified example of what the script might look like:

```bash
#!/bin/bash

# Output file
output=""chromosome_read_percentages.txt""

# Header
echo -e ""File\tChromosome\tPercentage"" > ""$output""

# Loop through BAM files
for file in *.bam; do
    # Use samtools and awk to calculate percentages
    samtools idxstats ""$file"" | awk -v bamfile=""$file"" 'BEGIN{total=0} {total+=$3} END{for (i=1; i<=22; i++) print bamfile, i; print bamfile, ""X""; print bamfile, ""Y""; print bamfile, ""MT""} {if ($1 ~ /^MT$|^[1-9]$|^1[0-9]$|^2[0-3]$|^X$|^Y$/){reads[$1]=$3}} END{for (chr in reads) print bamfile, chr, (reads[chr]/total)*100}' >> ""$output""
done
```

This script is a basic template and might need adjustments based on your specific requirements, such as handling unplaced scaffolds or refining the output format. The key takeaway is to use the combination of `samtools idxstats` for read counts, `awk` for processing these counts, and a shell script to automate the process across multiple BAM files. This approach provides a flexible and efficient way to calculate and report the percentage of reads per chromosome for your dataset.",5,5,5
"I would like to add read group info (<code>-R</code>) during the mapping/alignment stage as part of my variant calling gatk pipeline.I am doing something like this:pre class=""pre""><code class=""language-bash"">bwa mem \-M \-t 8 \-v 3 \-R &lt;(sh a-illumina-read-group.sh $1) \""$path_dr_bwaindex_genome"" \$1 $2/code></pre>where the read group string is generated automatically from the fastq file by the shell script <code>a-illumina-read-group.sh</code>. It produces a string like: code>'@RG\tID:ST-E00215_230_HJ3FMALXX_2\tSM:ST-E00215_230_HJ3FMALXX_2_ATCACG\tLB:ATCACG\tPL:ILLUMINA'</code>but, when I run bwa, it fails with this error:code>[E::bwa_set_rg] the read group line is not started with @RG</code>I have tried excluding the single quotes (<code>''</code>) around read group info, but that didn't change anything. I also tried variations in how the variable is passed.code>-R=$(sh a-illumina-read-group.sh $1) \</code>code>-R=$(echo $(sh a-illumina-read-group.sh $1)) \</code>Just as a test, I tried:code>rg='@RG\tID:ST-E00215_230_HJ3FMALXX_2\tSM:ST-E00215_230_HJ3FMALXX_2_ATCACG\tLB:ATCACG\tPL:ILLUMINA'</code>code>-R &lt;(echo $rg)  \</code>But, they all produce the same error. I would appreciate any solutions to this issue.I understand that I can add read groups later on using PicardTools <code>AddOrReplaceReadGroup</code>, but I thought it might be convenient doing it here in one step.Thanks.","What worked for me was to read the read group information from the fastq file during the mapping run. My read name in the fastq file looks like this: <code>@ST-E00274:188:H3JWNCCXY:4:1101:5142:1221 1:N:0:NTTGTA</code>.The bash file looks like this:pre class=""pre""><code class=""language-bash"">#!/bin/bashheader=$(zcat $1 | head -n 1)id=$(echo $header | head -n 1 | cut -f 1-4 -d"":"" | sed 's/@//' | sed 's/:/_/g')sm=$(echo $header | head -n 1 | grep -Eo ""[ATGCN]+$"")echo ""Read Group @RG\tID:$id\tSM:$id""_""$sm\tLB:$id""_""$sm\tPL:ILLUMINA""bwa mem \-M \-t 8 \-v 3 \-R $(echo ""@RG\tID:$id\tSM:$id""_""$sm\tLB:$id""_""$sm\tPL:ILLUMINA"") \""$path_bwaindex_genome"" \$1 $2 | samblaster -M | samtools fixmate - - | samtools sort -O bam -o ""mapped-bwa.bam""/code></pre>And the bash file is run aspre class=""pre""><code class=""language-bash"">bwa-mapper.sh read_1.fq.gz read_2.fq.gz/code></pre>You can remove this part (<code>| samblaster -M | samtools fixmate - - | samtools sort -O bam -o</code>) and replace with <code>&gt;</code> if you don't need it. <code>samblaster</code> marks duplicates like Picard. I don't remember what <code>fixmate</code> does. The sort part sorts the SAM file and generates an output BAM.","The issue you're encountering with adding read group information during the mapping stage with BWA stems from how the read group string is being passed to the `-R` option. BWA expects the read group line to start with `@RG`, but it seems there's a problem with how the shell script's output is being interpreted or incorporated into the BWA command. When you use process substitution (`<()`) or attempt to directly insert the output of your script into the command, it's crucial that the format and escaping of special characters (like tabs) are preserved correctly. 

One potential solution is to ensure that the output of your shell script `a-illumina-read-group.sh` is exactly in the format BWA expects, without any additional characters or formatting issues. You might want to directly call your script and inspect the output to ensure it's correct. Also, instead of using process substitution, you could try capturing the output of your script into a variable and then carefully inserting that variable into your BWA command, paying close attention to how shell quoting and escaping are handled. 

For example, capturing the output of your script into a variable and then using it in your BWA command might look something like this:

```bash
read_group_info=$(sh a-illumina-read-group.sh $1)
bwa mem -M -t 8 -v 3 -R ""$read_group_info"" ""$path_dr_bwaindex_genome"" $1 $2
```

Make sure that when you inspect or echo the `read_group_info` variable, it matches exactly what BWA expects, including the `@RG` at the beginning and the correct escaping of tabs and other special characters. If necessary, manually adjust the script or the way you're capturing its output to ensure compatibility.

If these approaches don't resolve the issue, as a workaround, you mentioned using PicardTools' `AddOrReplaceReadGroup` after the alignment step. While it's an extra step, it might offer a more straightforward and controlled way to add read group information, especially if the direct inclusion during the BWA alignment proves too troublesome.",3,5,5
"Dear all,I have indexed the C. elegans reference genome with:pre class=""pre""><code class=""language-bash"">bwa index output/genome/ref/seq/celegans.fa/code></pre>and then aligned my de novo assembly to the reference with:pre class=""pre""><code class=""language-bash"">bwa mem -t 8 -x intractg output/genome/ref/seq/celegans.fa input/assembly/celegans/hgap/bristol/assembly.fa &gt; output/alignment/pacbio/bwa/ref/bristolAssembly.sam/code></pre>I then pre class=""pre""><code class=""language-bash"">samtools view -bS output/alignment/pacbio/bwa/ref/bristolAssembly.sam &gt; output/alignment/pacbio/bwa/ref/bristolAssembly.bamsamtools sort output/alignment/pacbio/bwa/ref/bristolAssembly.bam -o output/alignment/pacbio/bwa/ref/bristolAssemblySorted.bamsamtools index output/alignment/pacbio/bwa/ref/bristolAssemblySorted.bam/code></pre>to visualise the alignment in IGV.This is what I get: <a rel=""nofollow"" href=""http://cristian-riccio.ch/wp-content/uploads/2017/07/igv_snapshot.png"">http://cristian-riccio.ch/wp-content/uploads/2017/07/igv_snapshot.png</a>You can see that my assembly is the same as the reference, just shifted by 12 bases or so. Has anyone any suggestions about how to solve this problem?Thanks.Best,C.","Solved finally!a rel=""nofollow"" href=""http://cristian-riccio.ch/wp-content/uploads/2017/07/igv_snapshotSolution.png"">http://cristian-riccio.ch/wp-content/uploads/2017/07/igv_snapshotSolution.png</a>I used this command instead, penalising gap extensions less.pre class=""pre""><code class=""language-bash"">bwa mem -t 8 -E0.5 -x intractg output/genome/ref/seq/celegans.fa input/assembly/celegans/hgap/bristol/assembly.fa &gt; output/alignment/pacbio/bwa/ref/bristolAssembly.sam/code></pre>The assembly comes from pacbio, and this technology is 12% indel error in the raw reads, that might be why the contigs also need a bit more lee-ways on indels for alignment.I figured it out with a colleague because we looked at the start of the chromosomes and it started off aligned and got misaligned when there was a larger indel in my assembly.Thanks to all for the suggestions.Best,C.","It appears that during your bioinformatics workflow, you've successfully indexed the C. elegans reference genome and aligned your de novo assembly to this reference using BWA. Following alignment, you converted the SAM file to a BAM file, sorted it, and indexed it for visualization in IGV. Upon inspection in IGV, you've noticed that your assembly aligns closely with the reference genome but is shifted by approximately 12 bases. This observation suggests that there might be a small insertion or deletion (indel) in your assembly relative to the reference, or it could be an alignment artifact.

To address this issue, you might consider a few steps. First, ensure that your de novo assembly is of high quality and that any potential sequencing errors have been corrected. You could also try realigning your assembly to the reference genome using different alignment parameters or software that might be more tolerant of indels or more suited to handling the specific characteristics of your data (e.g., long reads from PacBio sequencing). Additionally, inspecting the region around the shift in more detail using IGV or another visualization tool might provide clues about the nature of the discrepancy. If the shift is consistent across the entire assembly, it might be worth exploring whether there is a systematic error in the assembly process. Finally, consulting with colleagues or the bioinformatics community for insights and potential solutions to similar issues could also be beneficial.",4,4,4
"Hi guys, I have a folder with around 300 <code>.bam</code> files. Each <code>.bam</code> file is a lane of a sample and hence 4 lanes make a sample. I would like to merge the .bam files of the four lanes in a single one by <code>_*S*_</code> where S is followed by a number that represent the number of the sample (e.g. <code>my_experimet_xxx__L001_S1_stimulated_Aligned.bam</code>). Suppose I have 75 samples, i.e. <code>${1...75}</code>. Can anyone help me please? The line I use to merge normally is the following: pre class=""pre""><code class=""language-bash"">samtools merge S1_merged.bam *bam/code></pre>Thank you in advance ","I think this should work for your issue:create a file name samtools_merge.shpre class=""pre""><code class=""language-bash"">$mkdir mergedfor L1 in *_L001_*.bamdo    echo $L1    L2=`echo $L1 | sed 's/_L001_/_L002_/'`    L3=`echo $L1 | sed 's/_L001_/_L003_/'`    L4=`echo $L1 | sed 's/_L001_/_L004_/'`    merged=`echo $L1 | sed 's/_L001_/_merged_/'`    samtools merge ./merged/${merged} ${L1} ${L2} ${L3} ${L4}done/code></pre>This will iterate over each unique sample with L001 somewhere in the name and store other variables by replacing L001 with L002,003,004, and do this for each sample. Then it will run samtools merge on all 4 lanes, then do the same for the next sample until it has gone through all the samples. The filename output will be the same as the sample name, but will substitute lane information with ""merged"". Just run this in your directory with all the bams and you should have merged bams in the dir ""merged"".","To merge your `.bam` files by sample, where each sample consists of 4 lanes and is identified by a unique number following `_S` in the filename, you can use a loop in combination with pattern matching in bash. Since you're familiar with using `samtools merge` for merging `.bam` files, you can incorporate this into a script that iterates over your sample numbers (1 to 75 in your case), constructs the pattern for each sample, and then calls `samtools merge` with the appropriate files.

Here's how you can do it in a bash script or command line:

1. Open your terminal or create a bash script.
2. Use a `for` loop to iterate over the sample numbers from 1 to 75.
3. For each iteration, construct the pattern that matches all lanes of the current sample. This can be done by using the wildcard character `*` and the sample identifier `_S${i}_`, where `${i}` is the current sample number in the loop.
4. Use this pattern with `samtools merge` to merge all lanes of the current sample into a single `.bam` file named after the sample number (e.g., `S1_merged.bam` for sample 1).

Here is a snippet that demonstrates this process:

```bash
for i in {1..75}; do
    # Construct the pattern to match all lanes of the current sample
    pattern=""*_S${i}_*.bam""
    # Use samtools merge with the constructed pattern
    samtools merge ""S${i}_merged.bam"" $pattern
done
```

This script iterates over each sample number, constructs the file matching pattern for that sample, and then uses `samtools merge` to merge all matching `.bam` files into a single file named `S${i}_merged.bam`, where `${i}` is the sample number. Make sure you run this script in the directory containing your `.bam` files, and also ensure that `samtools` is installed and accessible from your command line. This approach is efficient and automates the process of merging `.bam` files by sample, saving you a significant amount of time and effort.",3,5,5
"Can anyone explain the following tags from BWA sam output.pre class=""pre""><code class=""language-bash"">GA004_0001:5:1:1073:12995#0   0       chr10   135119228       37      75M     *       0       0       CTGGGTTTGGCATAGTGGGAGGGCAGGCAGGGGTGGTTTTCCTGGCTACTCAGGGTTGCAGAGGACAGGACCGAA     CCCBCCCBCBCCC=CCCCCCCC@@BCCCCCCBC?C&gt;=CCACAC@A+?;&lt;;BAA@A08A++?6?&lt;9ACCC68=C8&lt;     XT:A:U  NM:i:1  X0:i:1  X1:i:0  XM:i:1  XO:i:0  XG:i:0  MD:Z:45A29/code></pre>How to check whether a tags in unique hot or multiple hits as sam flag is bit confusing to read. Thanks.","<a rel=""nofollow"" href=""http://bioinformatics.oxfordjournals.org/cgi/content/short/25/16/2078"">Here</a> and in more details <a rel=""nofollow"" href=""http://samtools.sourceforge.net/SAM1.pdf"">here</a>, you can find a good description of the SAM/BAM standard and what all fields mean. There is also a page with predefined tags and it says how you can make your own.Those starting with X,Y and Z are ""reserved for end user"" Maybe an intermediate program?NM:i:1 Number of nucleotide differencesMD:Z:45A29 String of mismatching positionI don't quite understand when you say ""tags in unique hit or multiple hits""","The BWA SAM output you've provided contains several tags that can help determine the uniqueness of the alignment. The key tags to look at for determining if an alignment is unique or has multiple hits are `XT`, `X0`, `X1`, `XM`, `XO`, and `XG`. 

- The `XT` tag indicates the type of alignment; `XT:A:U` means the read is uniquely aligned, while `XT:A:R` would indicate a repeat (non-unique alignment).
- The `X0` tag shows the number of best hits found; `X0:i:1` means there is one best hit, suggesting a unique alignment in this context.
- The `X1` tag indicates the number of suboptimal hits found; `X1:i:0` means there are no suboptimal hits, further supporting the uniqueness of this alignment.
- The `XM`, `XO`, and `XG` tags provide information on mismatches, gap opens, and gap extensions, respectively, but are not directly related to determining the uniqueness of the alignment.

In your example, the `XT:A:U` tag indicates that the alignment is unique, and this is supported by the `X0:i:1` tag, which shows there is only one best hit for this alignment. The `X1:i:0` tag confirms there are no other close matches, reinforcing the conclusion that this alignment is unique. Therefore, based on these tags, you can determine that the read aligns uniquely to the reference genome.",4,5,5
"Hi everyone. I keep getting this error message with samtools. I have used samtools in the past plenty of times. I am not sure how to solve it. Any help would be greatly appreciated. samtools: error while loading shared libraries: libbz2.so.1.0: cannot open shared object file: No such file or directoryI have tried googling the error. Nothing specific with respect to samtools has come up. However, there were some fixes that I tried: sudo yum install bzip2-develsudo ln -s <code>find /usr/lib64/ -type f -name ""libbz2.so.1*""</code> /usr/lib64/libbz2.so.1.0However, it asks for a login when I try this fix or others. ","From <a rel=""nofollow"" href=""https://github.com/bioconda/bioconda-recipes/pull/5049#issuecomment-311070184"">https://github.com/bioconda/bioconda-recipes/pull/5049#issuecomment-311070184</a>bioconda now requires conda-forge and the conda-forge version of bzip2 uses shared libraries, while the one in the main channel uses a static library. Since it was compiled against the shared library version you need to also have than included in your environment. Hope this fixes it for you.Try installing samtools with conda-forge included:code>conda install -c conda-forge -c bioconda samtools bzip2</code>","The error message you're encountering with samtools, ""error while loading shared libraries: libbz2.so.1.0: cannot open shared object file: No such file or directory,"" suggests that samtools is unable to find the required version of the BZ2 library (libbz2.so.1.0) on your system. This library is necessary for samtools to run properly as it likely depends on it for file compression/decompression functionalities.

You've already taken a good step by attempting to install the `bzip2-devel` package, which should include the necessary library files. However, if samtools is still not finding the library, creating a symbolic link (symlink) to the library file seems like a reasonable approach. The command you've mentioned attempts to create a symlink to the `libbz2.so.1.0` file from the actual location of the library found by the `find` command. If it's asking for a login, it's likely because you're trying to execute a command that requires root or sudo privileges.

If you're not able to execute the command due to login issues, ensure that you have the necessary permissions on the system to install packages and create symlinks in `/usr/lib64/` or wherever the system expects shared libraries. If you're not the system administrator, you might need to ask for assistance from someone who has the required access.

Another approach could be to ensure that the environment variable `LD_LIBRARY_PATH` includes the directory where `libbz2.so.1.0` is located. This can be done by exporting the path to this environment variable, for example: `export LD_LIBRARY_PATH=/path/to/lib:$LD_LIBRARY_PATH`. However, this is more of a temporary solution and might need to be set for every session unless added to your shell initialization file (e.g., `.bashrc` or `.bash_profile`).

If these steps do not resolve the issue, double-check that the `bzip2-devel` package was successfully installed and that the version installed includes `libbz2.so.1.0`. It's also possible that a different version of the library was installed (e.g., `libbz2.so.1.0.6`), in which case you might need to adjust the symlink command to point to the correct version of the library file.",2,5,4
"I am using hg38 as a reference for mapping in bwa-0.7.17. I have already created the 5 BWA index files  for my reference fasta file. Since it's advisable to also take into consideration the alternate contigs (hg38DH.fa.alt); I wanted to ask if:1. How do we include the file containing decoy sequences (hg38DH-extra.fa) in the alignment process. ol>li>In case the decoy file is needed, does it need to be in the same folder as the other index files. </li>li>If the bwa index files for the ALT contigs need to be present. </li>/ol>","My reference includes the primary chromosomes (1-22, X, Y) plus chrM, all unplaced and random contigs + the EBV decoy. See also <a rel=""nofollow"" href=""https://www.biostars.org/p/342482/"">Which human reference genome should I use?</a>. ALT contigs are typically not included unless you intend to use an ALT-aware alignment pipeline, such as the one in BWAkit. That is typically not necessary unless you are interested in exactly these regions and the variation going on there. Therefore, for standard purposes, do not include them into the reference. The reason is that they represent alternative sequences for regions that are already included in the primary assembly (highly variable regions like MHC) leading to multimapping events between the primary assembly and the ALTs. As most downstream tools typically exclude multimappers, including the ALTs in an ALT-unaware alignment pipeline, eventually leads to a loss of these reads. See also <a rel=""nofollow"" href=""https://gatkforums.broadinstitute.org/gatk/discussion/7857/reference-genome-components"">Reference Genome Components</a>. Once you have all the chromsomes and contigs you want to include as <code>fasta</code>, <code>cat</code> them together into one file and index them with BWA. See again <a rel=""nofollow"" href=""https://www.biostars.org/p/342482/"">Which human reference genome should I use?</a>.","To include the file containing decoy sequences (hg38DH-extra.fa) in the alignment process using BWA (version 0.7.17) and the hg38 reference, you should first integrate the decoy sequences into your reference genome before creating the BWA index. This means that the decoy sequences (from hg38DH-extra.fa) should be concatenated to the primary assembly of hg38 before you run the `bwa index` command. This ensures that the decoy sequences are considered during the alignment process. The resulting index files will then inherently contain information about the decoy sequences, eliminating the need to handle them separately during alignment. 

Regarding the location of the decoy file and the index files, once the decoy sequences are integrated into your reference genome and the index is created, the resulting BWA index files should be kept in the same directory where you plan to run your BWA commands. This simplifies the command-line arguments, as you only need to specify the path to the primary reference (now including decoys) when initiating the alignment. 

As for the ALT contigs, if you're using a reference that includes ALT contigs (like hg38DH.fa.alt), and you wish to consider these in your alignments, you should ensure that these sequences are also included in your reference genome before indexing. BWA can handle ALT contigs during the alignment process to improve alignment quality, but this requires that the ALT contigs are part of the reference genome used to create the BWA index files. Therefore, both the decoy sequences and the ALT contigs should be integrated into your reference genome before indexing to ensure they are considered during the alignment process.",3,5,5
"Dear All,I want to remove the singletons from the aligned bam file.Downloaded fastq files using pre class=""pre""><code class=""language-bash"">fastq-dump --split-files SRR1517848/code></pre>Then aligned the paired end fastq files, using BWA by:pre class=""pre""><code class=""language-bash"">bwa mem hg19.fa R_1.fa R_2.fa -o SRR1517848.sam/code></pre>Then converted it to BAM format and <strong>I used samtools to remove the singletons using</strong> : according to the paper, <a rel=""nofollow"" href=""https://peerj.com/articles/600/"">article</a>pre class=""pre""><code class=""language-bash"">samtools view -@ 8 -F 0x04 -b SRR1517848.sam &gt; SRR1517848.bam/code></pre>Then I looked into the stats using samtools flagstat command by;pre class=""pre""><code class=""language-bash"">samtools flagstat SRR1517848.bam/code></pre>which gave;pre class=""pre""><code class=""language-bash"">   Before filtering     4614120 + 0 in total (QC-passed reads + QC-failed reads)    4549753 + 0 mapped (98.61% : N/A)    4609656 + 0 paired in sequencing    2304828 + 0 read1    2304828 + 0 read2    4461356 + 0 properly paired (96.78% : N/A)    4517788 + 0 with itself and mate mapped    27501 + 0 singletons (0.60% : N/A)    39296 + 0 with mate mapped to a different chr    33576 + 0 with mate mapped to a different chr (mapQ&gt;=5)/code></pre>And after filtering pre class=""pre""><code class=""language-bash"">4549753 + 0 in total (QC-passed reads + QC-failed reads)0 + 0 secondary4464 + 0 supplementary0 + 0 duplicates4549753 + 0 mapped (100.00% : N/A)4545289 + 0 paired in sequencing2281318 + 0 read12263971 + 0 read24461356 + 0 properly paired (98.15% : N/A)4517788 + 0 with itself and mate mapped27501 + 0 singletons (0.61% : N/A)39296 + 0 with mate mapped to a different chr33576 + 0 with mate mapped to a different chr (mapQ&gt;=5)/code></pre>strong>So my Questions:</strong>1) So the command to remove the singletons by -F 0x04 have only removed unmapped reads ?2) In both before and after stats the singletons remain, and what are those? Before: <code>27501 + 0 singletons (0.60% : N/A)</code>After : <code>27501 + 0 singletons (0.61% : N/A)</code>3) Is there a way to remove singletons in variant detection GATK pipeline ? what benefits does it have?Thanks","As per the <a rel=""nofollow"" href=""https://broadinstitute.github.io/picard/explain-flags.html"">SAM flag guide</a> the flag that you are filtering for i.e. <code>0x04</code> is for unmapped reads. This explains the removal of unmapped reads. In case you want to filter for singletons i.e. reads for which the <code>mate is unmapped</code> you an select that as the condition. This gives a SAM flag value of <code>0x08</code>. You can hence change your command to pre class=""pre""><code class=""language-bash"">samtools view -@ 8 -F 0x08 -b SRR1517848.sam &gt; SRR1517848.bam/code></pre>This should remove the singleton reads.","Yes, the command you used with `-F 0x04` in samtools view indeed only removes unmapped reads. The flag `0x04` corresponds to the SAM flag for reads that are not mapped to the reference genome. Therefore, this command does not specifically target singletons but rather filters out reads that have not been aligned at all. Singletons, in the context of paired-end sequencing, refer to reads for which one read of the pair is mapped, but its mate is not. The statistics you observed before and after filtering, where the count of singletons remains the same, confirms that the filtering command did not affect the singletons.

To specifically remove singletons, you would need to use additional flags with samtools or another tool that can identify and filter out these reads based on their mapping status and their relationship with their mate reads. For instance, using samtools view with the flag `-f 0x2` can select only those reads that are properly paired (i.e., both reads of the pair are mapped in a proper pair), which indirectly removes singletons.

In the context of a variant detection pipeline like GATK, removing singletons can be beneficial because it helps to reduce noise and potential false positives in variant calling. Singletons might arise from sequencing errors, PCR artifacts, or genuine structural variations, but they are often considered less reliable for variant calling, especially in high-confidence regions. By focusing on properly paired reads, the analysis can be more robust and accurate, leading to higher confidence in the detected variants. GATK and other variant calling tools often have built-in mechanisms or recommended practices for filtering reads, including the removal of poorly mapped reads or reads not meeting certain criteria, which indirectly addresses the issue of singletons as well.",4,5,5
"Hello all. I am trying to do a paired-end analysis. Ran the 2 fastq files with hisat2:pre class=""pre""><code class=""language-bash"">hisat2 -p 10 -x '..index_hg19/indexed' -1 R1_001.fastq.gz -2 R2_001.fastq.gz -S hisat2output.sam/code></pre>Then : pre class=""pre""><code class=""language-bash"">samtools view -@ 10 -bS hisat2output.sam &gt; hisat2.bamsamtools sort -@ 12 -n hisat2.bam &gt; testSort.bamsamtools fixmate -m -@ 12 testSort.bam testSort_fixmate.bam/code></pre>then i try to remove duplicates : pre class=""pre""><code class=""language-bash"">samtools markdup -r -@ 12 testSort_fixmate.bam &gt; testSort_fixmate-markdup.bam/code></pre>but returns problem : blockquote>  ERROR: queryname sorted, must be sorted by coordinate./blockquote>WHEN i don't use <code>-n</code> option in samtools sort , samtools markdup returns problem:blockquote>  ERROR: Coordinate sorted, require grouped/sorted by queryname./blockquote>I cant find where is the problem. Any help ? ","<strong>edited answer:</strong>You have to <strong>name-sort</strong> for <code>samtools fixmate</code>, and <strong>coordinate-sort</strong> for <code>samtools markdup</code>. Here is the correct order of operations, from samtools man file:pre class=""pre""><code class=""language-bash""># The first sort can be omitted if the file is already name orderedsamtools sort -n -o namesort.bam example.bam# Add ms and MC tags for markdup to use latersamtools fixmate -m namesort.bam fixmate.bam# Markdup needs position ordersamtools sort -o positionsort.bam fixmate.bam# Finally mark duplicatessamtools markdup positionsort.bam markdup.bam/code></pre>strong>original answer</strong>The problem is you are sorting by name (<code>samtools sort -n</code>), and you should sort by coordinate:pre class=""pre""><code class=""language-bash"">samtools sort -@ 12 hisat2.bam &gt; testSort.bam/code></pre>","It seems like you're encountering an issue with sorting requirements for different steps in your analysis pipeline. When you use `samtools sort -@ 12 -n hisat2.bam > testSort.bam`, you're sorting the BAM file by read name (queryname), which is necessary for `samtools fixmate` to work correctly, as `fixmate` requires the input to be sorted by name to properly identify and fix mate-pair information. However, `samtools markdup`, which is used for marking or removing duplicates, requires the input to be sorted by coordinates, not by read name. This is why you're seeing the error ""ERROR: queryname sorted, must be sorted by coordinate"" when you try to run `samtools markdup` after sorting by read name.

On the other hand, if you don't use the `-n` option with `samtools sort`, meaning you're sorting by coordinates, you then encounter the opposite problem when trying to run `samtools markdup` without first sorting by name, as indicated by the error ""ERROR: Coordinate sorted, require grouped/sorted by queryname."" This error seems a bit unusual in the context of `samtools markdup`, as `markdup` typically requires coordinate sorting, not name sorting. It's possible there might be a misunderstanding or a typo in the error message you've encountered here.

To resolve your issue, follow these steps:

1. After running `hisat2`, use `samtools view` to convert the SAM file to an unsorted BAM file.
2. Sort the BAM file by coordinates using `samtools sort` without the `-n` option. This step is crucial for duplicate marking/removal.
3. Run `samtools markdup` on the coordinate-sorted BAM file to mark or remove duplicates.

If you need to use `samtools fixmate`, ensure it's done before the duplicate marking step and after sorting by name. However, for marking duplicates with `samtools markdup`, the sorting must be by coordinates. Therefore, the typical workflow would be: mapping (with `hisat2`), converting to BAM (with `samtools view`), sorting by coordinates (with `samtools sort`), and then marking/removing duplicates (with `samtools markdup`). If `fixmate` is necessary for your analysis, make sure to incorporate it at the appropriate step, keeping in mind the sorting requirements for each command.",4,5,4
"Usually when I use alignment with bwa, I follow this script:  code>bwa aln reference.fa sample.fastq.gz &gt; sample.sai</code>But this time I have manifest.txt and I want to target specific regions with this and I want to speed the alignment process with specific output. If It is possible in BWA, I would like to get your answers. Any help is much appreciated. Thanks in advance. ","you need to map everything first, convert this ""manifest.txt"" file as a bed file and extract the regions. <a rel=""nofollow"" href=""https://www.biostars.org/p/49306/"">Samtools And Region List</a>","Using BWA to align sequencing reads to a reference genome is a common practice in bioinformatics. However, when you have a specific set of regions you're interested in, such as those listed in a manifest file, and you want to speed up the alignment process, you might need to adjust your workflow slightly. BWA itself does not directly support targeted alignment based on a manifest file. The manifest file, which typically lists specific genomic regions or targets, would need to be used in conjunction with other tools to achieve your goal.

One approach to incorporate the manifest file into your alignment process is to first extract the regions of interest from your reference genome using tools like `bedtools` with your manifest file (assuming it's in a format like BED). Then, you can align your reads to this smaller, targeted reference genome using BWA, which should speed up the alignment process due to the reduced size of the reference. The command you mentioned, `bwa aln reference.fa sample.fastq.gz > sample.sai`, is for the alignment step, and it remains largely the same, except you would replace `reference.fa` with the path to your newly created, smaller reference file.

Remember, this approach simplifies the process and assumes your manifest file is ready to use with tools like `bedtools`. If your manifest isn't in a BED format or similar, you'll need to convert it first. Also, while this method can speed up the alignment by focusing on specific regions, it's essential to ensure that the regions extracted are precisely what you're interested in, as any discrepancies could lead to missing or incorrect data in your final analysis.",4,4,4
"Hi all,Currently, after mapping, I got a sam file which contained approximately 30 million mapped reads. Then, by using bedtool bamtobed, I was able to obtain a bed file. However, there were so many many similar reads.Therefore, in order to reduce the size of the final bed file, is there any way that I can mention each read only once as well as its number of presentation in the sam file.hr>For instance:hr>var_1     0     15      ATGCATGCATGCCGTAhr>var_1     0     15      ATGCATGCATGCCGTAhr>var_1     0     15      ATGCATGCATGCCGTAhr>var_2     5     20      ATGCATGCGGGCCCChr>Will become:hr>var_1     0     15      ATGCATGCATGCCGTA   3hr>var_2     5     20      ATGCATGCGGGCCCC    1Thank you in advance!","Use <code>uniq -c</code> your bed file.pre class=""pre""><code class=""language-bash"">uniq -c mybed.bed &gt; uniqbed.bed/code></pre>orpre class=""pre""><code class=""language-bash"">echo ""var_1 0 38 ATGCATGCATGCCGTAvar_1 0 38 ATGCATGCATGCCGTAvar_1 0 38 ATGCATGCATGCCGTAvar_2 5 40 ATGCATGCGGGCCCC"" | uniq -c3 var_1 0 38 ATGCATGCATGCCGTA1 var_2 5 40 ATGCATGCGGGCCCC/code></pre>","To achieve the reduction of your BED file by consolidating identical reads and annotating them with their occurrence count, you can utilize a combination of UNIX command-line tools. After obtaining the BED file using `bedtools bamtobed`, you can sort the file and then use `uniq -c` to count the occurrences of each unique line. The `uniq -c` command prefixes lines by their count. However, this output will have the count at the beginning of each line, which is slightly different from your desired format. To rearrange the output to match your example, you can use `awk`. Specifically, you would first sort your BED file using `sort yourfile.bed > sorted.bed`. Then, you can pipe this sorted file into `uniq -c` to count the occurrences, and finally use `awk` to format the output correctly: `uniq -c sorted.bed | awk '{print $2, $3, $4, $5, $1}' > final_output.bed`. This `awk` command rearranges the fields so that the count (`$1`) is moved to the end of the line, and the rest of the fields are ordered as per your requirement. This process will give you a BED file where each unique read is mentioned once along with its count of presentation, effectively reducing the size of your final BED file and making it more manageable for downstream analysis.",3,5,5
"Hi, Given a sorted bam file from standard 10x cell ranger output, i.e. from <a rel=""nofollow"" href=""https://support.10xgenomics.com/single-cell-vdj/datasets/4.0.0/sc5p_v1p1_hs_PBMC_1k"">https://support.10xgenomics.com/single-cell-vdj/datasets/4.0.0/sc5p_v1p1_hs_PBMC_1k</a>, I am wondering if it's possible to convert this scRNA-seq bam file to a bulk RNA-seq (""pseudo-bulk"") bam file, e.g. combining reads across all cell barcodes in the bam file?I imagine there is a way to do this using samtools, but could not find any examples.  Any help would be much appreciated.  Thanks!","It's a normal bam file, just with a few extra tags with cell barcodes and such. You can read more about the tags on the 10X website <a rel=""nofollow"" href=""https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/output/bam"">here</a>. Because there is nothing special about it, you can use any feature counting software designed for RNA-seq, such as Subread or HTSeq.","Yes, it is indeed possible to convert a sorted BAM file from 10x Genomics scRNA-seq data into a ""pseudo-bulk"" RNA-seq BAM file by combining reads across all cell barcodes. This process involves manipulating the BAM file to disregard the cell barcode information and treat all reads as if they originated from a single bulk sample. While specific tools designed for this task might exist, you can achieve this using `samtools` and some scripting. 

First, you would use `samtools view` to convert the BAM file to SAM format for easier manipulation. Then, you could use a scripting language like Python or bash to remove or ignore the cell barcode information in the read names and tags. This step might involve modifying the read names to make them unique again if necessary. After processing, you would convert the modified SAM file back to BAM format using `samtools view`, and then sort and index the BAM file using `samtools sort` and `samtools index`, respectively. 

It's important to note that by combining all reads, you lose the single-cell resolution provided by the cell barcodes, and the resulting data will not reflect the heterogeneity present in the original sample. This approach, however, can be useful for certain analyses where single-cell resolution is not necessary or when a bulk RNA-seq comparison is needed. Always ensure that the final BAM file is correctly formatted and indexed for compatibility with downstream analysis tools.",3,5,5
"I would like to know how BWA mem handles repetitive hits.I know that bwa aln/samse- given a read that maps to multiple regions- will randomly select one region. Each query will be listed once in the sam file, and alternative mapping locations for that read will be listed in XA if the number of hits is less than INT hits.But what about BWA mem? I keep reading that BWA mem differs from bwa aln in that it will split queries, but what about reads that aren't split but still map to multiple locations? Does mem also chose a random location? Are multiply mapped reads reported in the same fashion in bwa mem as they are for bwa aln/samse (that is, with one listing per query and XAs reported if less than INT)? For simplicity's sake, I am not interested in using other aligners. I have pre-trimmed RAD data (80-139bp) from a frog species with a highly repetitive genome.Thank you.","In general, short read aligners take some liberties in the way they report the alignments - as it turns out bwa is no different.Alas in most cases there is surprisingly little information in the docs on the specifics on what gets reported in which way. The following ismy best understanding of how <code>bwa mem</code> chooses to report alignments:ol>li>When a read matches in its entirety, with an equal score in multiple locations, one of the locations is picked at random, is labeled as primary, will be given a mapping quality of zero and will have an XA tag that contains the alternative locations (this is identical to how <code>bwa aln</code> worked)/li>li>When different, non-overlapping regions of a read align with high scores to different, non-linear locations in the genome, the higher score alignment will be labeled as primary, the others may be reported as secondary alignments. There is some threshold on how many of these secondary alignments will be reported (<code>bwa aln</code> did not produce secondary alignments)/li>li>When complementary regions of a read (the pieces add up to the full read) align to different, non-linear genomic locations, with no little to no overlap, one of the alignments will be labeled as primary, the others as supplementary alignments (<code>bwa aln</code> did not produce supplementary alignments)/li>/ol>","BWA-MEM, an algorithm designed for aligning sequence reads ranging from 70bp to 1Mbp, handles repetitive hits differently than BWA aln/samse. Unlike BWA aln, which might randomly select a region for a read that maps to multiple locations, BWA-MEM employs a more sophisticated approach to deal with multi-mapping reads. It does not simply choose a random location; instead, BWA-MEM attempts to identify the most likely origin of the read by scoring different alignments and may report the best scoring alignments. For reads that map to multiple locations without being split, BWA-MEM can still report multiple alignments, but it prioritizes the primary alignment based on its scoring system. The secondary alignments are marked differently in the SAM file, using flags to indicate their status. The algorithm also supports the reporting of alternative hits in a similar fashion to BWA aln, using the XA tag for reads with a number of hits below a certain threshold. This approach allows BWA-MEM to handle repetitive regions more effectively by providing a more nuanced view of where a read might originate from, rather than randomly assigning a location or merely listing alternative locations without prioritization. This capability makes BWA-MEM particularly useful for aligning reads from genomes with high levels of repetition, such as your frog species, by offering a more detailed and informative mapping outcome.",4,5,4
"Hi!I am trying to do an heatmap with pheatmap package but I keep getting this error : blockquote>  Error in hclust(d, method = method) :   NA/NaN/Inf in foreign function  call (arg 10)/blockquote>I have tried with <code>na.omit()</code> and looking at the dataset there is not NA. here my dataset:pre class=""pre""><code class=""language-bash""># A tibble: 5 x 8  `Gene descripti~ `Gene symbol`  mu_p0 `mu_ p2_`  &lt;chr&gt;            &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;1 RIKEN cDNA 0610~ 0610005C13RIK  0.797      1.042 RIKEN cDNA 0610~ 0610007C21RIK 99.9      129.  3 RIKEN cDNA 0610~ 0610007L01RIK 28.4       32.7 4 RIKEN cDNA 0610~ 0610007P08RIK  6.13       2.615 RIKEN cDNA 0610~ 0610007P14RIK 37.9       37.7/code></pre>and here my code:pre class=""pre""><code class=""language-bash"">library(gplots) library(pheatmap)library(RColorBrewer)library(tidyr)mouse &lt;- Mousebaseline %&gt;% drop_na() #remove rows with NA from the merged filedrnames &lt;- mouse$`Gene symbol`#select namemouse &lt;- mouse[-c(1:2)]# remove gene symbolmouse.matrix &lt;-(as.matrix(mouse))rownames(mouse.matrix) &lt;- rnames # assign row namesmouse.matrix &lt;- t(mouse.matrix) #transposemouseUT &lt;- scale(mouse.matrix)pheatmap(mouseUT, scale = ""none"",cluster_rows = T, cluster_cols = T, show_rownames = T, show_colnames = F, clustering_method = ""ward.D2"",border_color= NA, main = ""Mouse baseline (Ward.D2)"")/code></pre>it gives me the same error even if I do not scale prior the heatmap like:pre class=""pre""><code class=""language-bash"">pheatmap(mouse.matrix, scale = ""column"",cluster_rows = T, cluster_cols = T, show_rownames = T, show_colnames = F, clustering_method = ""ward.D2"",border_color= NA, main = ""Mouse baseline (Ward.D2)"")/code></pre>also if I do <code>na.omit()</code> as follow:pre class=""pre""><code class=""language-bash"">library(gplots) library(pheatmap)library(RColorBrewer)library(tidyr)mouse &lt;- Mousebaseline %&gt;% drop_na() #remove rows with NA from the merged filedrnames &lt;- mouse$`Gene symbol`#select namemouse &lt;- mouse[-c(1:2)]# remove gene symbolmouse.matrix &lt;-(as.matrix(mouse))rownames(mouse.matrix) &lt;- rnames # assign row namesmouse.matrix &lt;- t(mouse.matrix) #transposemouseUT &lt;- scale(mouse.matrix)mouseUT&lt;- na.omit(mouseUT)pheatmap(mouseUT, scale = ""none"",cluster_rows = T, cluster_cols = T, show_rownames = T, show_colnames = F, clustering_method = ""ward.D2"",border_color= NA, main = ""Mouse baseline (Ward.D2)"")/code></pre>I got this error: blockquote>  Error in hclust(d, method = method) : must have n &gt;= 2 objects to  cluster/blockquote>thank you for you help!camilla",Remove all the rows which have <code>0</code> values across the samplesYou may have all the rows having <code>0</code> values in the dataframe,"It seems like you're encountering a common issue when trying to generate a heatmap with the `pheatmap` package in R. The error message `NA/NaN/Inf in foreign function call (arg 10)` typically indicates that there are missing or infinite values in your data, or that the data might contain values that cannot be handled by the clustering algorithm (e.g., all zeros in a row/column after scaling).

First, ensure that your dataset does not contain any `Inf` or `-Inf` values, as these can also cause the error you're seeing. You've already checked for `NA` values and attempted to remove them, which is a good first step. However, it's also important to check for infinite values using something like `is.infinite()` and replace or remove them as necessary.

Second, when you scale your data using `scale(mouse.matrix)`, it's possible for rows or columns to end up with a standard deviation of zero, especially if all values in a row/column are the same. This can lead to `NA` values after scaling, which might not be immediately obvious. You can check the scaled data (`mouseUT`) for `NA` values before passing it to `pheatmap`.

Third, the error `must have n >= 2 objects to cluster` suggests that after omitting `NA` values with `na.omit(mouseUT)`, your dataset might be reduced to a size that is too small for clustering. This could happen if `na.omit()` removes too much of your data, possibly due to the presence of `NA` values in your scaled data. Instead of using `na.omit()` on the entire dataset, consider handling `NA` or infinite values on a per-row or per-column basis before scaling.

To troubleshoot and resolve these issues, you can:

1. Check and handle `Inf` or `-Inf` values in your dataset.
2. Carefully inspect your data after scaling to ensure no `NA` values are introduced by the scaling process.
3. Consider using alternative scaling or normalization methods that ensure your data remains suitable for clustering.
4. If your dataset is very small or becomes very small after cleaning, ensure you have enough data points for clustering (at least 2).

Remember, the goal of preprocessing your data for a heatmap is to ensure it's in a format that can be effectively clustered and visualized, which sometimes requires careful handling of special cases like `NA`, `Inf`, and uniform data rows/columns.",4,5,5
"Hi, I need to get 5'-end position of each read in <a rel=""nofollow"" href=""http://samtools.sourceforge.net/SAM1.pdf"">SAM</a> file. For reads aligned in forward direction it's provided in <a rel=""nofollow"" href=""http://samtools.sourceforge.net/SAM1.pdf"">SAM</a> file (POS). But for reads aligned onto reverse strand the one has to figure it out from the cigar string. You cannot simple add length of the read to left-most position, as reads may be soft-clipped or some indel may occure. I have written simple python function in order to find right most position of aligned read. Could you have a look and comment on that as I'm not sure if it's correct?pre><code>import re#should nicely separate CIGAR entriescigar_pat = re.compile(r""\d+[MIDNSHP=X]{1}"")def cigar2end( left,cigar ):  """"""Return right-most position of aligned read.""""""  #store info about each CIGAR category  counts={ ""M"":0, #M 0 alignment match (can be a sequence match or mismatch)           ""I"":0, #I 1 insertion to the reference           ""D"":0, #D 2 deletion from the reference           ""N"":0, #N 3 skipped region from the reference           ""S"":0, #S 4 soft clipping (clipped sequences present in SEQ)           ""H"":0, #H 5 hard clipping (clipped sequences NOT present in SEQ)           ""P"":0, #P 6 padding (silent deletion from padded reference)           ""="":0, #= 7 sequence match           ""X"":0, #X 8 sequence mismatch        }  #split cigar entries  for centry in cigar_pat.findall(cigar):    ccount  = int(centry[:-1])    csymbol = centry[-1]    counts[csymbol] = ccount  #get number of aligned 'reference' bases  aligned = counts[""M""] + counts[""D""] + counts[""N""] #+ counts[""=""] + counts[""X""]  right   = left + aligned  return right/code></pre>","As Sean suggested I use <a rel=""nofollow"" href=""http://code.google.com/p/pysam/"">pysam</a>:pre class=""pre""><code class=""language-bash"">import pysamsamfile = pysam.Samfile( ""somefile.bam"",""rb"" )#process all reads in regionfor sam in samfile.fetch( ref,start,end ):    print sam.pos, sam.aend/code></pre>","Your Python function `cigar2end` aims to calculate the right-most position of an aligned read in a SAM file, taking into account the complexities introduced by the CIGAR string. The function correctly identifies the need to parse the CIGAR string to account for various operations that affect the alignment length on the reference sequence. However, there are a few issues and improvements to consider:

1. **CIGAR Parsing**: Your function parses the CIGAR string and updates the counts for each operation found. However, it replaces the count for each operation with the most recent one found rather than summing them up. This means if a CIGAR string has multiple operations of the same type, only the last one will be considered. You should sum these counts instead of replacing them.

2. **Operations Considered**: You correctly include 'M', 'D', and 'N' operations in the calculation of the aligned reference bases. These operations consume the reference sequence and thus should be included in the calculation of the right-most position. However, you've commented out the '=' and 'X' operations. Both '=' and 'X' also consume the reference and should be included in the calculation. The '=' operation denotes a sequence match, and 'X' denotes a sequence mismatch, both of which consume reference bases just like 'M'.

3. **Return Value Calculation**: The calculation of the `right` variable correctly adds the number of aligned reference bases to the left-most position (`left`). However, since the left-most position is 1-based (as per SAM format specification), and you're calculating the length of the alignment, you should subtract 1 to get the correct right-most position. The correct formula should be `right = left + aligned - 1`.

4. **Function Documentation**: It's good practice to include in your function's documentation that the `left` parameter is expected to be the left-most, 1-based position of the aligned read from the SAM file, and that the function returns the 1-based right-most position of the alignment on the reference sequence.

Here's a revised version of your function with the above points addressed:

```python
import re

# Compile a pattern to nicely separate CIGAR entries
cigar_pat = re.compile(r""\d+[MIDNSHP=X]{1}"")

def cigar2end(left, cigar):
    """"""Return the 1-based right-most position of an aligned read, considering CIGAR string.""""""
    counts = {""M"": 0, ""I"": 0, ""D"": 0, ""N"": 0, ""S"": 0, ""H"": 0, ""P"": 0, ""="": 0, ""X"": 0}
    
    # Split CIGAR entries and sum counts for each operation
    for centry in cigar_pat.findall(cigar):
        ccount = int(centry[:-1])
        csymbol = centry[-1]
        counts[csymbol] += ccount
    
    # Get number of aligned 'reference' bases (including matches, mismatches, deletions, and skipped regions)
    aligned = counts[""M""] + counts[""D""] + counts[""N""] + counts[""=""] + counts[""X""]
    right = left + aligned - 1  # Adjust for 1-based position
    
    return right
```

This revised function now correctly sums the counts for each CIGAR operation and includes all operations that consume the reference sequence in the calculation of the alignment length. It also correctly calculates the right-most position based on 1-based indexing.",1,4,4
"Hi Guys,I have a BAM file, and a big read list. What I want to do is to remove the reads in the read list from the BAM file. I can transform Bam to Sam file and then use a Python script to remove unwanted reads. And then transform Sam to Bam again. But I am wondering if there is a more efficient way, which I mean faster, easier, and memory-efficient, to achieve this goal?Any advice is appreciated!Tao","<a rel=""nofollow"" href=""http://broadinstitute.github.io/picard/command-line-overview.html#FilterSamReads"">picard FilterSamReads</a>blockquote>  <strong>READ_LIST_FILE (File)</strong>    Read List File containing reads that will be included or excluded from the OUTPUT SAM or BAM file. Default value: null./blockquote>","Certainly, Tao! A more efficient way to remove specific reads from a BAM file without converting it to SAM and back again involves using tools like `samtools` and `bedtools`, which are designed for efficient manipulation of large sequencing files. First, ensure your read list is in a format that can be easily used to filter the BAM file, such as a text file with one read name per line. You can then use `samtools view` in combination with a custom script (bash or Python) to directly filter out the unwanted reads. Specifically, you can use `samtools view` to stream the BAM file and pipe it into a script that checks each read against your list, only passing through those reads not in your list. This avoids the memory-intensive step of converting the entire file into SAM format and then back to BAM. For example, using `samtools view` to output the BAM as SAM lines (`-h` for header), piping this into a Python script that filters out the unwanted reads, and then using `samtools view` again to convert it back to BAM format on the fly. This method is significantly faster, more memory-efficient, and easier once set up, as it leverages the optimized performance of `samtools` for handling large sequencing files and avoids unnecessary file format conversions.",4,5,5
"I have a series of BWA index files ( *.amb *.ann *.bwt, etc) but the original reference fasta sequences are not available. Assuming that it's a complete burrows-wheeler index, the complete reference should be encoded in those indices.Does anyone know if/how the fasta can be re-extracted from them?","This is an interesting question. It definitely should be possible, so I guess the question may be how to do it with existing tools and the least amount of pain.I looked into it, and it seems that from the ""https://github.com/mruffalo/bwt-sw"" rel=""nofollow"">original bwtsw code</a> (that bwa relies on, particularly for the indexing steps), the ""packed"" fasta file (<code>pac</code>) is the key file to use. This is supported by looking at the order of the indexing substeps of <code>fa2pac</code>, <code>pac2bwt</code>, and finally <code>bwt2sa</code>.So as an informed guess I searched for ""pac2fasta"", and (surprisingly to me) found an existing utility in the ""https://github.com/iontorrent/TMAP/"" rel=""nofollow"">TMAP package</a>. I believe, based on some quick tests, that the binary format for their <code>pac</code> file is the same as bwa uses (and bwtsw), aside from some embedded version numbers. The only catch is that TMAP has a binary annotation file (<code>$ref.tmap.anno</code>) that stores the chromosome names and lengths, whereas bwa uses a plaintext annotation file (<code>$ref.ann</code>). So if this is really what you want to do, it looks like you'll have to hardcode things (that's what I did to test with a small single chromosome reference) or write some code to make a TMAP annotation file from a bam header or bwa <code>.ann</code> file (by working through <code>tmap_refseq_write_header</code> in ""https://github.com/iontorrent/TMAP/blob/master/src/index/tmap_refseq.c"" rel=""nofollow"">tmap_refseq.c</a>).","Reconstructing the original FASTA sequences from BWA index files (such as *.amb, *.ann, *.bwt, etc.) is not straightforward and, under most circumstances, is not directly possible in a complete and accurate manner. The BWA indices are designed for efficient alignment and not for storing the original sequences in a form that can be easily reversed. The *.bwt file, which contains the Burrows-Wheeler Transform (BWT) of the reference, encodes the sequence in a way that facilitates fast search operations but does not store the sequence explicitly. While theoretically, some information about the sequence can be inferred from the BWT and other index files, reconstructing the exact original sequence would require additional information not present in these files. Tools and methods for extracting sequences from BWA indices are not commonly available, and any attempt to do so would likely result in incomplete or ambiguous sequences. Therefore, the best approach to obtaining the original sequences would be to locate the original FASTA files or to obtain the reference genome from a public database if the source is known.",1,4,1
