{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a1d334c-4ffa-4b85-aac1-be2d193364d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (0.3.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain_community) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain_community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.6 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain_community) (0.3.7)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.14 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain_community) (0.3.15)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain_community) (0.1.139)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain_community) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.6->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.6->langchain_community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.14->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.14->langchain_community) (24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.14->langchain_community) (4.11.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (4.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.14->langchain_community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain_community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain_community) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: azure-ai-ml in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (1.21.1)\n",
      "Requirement already satisfied: pyyaml>=5.1.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-ai-ml) (6.0.1)\n",
      "Requirement already satisfied: msrest>=0.6.18 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-ai-ml) (0.7.1)\n",
      "Requirement already satisfied: azure-core>=1.23.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-ai-ml) (1.32.0)\n",
      "Requirement already satisfied: azure-mgmt-core>=1.3.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-ai-ml) (1.5.0)\n",
      "Requirement already satisfied: marshmallow>=3.5 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-ai-ml) (3.23.0)\n",
      "Requirement already satisfied: jsonschema>=4.0.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-ai-ml) (4.22.0)\n",
      "Requirement already satisfied: tqdm in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-ai-ml) (4.66.4)\n",
      "Requirement already satisfied: strictyaml in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-ai-ml) (1.7.3)\n",
      "Requirement already satisfied: colorama in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-ai-ml) (0.4.6)\n",
      "Requirement already satisfied: pyjwt in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-ai-ml) (2.9.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.10.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-ai-ml) (12.23.1)\n",
      "Requirement already satisfied: azure-storage-file-share in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-ai-ml) (12.19.0)\n",
      "Requirement already satisfied: azure-storage-file-datalake>=12.2.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-ai-ml) (12.17.0)\n",
      "Requirement already satisfied: pydash>=6.0.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-ai-ml) (8.0.3)\n",
      "Requirement already satisfied: isodate in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-ai-ml) (0.7.2)\n",
      "Requirement already satisfied: azure-common>=1.1 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-ai-ml) (1.1.28)\n",
      "Requirement already satisfied: typing-extensions in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-ai-ml) (4.11.0)\n",
      "Requirement already satisfied: opencensus-ext-azure in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-ai-ml) (1.1.13)\n",
      "Requirement already satisfied: opencensus-ext-logging in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-ai-ml) (0.1.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-core>=1.23.0->azure-ai-ml) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-core>=1.23.0->azure-ai-ml) (1.16.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-storage-blob>=12.10.0->azure-ai-ml) (43.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (0.18.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from marshmallow>=3.5->azure-ai-ml) (24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from msrest>=0.6.18->azure-ai-ml) (2024.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from msrest>=0.6.18->azure-ai-ml) (2.0.0)\n",
      "Requirement already satisfied: azure-identity<2.0.0,>=1.5.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opencensus-ext-azure->azure-ai-ml) (1.19.0)\n",
      "Requirement already satisfied: opencensus<1.0.0,>=0.11.4 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opencensus-ext-azure->azure-ai-ml) (0.11.4)\n",
      "Requirement already satisfied: psutil>=5.6.3 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opencensus-ext-azure->azure-ai-ml) (5.9.8)\n",
      "Requirement already satisfied: python-dateutil>=2.6.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from strictyaml->azure-ai-ml) (2.9.0.post0)\n",
      "Requirement already satisfied: msal>=1.30.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure->azure-ai-ml) (1.31.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure->azure-ai-ml) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (1.16.0)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (0.1.3)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (2.22.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (2.2.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml) (3.2.2)\n",
      "Requirement already satisfied: pycparser in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (2.22)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (1.65.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (4.25.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (1.25.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (2.35.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from msal-extensions>=1.2.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure->azure-ai-ml) (2.10.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: json5 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (0.9.25)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: evaluate in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (0.4.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from evaluate) (2.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from evaluate) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from evaluate) (0.23.2)\n",
      "Requirement already satisfied: packaging in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from evaluate) (24.0)\n",
      "Requirement already satisfied: filelock in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.14.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: rouge_score in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: nltk in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from nltk->rouge_score) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in /Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages (from nltk->rouge_score) (4.66.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_community\n",
    "%pip install azure-ai-ml\n",
    "%pip install -qU langchain-openai\n",
    "%pip install json5\n",
    "%pip install evaluate\n",
    "%pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f430c0b-3287-46a2-9871-50f08f536f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.azureml_endpoint import (\n",
    "    AzureMLOnlineEndpoint,\n",
    "    AzureMLEndpointApiType,\n",
    "    DollyContentFormatter,\n",
    "    ContentFormatterBase\n",
    ")\n",
    "from typing import Dict\n",
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "import time\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_community.retrievers import AzureAISearchRetriever\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_community.chat_models.azureml_endpoint import (\n",
    "    AzureMLEndpointApiType,\n",
    "    CustomOpenAIChatContentFormatter,\n",
    ")\n",
    "from langchain_community.chat_models.azureml_endpoint import AzureMLChatOnlineEndpoint\n",
    "\n",
    "import json5\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74a3d36-8870-4cdc-a039-a31c6d8afb5d",
   "metadata": {},
   "source": [
    "#### 1st Agent: Fine-tuned LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1b983e-9bf7-4b47-b427-918fbfe6e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True)\n",
    "\n",
    "class CustomFormatter(ContentFormatterBase):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def format_request_payload(self, prompt: str, *args, **kwargs) -> bytes:\n",
    "        model_kwargs = kwargs.get('model_kwargs', {})\n",
    "        input_str = json.dumps(\n",
    "            {\"input_data\": [{\"role\": \"user\", \"content\": prompt}], \"params\": {\"temperature\": 0.1, \"max_new_tokens\": 1000, \"do_sample\": True}}\n",
    "        )\n",
    "        return str.encode(input_str)\n",
    "\n",
    "    def format_response_payload(self, output: bytes, *args, **kwargs) -> Dict:\n",
    "        response_json =  json.loads(output)\n",
    "\n",
    "        try:\n",
    "            # Step 1: Prepare JSON string\n",
    "            response_content = response_json['result'].replace(\"'\", \"\\\"\")\n",
    "\n",
    "            # Step 2: Escape double quotes within the `content` fields\n",
    "            response_content = re.sub(r'(?<=content\": \")', lambda m: m.group(0).replace('\"', '\\\\\"'), response_content)\n",
    "            response_content = response_content.replace('Here\"s', 'Here\\'s')\n",
    "            \n",
    "            # Step 3: Split the JSON string based on \"} {\" separator to handle multiple entries\n",
    "            json_entries = response_content.split(\"} {\")\n",
    "            \n",
    "            # Wrap entries in braces to create valid JSON for each entry\n",
    "            json_entries = [\"{\" + entry + \"}\" if not entry.startswith(\"{\") else entry for entry in json_entries]\n",
    "            json_entries = [entry + \"}\" if not entry.endswith(\"}\") else entry for entry in json_entries]\n",
    "            \n",
    "            # Step 4: Parse each JSON entry and retrieve assistant content\n",
    "            assistant_content = None\n",
    "            for json_string in json_entries:\n",
    "                # Regular expression to find \"role\": \"assistant\" and capture \"content\" value\n",
    "                match = re.search(r'\"role\"\\s*:\\s*\"assistant\",\\s*\"content\"\\s*:\\s*\"(.*?)\"\\s*}', json_string, re.DOTALL)\n",
    "\n",
    "                # Check if role is \"assistant\" and retrieve content\n",
    "                if match:\n",
    "                    assistant_content = match.group(1)  # Get the content text\n",
    "        \n",
    "            return {\"text\": assistant_content}\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON decode error: {e}\")\n",
    "\n",
    "        # Return a default response if there was an error\n",
    "            return {\"text\": \"No valid response\"}\n",
    "\n",
    "# Example usage of the CustomFormatter\n",
    "content_formatter = CustomFormatter()\n",
    "\n",
    "\n",
    "solver_llm = AzureMLOnlineEndpoint(\n",
    "    endpoint_url=\"\",\n",
    "    endpoint_api_type=AzureMLEndpointApiType.dedicated,\n",
    "    endpoint_api_key=\"\",\n",
    "    model_kwargs={\"temperature\": 0.1, \"max_new_tokens\": 1000, \"do_sample\": True},\n",
    "    content_formatter=content_formatter,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da9d27f-7a2a-42e6-910b-fb18b4f6d2a9",
   "metadata": {},
   "source": [
    "#### Second Agent: RAG + Phi-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c494d42-a270-4d81-acd6-f906d7328241",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for AzureAISearchRetriever\nmax_query_length\n  Extra inputs are not permitted [type=extra_forbidden, input_value=2000, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.9/v/extra_forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[196], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m AZURE_AI_SEARCH_SERVICE_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbioagentssearch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m AZURE_AI_SEARCH_API_KEY \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwyqRr5g53aVKRPfnmNCDymHxOSR0HanLcKFuEWALAWAzSeBtxjZQ\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[43mAzureAISearchRetriever\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAZURE_AI_SEARCH_SERVICE_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvector-rag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAZURE_AI_SEARCH_API_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchunk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_query_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Azure OpenAI setup\u001b[39;00m\n\u001b[1;32m     15\u001b[0m coder_llm \u001b[38;5;241m=\u001b[39m AzureMLChatOnlineEndpoint(\n\u001b[1;32m     16\u001b[0m     endpoint_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://bioagentspaper-rkdpb.eastus2.inference.ml.azure.com/score\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     endpoint_api_type\u001b[38;5;241m=\u001b[39mAzureMLEndpointApiType\u001b[38;5;241m.\u001b[39mdedicated,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     model_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_new_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1000\u001b[39m},\n\u001b[1;32m     21\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.12/site-packages/langchain_core/load/serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.12/site-packages/pydantic/main.py:212\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    211\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    214\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    218\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for AzureAISearchRetriever\nmax_query_length\n  Extra inputs are not permitted [type=extra_forbidden, input_value=2000, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.9/v/extra_forbidden"
     ]
    }
   ],
   "source": [
    "# Azure AI Search setup\n",
    "AZURE_AI_SEARCH_SERVICE_NAME = \"\"\n",
    "AZURE_AI_SEARCH_API_KEY = \"\"\n",
    "\n",
    "retriever = AzureAISearchRetriever(\n",
    "    service_name=AZURE_AI_SEARCH_SERVICE_NAME,\n",
    "    index_name=\"vector-rag\",\n",
    "    api_key=AZURE_AI_SEARCH_API_KEY,\n",
    "    content_key=\"chunk\",\n",
    "    top_k=1\n",
    ")\n",
    "\n",
    "# Azure OpenAI setup\n",
    "coder_llm = AzureMLChatOnlineEndpoint(\n",
    "    endpoint_url=\"\",\n",
    "    endpoint_api_type=AzureMLEndpointApiType.dedicated,\n",
    "    endpoint_api_key=\"\",\n",
    "    content_formatter=CustomOpenAIChatContentFormatter(),\n",
    "    model_kwargs={\"temperature\": 0.1, \"max_new_tokens\": 1000},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43d8ae1-3c5f-4abf-afc8-305b4ded983a",
   "metadata": {},
   "source": [
    "#### Reasoning Agent: Phi-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfa1633-d1e8-4b5d-8360-7914750fa2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_agent = AzureMLChatOnlineEndpoint(\n",
    "    endpoint_url=\"\",\n",
    "    endpoint_api_type=AzureMLEndpointApiType.dedicated,\n",
    "    endpoint_api_key=\"\",\n",
    "    content_formatter=CustomOpenAIChatContentFormatter(),\n",
    "    model_kwargs={\"temperature\": 0.1, \"max_new_tokens\": 1000},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e350ec3-fcee-44ee-bc4c-790aa05814f5",
   "metadata": {},
   "source": [
    "### Format csv to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4629ec2f-5426-414b-81eb-bfae00eb5660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"analysis_and_tools_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bb607a9-7cd8-41d7-a22f-f38e04f556c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file created successfully.\n"
     ]
    }
   ],
   "source": [
    "#preprocess data\n",
    "\n",
    "input_string = []\n",
    "\n",
    "# Iterate through the rows of the dataframe\n",
    "for index, row in df.iterrows():\n",
    "    # 'content' is the column with the user questions\n",
    "    user_content = row['content']\n",
    "    # 'answer content' is the column with the ground truth answers\n",
    "    assistant_content = row['answer_content']\n",
    "\n",
    "    # Append only user content to the input_data\n",
    "    input_string.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "# Define the parameters for the model\n",
    "params = {\n",
    "    \"temperature\": 0.1,\n",
    "    \"max_new_tokens\": 4096, #output\n",
    "    \"do_sample\": True,\n",
    "    \"return_full_text\": False\n",
    "}\n",
    "\n",
    "# Combine input data and parameters into the final test data structure\n",
    "test_data = {\n",
    "    \"input_data\": input_string,\n",
    "    \"parameters\": params\n",
    "}\n",
    "\n",
    "# Save the JSON output to a file\n",
    "with open('test_data.json', 'w') as json_file:\n",
    "    json.dump(test_data, json_file, indent=4)\n",
    "\n",
    "print(\"JSON file created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c87926-c12f-45ab-93ae-36cbae39b63f",
   "metadata": {},
   "source": [
    "#### Muti-Agent Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f4ba3e52-249f-4edc-96b9-808e3cc39d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    \"\"\"Format retrieved documents into a single string.\"\"\"\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs if doc.page_content) if docs else \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7ab4e6bb-1c8b-43d0-8024-87ed54843cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_with_retries(llm, prompt, max_retries=5, backoff_factor=2):\n",
    "    \"\"\"\n",
    "    Helper function to invoke LLM with retry logic in case of timeout or HTTP errors.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return llm.invoke(prompt, timeout=300000)  # Attempt to invoke LLM\n",
    "        except TimeoutError:\n",
    "            # Handle timeout errors with exponential backoff\n",
    "            sleep_time = backoff_factor * (2 ** attempt)\n",
    "            time.sleep(sleep_time)\n",
    "            print(f\"Timeout occurred. Retrying after {sleep_time} seconds... Attempt {attempt + 1}/{max_retries}\")\n",
    "        except HTTPError as e:\n",
    "            if e.code == 424:  # Handle HTTP 424: Failed Dependency\n",
    "                print(f\"HTTP Error 424: Failed Dependency. Skipping after {attempt + 1}/{max_retries} attempts.\")\n",
    "                return None\n",
    "            else:\n",
    "                print(f\"HTTP Error {e.code}: {e.reason}. Retrying...\")\n",
    "                sleep_time = backoff_factor * (2 ** attempt)\n",
    "                time.sleep(sleep_time)\n",
    "    print(f\"Max retries reached for {llm}.\")\n",
    "    return None  # Return None if all retries fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "6f7ee9db-555d-467f-a292-f2e4d1b05656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_query(query, chunk_size=1500):\n",
    "    return [query[i:i+chunk_size] for i in range(0, len(query), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "0f9de2b8-8085-4551-a5ab-cc083a6ff8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_response(query, tries=3, backoff_factor=1):\n",
    "    attempt = 0\n",
    "    final_response = \"\"\n",
    "    while attempt < tries:\n",
    "\n",
    "        # Step 1: Retrieve documents\n",
    "        \"\"\"Trim the string after the first occurrence of 'ETA:'.\"\"\"\n",
    "        eta_index = query.find(\"ETA:\")\n",
    "        if eta_index != -1:\n",
    "            query = query[:eta_index].strip()\n",
    "        query_chunks = chunk_query(query)\n",
    "        docs = []\n",
    "        for chunk in query_chunks:\n",
    "            docs.extend(retriever.invoke(chunk))\n",
    "        if not docs:\n",
    "            print(\"No documents found for the query.\")\n",
    "\n",
    "        # Step 2: Format documents\n",
    "        context = format_docs(docs)\n",
    "        if not context:\n",
    "            print(\"Formatted context is empty.\")\n",
    "\n",
    "        # Step 3: Generate prompt for coder LLM\n",
    "        prompt = f\"\"\"This is relevant code documentation: \\n{context}\\n\\nQuestion: {query}.\\nPlease respond with code.\"\"\"\n",
    "        response_coder = coder_llm.invoke(prompt)\n",
    "\n",
    "        # Process coder response\n",
    "        response_code = response_coder.content if hasattr(response_coder, 'content') else \"\"\n",
    "        if not response_code:\n",
    "            print(\"Unexpected response from coder LLM.\")\n",
    "\n",
    "        # Step 4: Generate solver response with retry on timeout\n",
    "        \n",
    "        solver_text = None\n",
    "        max_retries = 10\n",
    "        retries = 0\n",
    "        base_sleep = 5  # Start with a 5 second wait\n",
    "        sleep_time = base_sleep\n",
    "        \n",
    "        while retries < max_retries and solver_text is None:\n",
    "            solver_text = invoke_with_retries(solver_llm, query, max_retries=1)  # Retry logic for a single attempt\n",
    "            if solver_text is None:\n",
    "                print(f\"Retry {retries + 1}/{max_retries} failed. Retrying in {sleep_time} seconds...\")\n",
    "                time.sleep(sleep_time)\n",
    "                retries += 1\n",
    "                sleep_time *= 2  # Exponentially increase the sleep time for each retry\n",
    "\n",
    "        if solver_text is None:\n",
    "            print(\"Failed to get response from solver LLM after maximum retries.\")\n",
    "            solver_text = \"\"  # Fallback if all attempts fail\n",
    "\n",
    "        # Step 5: Generate reasoning prompt\n",
    "        prompt_reason = (\n",
    "            f\"You are an AI reasoning agent collaborating with other specialized assistants. \"\n",
    "            f\"There are two previous responses you should review: \"\n",
    "            f\"A solving agent specializing in bioinformatics tools has provided the following response: {solver_text}. \"\n",
    "            f\"A coder agent specializing in genomics analysis workflows written in Nextflow has provided the following response: {response_code}. \"\n",
    "            f\"Your task is to answer the user query: {query}. \"\n",
    "            f\"After you generate your response, print the quality rating of your output as Quality Rating: on a new line. using the scale 1-10 using format x/10.\"\n",
    "        )\n",
    "\n",
    "        combined_reasoning = reasoning_agent.invoke(prompt_reason)\n",
    "\n",
    "        # Step 6: Check reasoning response\n",
    "        if hasattr(combined_reasoning, 'content'):\n",
    "            final_response = combined_reasoning.content\n",
    "\n",
    "            match = re.search(r'Quality Rating: (\\d+)/10', final_response)\n",
    "\n",
    "            if match:\n",
    "                quality_rating = int(match.group(1))\n",
    "                if quality_rating > 7:\n",
    "                    print(\"Achieved satisfactory rating.\")\n",
    "                    return final_response, attempt # Return response if rating is above 7\n",
    "                else:\n",
    "                    print(\"Rating not satisfactory, continuing to next attempt.\")\n",
    "            else:\n",
    "                print(\"Quality Rating not found in the response.\")\n",
    "        else:\n",
    "            print(\"Reasoning agent did not return valid content.\")\n",
    "\n",
    "        # Backoff before the next attempt\n",
    "        sleep_time = backoff_factor * (2 ** attempt)  # Exponential backoff\n",
    "        print(f\"Sleeping for {sleep_time} seconds before next attempt.\")\n",
    "        time.sleep(sleep_time)\n",
    "        attempt += 1\n",
    "\n",
    "    print(\"Max attempts reached. Returning last response.\")\n",
    "    return final_response, attempt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a3f2297e-fee1-4d10-b81a-1f77741b7aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path for saving the real request file\n",
    "test_src_dir = \"./inference-test\"\n",
    "os.makedirs(test_src_dir, exist_ok=True)\n",
    "real_data_path = os.path.join(test_src_dir, \"test_data.json\")\n",
    "\n",
    "# Save the real request data to a JSON file\n",
    "with open(real_data_path, \"w\") as f:\n",
    "    json.dump(test_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c37e48bc-73bb-4e9a-8e15-a9e54f7d8c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and parameters\n",
    "timeout = 1000\n",
    "test_src_dir = \"./inference-test\"\n",
    "response_src_dir = \"./inference-responses\"\n",
    "batch_size = 1\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(test_src_dir, exist_ok=True)\n",
    "os.makedirs(response_src_dir, exist_ok=True)\n",
    "\n",
    "def batch_data(data, batch_size):\n",
    "    \"\"\"Split data into batches of given size.\"\"\"\n",
    "    return [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "\n",
    "\n",
    "# Create batches\n",
    "batches = batch_data(test_data[\"input_data\"], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ae402661-b57d-4b97-b4d4-d9d13e35fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_tasks(batch, id):\n",
    "\n",
    "    combined_query = batch[0]['content']\n",
    "\n",
    "    query = f\"\"\"Question: {combined_query}\\nPlease provide a solution in raw text.\"\"\"\n",
    "    final_response, tries = generate_final_response(query)\n",
    "    \n",
    "     # Save both input and response data\n",
    "    response_file_path = os.path.join(response_src_dir, f\"response_{id}.json\")\n",
    "    with open(response_file_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"input_data\": query,\n",
    "            \"response_data\": final_response,\n",
    "            \"attempts\": tries # Ensure result is JSON serializable\n",
    "        }, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "0ca52f07-bdd8-4692-af58-990f79b2a4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file './inference-responses/response_0.json' exists.\n",
      "The file './inference-responses/response_1.json' exists.\n",
      "The file './inference-responses/response_2.json' exists.\n",
      "The file './inference-responses/response_3.json' exists.\n",
      "The file './inference-responses/response_4.json' exists.\n",
      "The file './inference-responses/response_5.json' exists.\n",
      "The file './inference-responses/response_6.json' exists.\n",
      "The file './inference-responses/response_7.json' exists.\n",
      "The file './inference-responses/response_8.json' exists.\n",
      "The file './inference-responses/response_9.json' exists.\n",
      "The file './inference-responses/response_10.json' exists.\n",
      "The file './inference-responses/response_11.json' exists.\n",
      "The file './inference-responses/response_12.json' exists.\n",
      "The file './inference-responses/response_13.json' exists.\n",
      "The file './inference-responses/response_14.json' exists.\n",
      "The file './inference-responses/response_15.json' exists.\n",
      "The file './inference-responses/response_16.json' exists.\n",
      "The file './inference-responses/response_17.json' exists.\n",
      "The file './inference-responses/response_18.json' exists.\n",
      "The file './inference-responses/response_19.json' exists.\n",
      "The file './inference-responses/response_20.json' exists.\n",
      "The file './inference-responses/response_21.json' exists.\n",
      "The file './inference-responses/response_22.json' exists.\n",
      "The file './inference-responses/response_23.json' exists.\n",
      "The file './inference-responses/response_24.json' exists.\n",
      "The file './inference-responses/response_25.json' exists.\n",
      "The file './inference-responses/response_26.json' exists.\n",
      "The file './inference-responses/response_27.json' exists.\n",
      "The file './inference-responses/response_28.json' exists.\n",
      "The file './inference-responses/response_29.json' exists.\n",
      "The file './inference-responses/response_30.json' exists.\n",
      "The file './inference-responses/response_31.json' exists.\n",
      "The file './inference-responses/response_32.json' exists.\n",
      "The file './inference-responses/response_33.json' exists.\n",
      "The file './inference-responses/response_34.json' exists.\n",
      "The file './inference-responses/response_35.json' exists.\n",
      "The file './inference-responses/response_36.json' exists.\n",
      "The file './inference-responses/response_37.json' exists.\n",
      "The file './inference-responses/response_38.json' exists.\n",
      "The file './inference-responses/response_39.json' exists.\n",
      "The file './inference-responses/response_40.json' exists.\n",
      "The file './inference-responses/response_41.json' exists.\n",
      "The file './inference-responses/response_42.json' exists.\n",
      "The file './inference-responses/response_43.json' exists.\n",
      "The file './inference-responses/response_44.json' exists.\n",
      "The file './inference-responses/response_45.json' exists.\n",
      "The file './inference-responses/response_46.json' exists.\n",
      "The file './inference-responses/response_47.json' exists.\n",
      "The file './inference-responses/response_48.json' exists.\n",
      "The file './inference-responses/response_49.json' exists.\n",
      "The file './inference-responses/response_50.json' exists.\n",
      "The file './inference-responses/response_51.json' exists.\n",
      "The file './inference-responses/response_52.json' exists.\n",
      "The file './inference-responses/response_53.json' exists.\n",
      "The file './inference-responses/response_54.json' exists.\n",
      "The file './inference-responses/response_55.json' exists.\n",
      "The file './inference-responses/response_56.json' exists.\n",
      "The file './inference-responses/response_57.json' exists.\n",
      "The file './inference-responses/response_58.json' does not exist.\n",
      "Working on 59 question\n",
      "Timeout occurred. Retrying after 2 seconds... Attempt 1/1\n",
      "Max retries reached for \u001b[1mAzureMLOnlineEndpoint\u001b[0m\n",
      "Params: {'deployment_name': '', 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 1000, 'do_sample': True, 'timeout': 300000}}.\n",
      "Retry 1/10 failed. Retrying in 5 seconds...\n",
      "Timeout occurred. Retrying after 2 seconds... Attempt 1/1\n",
      "Max retries reached for \u001b[1mAzureMLOnlineEndpoint\u001b[0m\n",
      "Params: {'deployment_name': '', 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 1000, 'do_sample': True, 'timeout': 300000}}.\n",
      "Retry 2/10 failed. Retrying in 10 seconds...\n",
      "Timeout occurred. Retrying after 2 seconds... Attempt 1/1\n",
      "Max retries reached for \u001b[1mAzureMLOnlineEndpoint\u001b[0m\n",
      "Params: {'deployment_name': '', 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 1000, 'do_sample': True, 'timeout': 300000}}.\n",
      "Retry 3/10 failed. Retrying in 20 seconds...\n",
      "Timeout occurred. Retrying after 2 seconds... Attempt 1/1\n",
      "Max retries reached for \u001b[1mAzureMLOnlineEndpoint\u001b[0m\n",
      "Params: {'deployment_name': '', 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 1000, 'do_sample': True, 'timeout': 300000}}.\n",
      "Retry 4/10 failed. Retrying in 40 seconds...\n",
      "Timeout occurred. Retrying after 2 seconds... Attempt 1/1\n",
      "Max retries reached for \u001b[1mAzureMLOnlineEndpoint\u001b[0m\n",
      "Params: {'deployment_name': '', 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 1000, 'do_sample': True, 'timeout': 300000}}.\n",
      "Retry 5/10 failed. Retrying in 80 seconds...\n",
      "Timeout occurred. Retrying after 2 seconds... Attempt 1/1\n",
      "Max retries reached for \u001b[1mAzureMLOnlineEndpoint\u001b[0m\n",
      "Params: {'deployment_name': '', 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 1000, 'do_sample': True, 'timeout': 300000}}.\n",
      "Retry 6/10 failed. Retrying in 160 seconds...\n",
      "Timeout occurred. Retrying after 2 seconds... Attempt 1/1\n",
      "Max retries reached for \u001b[1mAzureMLOnlineEndpoint\u001b[0m\n",
      "Params: {'deployment_name': '', 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 1000, 'do_sample': True, 'timeout': 300000}}.\n",
      "Retry 7/10 failed. Retrying in 320 seconds...\n",
      "Timeout occurred. Retrying after 2 seconds... Attempt 1/1\n",
      "Max retries reached for \u001b[1mAzureMLOnlineEndpoint\u001b[0m\n",
      "Params: {'deployment_name': '', 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 1000, 'do_sample': True, 'timeout': 300000}}.\n",
      "Retry 8/10 failed. Retrying in 640 seconds...\n",
      "Timeout occurred. Retrying after 2 seconds... Attempt 1/1\n",
      "Max retries reached for \u001b[1mAzureMLOnlineEndpoint\u001b[0m\n",
      "Params: {'deployment_name': '', 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 1000, 'do_sample': True, 'timeout': 300000}}.\n",
      "Retry 9/10 failed. Retrying in 1280 seconds...\n",
      "Timeout occurred. Retrying after 2 seconds... Attempt 1/1\n",
      "Max retries reached for \u001b[1mAzureMLOnlineEndpoint\u001b[0m\n",
      "Params: {'deployment_name': '', 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 1000, 'do_sample': True, 'timeout': 300000}}.\n",
      "Retry 10/10 failed. Retrying in 2560 seconds...\n",
      "Failed to get response from solver LLM after maximum retries.\n",
      "Achieved satisfactory rating.\n",
      "The file './inference-responses/response_59.json' exists.\n",
      "The file './inference-responses/response_60.json' exists.\n",
      "The file './inference-responses/response_61.json' exists.\n",
      "The file './inference-responses/response_62.json' exists.\n",
      "The file './inference-responses/response_63.json' exists.\n",
      "The file './inference-responses/response_64.json' exists.\n",
      "The file './inference-responses/response_65.json' exists.\n",
      "The file './inference-responses/response_66.json' exists.\n",
      "The file './inference-responses/response_67.json' exists.\n",
      "The file './inference-responses/response_68.json' exists.\n",
      "The file './inference-responses/response_69.json' exists.\n",
      "The file './inference-responses/response_70.json' exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from urllib.error import HTTPError  # Adjust the import as needed based on your HTTP library\n",
    "\n",
    "# Example batch processing\n",
    "for i, batch in enumerate(batches):\n",
    "    response_file_path = os.path.join(response_src_dir, f\"response_{i}.json\")\n",
    "    \n",
    "    if os.path.exists(response_file_path):\n",
    "        print(f\"The file '{response_file_path}' exists.\")\n",
    "    else:\n",
    "        print(f\"The file '{response_file_path}' does not exist.\")\n",
    "        print(f\"Working on {i + 1} question\")\n",
    "        submit_tasks(batch, i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7410d883-de2a-4516-a12b-e3ea27c46429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Attempts</th>\n",
       "      <th>Quality Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Question: I used Hmmer search for finding doma...</td>\n",
       "      <td>To overcome the issue of HMMER identifying dom...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Question: I am looking for a good workflows, r...</td>\n",
       "      <td>To help you with SNP calling and understanding...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Question: Dear all,I have indexed the C. elega...</td>\n",
       "      <td>Quality Rating: 8/10\\n\\nDear C,\\n\\nThank you f...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Question: Hie NGS Geeks,Recently I observed so...</td>\n",
       "      <td>It seems like you're observing differences in ...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Question: How can I get the number of mapped r...</td>\n",
       "      <td>To get the number of mapped reads for a partic...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Question: I used Hmmer search for finding doma...   \n",
       "1  Question: I am looking for a good workflows, r...   \n",
       "2  Question: Dear all,I have indexed the C. elega...   \n",
       "3  Question: Hie NGS Geeks,Recently I observed so...   \n",
       "4  Question: How can I get the number of mapped r...   \n",
       "\n",
       "                                              Answer  Attempts  Quality Rating  \n",
       "0  To overcome the issue of HMMER identifying dom...         1               9  \n",
       "1  To help you with SNP calling and understanding...         1               9  \n",
       "2  Quality Rating: 8/10\\n\\nDear C,\\n\\nThank you f...         1               8  \n",
       "3  It seems like you're observing differences in ...         2               8  \n",
       "4  To get the number of mapped reads for a partic...         1              10  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "file_pattern = \"./inference-responses/*.json\"\n",
    "\n",
    "questions = []\n",
    "answers = []\n",
    "attempts = []\n",
    "quality_ratings = []\n",
    "\n",
    "\n",
    "for file_name in glob.glob(file_pattern): #glob lists all the text files in the current working dir.\n",
    "    with open(file_name, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "\n",
    "    if \"input_data\" in data: #retrieves list of dictionaries\n",
    "        question = data[\"input_data\"]\n",
    "        questions.append(question)\n",
    "\n",
    "    if \"response_data\" in data:\n",
    "        response = data[\"response_data\"]\n",
    "        answers.append(response)\n",
    "        match = re.search(r'Quality Rating: (\\d+)/10', response)\n",
    "        quality_rating = int(match.group(1))\n",
    "        quality_ratings.append(quality_rating)\n",
    "\n",
    "    if \"attempts\" in data:\n",
    "        attempt = data[\"attempts\"] + 1\n",
    "        attempts.append(attempt)\n",
    "\n",
    "final_df = pd.DataFrame({\"Question\": questions, \"Answer\": answers, \"Attempts\": attempts, 'Quality Rating': quality_ratings})\n",
    "\n",
    "# Save DataFrame to a CSV file (optional)\n",
    "final_df.to_csv('combined_questions_answers.csv', index=False)\n",
    "\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b19011-917b-4722-b18a-2555a936fa4d",
   "metadata": {},
   "source": [
    "#### ROUGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d0f80e-d417-46bb-b91f-0951c2efe0b9",
   "metadata": {},
   "source": [
    "########note: rouge captures (number of n-grams in prediction summary (fine-tuned phi-3 model) that match the reference summary (ground-truth)) / number of n-grams in reference summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b39b4f2-c700-481b-b824-a49e93b3f218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venkatmalladi/opt/anaconda3/envs/llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading builder script: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6.27k/6.27k [00:00<00:00, 5.11MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.121\n",
      "ROUGE-2: 0.012\n",
      "ROUGE-L: 0.071\n",
      "ROUGE-Lsum: 0.086\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "predictions = final_df[\"Answer\"].to_list()\n",
    "references = df[\"answer_content\"].to_list()\n",
    "\n",
    "rouge = evaluate.load('rouge') #https://huggingface.co/spaces/evaluate-metric/rouge\n",
    "\n",
    "\n",
    "results = rouge.compute(predictions=predictions,\n",
    "                         references=references,\n",
    "                        use_aggregator=True)\n",
    "\n",
    "print(\"ROUGE-1:\", round(results[\"rouge1\"], 3))\n",
    "print(\"ROUGE-2:\", round(results[\"rouge2\"], 3))\n",
    "print(\"ROUGE-L:\", round(results[\"rougeL\"], 3))\n",
    "print(\"ROUGE-Lsum:\", round(results[\"rougeLsum\"], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a7c77b5-bf57-4da9-8470-e149dbb7f04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = pd.DataFrame.from_dict(results.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec48d9b0-1852-4383-a3b7-4e090b71222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to a CSV file (optional)\n",
    "rouge.to_csv('biostars_multiagent_rouge.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "29e3743a-28d8-4112-947d-35c31fd5d9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Student ask: 'How would I provide quality metric on fastq files?' Provide the steps you would advise the student to take.\n",
      "Please explain your logic and reasoning behind your answer.\n",
      "What additional information do you need to answer the question?\n",
      "Please provide a solution in raw text.\n",
      "Achieved satisfactory rating.\n",
      "Question: Student ask: 'What code or workflow do I need to write to provide quality metric on fastq files?' Provide the steps you would advise the student to take.\n",
      "Please explain your logic and reasoning behind your answer.\n",
      "What additional information do you need to answer the question?\n",
      "Please provide a solution in raw text.\n",
      "Timeout occurred. Retrying after 2 seconds... Attempt 1/1\n",
      "Max retries reached for \u001b[1mAzureMLOnlineEndpoint\u001b[0m\n",
      "Params: {'deployment_name': '', 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 1000, 'do_sample': True, 'timeout': 300000}}.\n",
      "Retry 1/10 failed. Retrying in 5 seconds...\n",
      "Timeout occurred. Retrying after 2 seconds... Attempt 1/1\n",
      "Max retries reached for \u001b[1mAzureMLOnlineEndpoint\u001b[0m\n",
      "Params: {'deployment_name': '', 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 1000, 'do_sample': True, 'timeout': 300000}}.\n",
      "Retry 2/10 failed. Retrying in 10 seconds...\n",
      "Achieved satisfactory rating.\n",
      "Question: Student ask: 'How do I align RNA-seq data against human reference genome?' Provide the steps you would advise the student to take.\n",
      "Please explain your logic and reasoning behind your answer.\n",
      "What additional information do you need to answer the question?\n",
      "Please provide a solution in raw text.\n",
      "Achieved satisfactory rating.\n",
      "Question: Student ask: 'What code or workflow do I need to write to align RNA-seq data against human reference genome?' Provide the steps you would advise the student to take.\n",
      "Please explain your logic and reasoning behind your answer.\n",
      "What additional information do you need to answer the question?\n",
      "Please provide a solution in raw text.\n",
      "Achieved satisfactory rating.\n",
      "Question: Student ask: 'How can I assemble, annotate, and analyze SARS-CoV-2 genomes from sequencing data to identify and characterize different variants of the virus?' Provide the steps you would advise the student to take.\n",
      "Please explain your logic and reasoning behind your answer.\n",
      "What additional information do you need to answer the question?\n",
      "Please provide a solution in raw text.\n",
      "Achieved satisfactory rating.\n",
      "Question: Student ask: 'What code or workflow do I need to write to assemble, annotate, and analyze SARS-CoV-2 genomes from sequencing data to identify and characterize different variants of the virus?' Provide the steps you would advise the student to take.\n",
      "Please explain your logic and reasoning behind your answer.\n",
      "What additional information do you need to answer the question?\n",
      "Please provide a solution in raw text.\n",
      "Timeout occurred. Retrying after 2 seconds... Attempt 1/1\n",
      "Max retries reached for \u001b[1mAzureMLOnlineEndpoint\u001b[0m\n",
      "Params: {'deployment_name': '', 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 1000, 'do_sample': True, 'timeout': 300000}}.\n",
      "Retry 1/10 failed. Retrying in 5 seconds...\n",
      "Timeout occurred. Retrying after 2 seconds... Attempt 1/1\n",
      "Max retries reached for \u001b[1mAzureMLOnlineEndpoint\u001b[0m\n",
      "Params: {'deployment_name': '', 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 1000, 'do_sample': True, 'timeout': 300000}}.\n",
      "Retry 2/10 failed. Retrying in 10 seconds...\n",
      "Timeout occurred. Retrying after 2 seconds... Attempt 1/1\n",
      "Max retries reached for \u001b[1mAzureMLOnlineEndpoint\u001b[0m\n",
      "Params: {'deployment_name': '', 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 1000, 'do_sample': True, 'timeout': 300000}}.\n",
      "Retry 3/10 failed. Retrying in 20 seconds...\n",
      "Timeout occurred. Retrying after 2 seconds... Attempt 1/1\n",
      "Max retries reached for \u001b[1mAzureMLOnlineEndpoint\u001b[0m\n",
      "Params: {'deployment_name': '', 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 1000, 'do_sample': True, 'timeout': 300000}}.\n",
      "Retry 4/10 failed. Retrying in 40 seconds...\n",
      "Timeout occurred. Retrying after 2 seconds... Attempt 1/1\n",
      "Max retries reached for \u001b[1mAzureMLOnlineEndpoint\u001b[0m\n",
      "Params: {'deployment_name': '', 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 1000, 'do_sample': True, 'timeout': 300000}}.\n",
      "Retry 5/10 failed. Retrying in 80 seconds...\n",
      "Timeout occurred. Retrying after 2 seconds... Attempt 1/1\n",
      "Max retries reached for \u001b[1mAzureMLOnlineEndpoint\u001b[0m\n",
      "Params: {'deployment_name': '', 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 1000, 'do_sample': True, 'timeout': 300000}}.\n",
      "Retry 6/10 failed. Retrying in 160 seconds...\n",
      "Timeout occurred. Retrying after 2 seconds... Attempt 1/1\n",
      "Max retries reached for \u001b[1mAzureMLOnlineEndpoint\u001b[0m\n",
      "Params: {'deployment_name': '', 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 1000, 'do_sample': True, 'timeout': 300000}}.\n",
      "Retry 7/10 failed. Retrying in 320 seconds...\n",
      "Achieved satisfactory rating.\n"
     ]
    }
   ],
   "source": [
    "query_part1= [\"Student ask: 'How would I provide quality metric on fastq files?' Provide the steps you would advise the student to take.\",\n",
    "              \"Student ask: 'What code or workflow do I need to write to provide quality metric on fastq files?' Provide the steps you would advise the student to take.\",\n",
    "              \"Student ask: 'How do I align RNA-seq data against human reference genome?' Provide the steps you would advise the student to take.\",\n",
    "              \"Student ask: 'What code or workflow do I need to write to align RNA-seq data against human reference genome?' Provide the steps you would advise the student to take.\",\n",
    "              \"Student ask: 'How can I assemble, annotate, and analyze SARS-CoV-2 genomes from sequencing data to identify and characterize different variants of the virus?' Provide the steps you would advise the student to take.\",\n",
    "              \"Student ask: 'What code or workflow do I need to write to assemble, annotate, and analyze SARS-CoV-2 genomes from sequencing data to identify and characterize different variants of the virus?' Provide the steps you would advise the student to take.\"\n",
    "              ]\n",
    "\n",
    "query_part2= \"Please explain your logic and reasoning behind your answer.\"\n",
    "query_part3 = \"What additional information do you need to answer the question?\"\n",
    "\n",
    "results = {\"easy_q\" : \"\", \"easy_code\" : \"\", \"med_q\": \"\" , \"med_code\": \"\", \"hard_q\": \"\", \"hard_code\": \"\"}\n",
    "\n",
    "for idx, question in enumerate (query_part1):\n",
    "\n",
    "  combined_query = f\"{question}\\n{query_part2}\\n{query_part3}\"\n",
    "  query = f\"Question: {combined_query}\\nPlease provide a solution in raw text.\"\n",
    "  print (query)\n",
    "  final_response = generate_final_response(query)\n",
    "\n",
    "  if idx == 0:\n",
    "    results[\"easy_q\"] = final_response\n",
    "\n",
    "  elif idx == 1:\n",
    "    results[\"easy_code\"] = final_response\n",
    "\n",
    "  elif idx == 2:\n",
    "    results[\"med_q\"] = final_response\n",
    "\n",
    "  elif idx == 3:\n",
    "    results[\"med_code\"] = final_response\n",
    "\n",
    "  elif idx == 4:\n",
    "    results[\"hard_q\"] = final_response\n",
    " \n",
    "  elif idx == 5:\n",
    "    results[\"hard_code\"] = final_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f756416-c1f4-48d3-a057-015755faed97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12116104379602413\n",
      "0.011580071165548536\n",
      "0.07095299989507012\n",
      "0.08641731222245205\n"
     ]
    }
   ],
   "source": [
    "for i in results:\n",
    "    response_file_path =  f\"response_{i}.json\"\n",
    "    with open(response_file_path, \"w\") as f:\n",
    "        json.dump(results[i], f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f59ce5a-de48-4027-b654-15bbb2b35623",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./response_hard_code.json\n",
      "To assemble, annotate, and analyze SARS-CoV-2 genomes from sequencing data to identify and characterize different variants of the virus, I would advise the student to follow these steps:\n",
      "\n",
      "1. Obtain sequencing data: Obtain raw sequencing data from a reliable source, such as the NCBI or other public databases. Ensure that the data is of high quality and has been generated using a reliable sequencing platform.\n",
      "\n",
      "2. Quality control: Perform quality control on the raw sequencing data using tools like FastQC to assess the quality of the reads and remove any low-quality reads or adapter sequences.\n",
      "\n",
      "3. Read trimming: Trim the reads using tools like Trimmomatic or Cutadapt to remove low-quality bases and adapter sequences.\n",
      "\n",
      "4. De novo assembly: Assemble the cleaned reads using a de novo assembly tool like SPAdes or MEGAHIT to generate contigs.\n",
      "\n",
      "5. Genome annotation: Annotate the assembled contigs using tools like Prokka or RAST to identify genes and other functional elements in the SARS-CoV-2 genome.\n",
      "\n",
      "6. Variant calling: Identify variants in the SARS-CoV-2 genome using tools like FreeBayes, GATK, or SURVIVOR. These tools will generate a VCF file containing the identified variants.\n",
      "\n",
      "7. Variant filtering: Filter the identified variants using tools like VCFtools or bcftools to remove low-quality or low-frequency variants.\n",
      "\n",
      "8. Variant analysis: Analyze the filtered variants to identify and characterize different variants of the virus. This can be done using tools like SnpEff or SnpSift to predict the functional effects of the variants and tools like PhyML or BEAST to infer the evolutionary relationships between the variants.\n",
      "\n",
      "9. Visualization: Visualize the identified variants and their evolutionary relationships using tools like IGV or Jalview.\n",
      "\n",
      "Additional information needed to answer the question:\n",
      "\n",
      "- The specific sequencing platform used (e.g., Illumina, Nanopore)\n",
      "- The sequencing depth and coverage\n",
      "- The reference genome used for comparison (e.g., NC_045512.2, the SARS-CoV-2 reference genome)\n",
      "- The specific research question or hypothesis being addressed (e.g., identifying variants associated with increased transmissibility or virulence)\n",
      "\n",
      "Quality Rating: 9/10. The response provides a comprehensive and detailed workflow for assembling, annotating, and analyzing SARS-CoV-2 genomes from sequencing data. It also addresses the need for additional information to tailor the workflow to specific sequencing platforms, coverage, and research questions. However, the response could be improved by providing more specific instructions on how to choose the appropriate tools and parameters for each step, as well as by including examples of how to interpret the results of the analysis.\n",
      "./response_med_code.json\n",
      "Quality Rating: 9/10\n",
      "\n",
      "To align RNA-seq data against the human reference genome, you can follow these steps using the popular bioinformatics tool, HISAT2, and the subsequent steps for quantification and differential expression analysis using featureCounts and DESeq2, respectively.\n",
      "\n",
      "1. Install and set up the necessary software and tools:\n",
      "   - HISAT2: A fast and sensitive alignment tool for mapping RNA-seq reads to a reference genome.\n",
      "   - Samtools: A suite of programs for interacting with high-throughput sequencing data.\n",
      "   - featureCounts: A program for counting reads mapped to a reference annotation.\n",
      "   - DESeq2: A package for differential expression analysis of count data.\n",
      "\n",
      "2. Obtain the human reference genome and annotation:\n",
      "   - Download the latest human reference genome assembly (e.g., GRCh38/hg38) from the UCSC Genome Browser (ftp://hgdownload.soe.ucsc.edu/goldenPath/hg38/).\n",
      "   - Download the corresponding annotation file (e.g., hg38.chrom.sizes) from the same source.\n",
      "\n",
      "3. Prepare your RNA-seq data:\n",
      "   - Quality control and preprocessing: Use tools like FastQC and Trimmomatic to assess the quality of your raw sequencing reads and trim low-quality bases and adapters.\n",
      "   - Align the reads to the reference genome: Run HISAT2 with the reference genome and annotation files as input.\n",
      "\n",
      "4. Quantify gene expression:\n",
      "   - Use featureCounts to count the number of reads mapped to each gene in the reference annotation.\n",
      "\n",
      "5. Differential expression analysis:\n",
      "   - Import the count data into R and use the DESeq2 package to perform differential expression analysis.\n",
      "   - Identify differentially expressed genes between your experimental conditions.\n",
      "\n",
      "Additional information needed to answer the question:\n",
      "- The specific RNA-seq data and experimental conditions.\n",
      "- The version of the human reference genome and annotation used.\n",
      "- The sequencing platform (e.g., Illumina, PacBio, Oxford Nanopore) and read length.\n",
      "- The desired level of statistical significance for differential expression analysis.\n",
      "\n",
      "By following these steps and using the recommended tools, you should be able to align your RNA-seq data against the human reference genome and perform downstream analysis to identify differentially expressed genes.\n",
      "./response_easy_code.json\n",
      "Quality Rating: 9/10\n",
      "\n",
      "To provide quality metrics on fastq files, you can follow these steps:\n",
      "\n",
      "1. Install necessary software: Install FastQC, a popular tool for quality control of high throughput sequence data. You can install it using conda or pip.\n",
      "\n",
      "   ```\n",
      "   conda install -c bioconda fastqc\n",
      "   ```\n",
      "\n",
      "   or\n",
      "\n",
      "   ```\n",
      "   pip install fastqc\n",
      "   ```\n",
      "\n",
      "2. Prepare your fastq files: Ensure that your fastq files are in the correct format and are accessible to the FastQC program.\n",
      "\n",
      "3. Run FastQC on your fastq files: Use the FastQC command-line tool to generate quality metrics for your fastq files. You can run FastQC on individual files or on a directory containing multiple files.\n",
      "\n",
      "   ```\n",
      "   fastqc *.fastq.gz\n",
      "   ```\n",
      "\n",
      "   or\n",
      "\n",
      "   ```\n",
      "   fastqc /path/to/your/fastq_files/*.fastq.gz\n",
      "   ```\n",
      "\n",
      "4. Analyze the FastQC output: The FastQC program generates an HTML report for each file, containing various quality metrics such as per base sequence quality, per sequence quality scores, per base sequence content, per base GC content, and sequence duplication levels. Review the HTML reports to assess the quality of your fastq files.\n",
      "\n",
      "5. Interpret the results: Based on the quality metrics, you can determine if your fastq files are of good quality or if they require further preprocessing or trimming. For example, if the per sequence quality scores are low, you may need to trim the low-quality bases from your reads.\n",
      "\n",
      "Additional information needed to answer the question:\n",
      "\n",
      "- The specific quality metrics you want to assess (e.g., per base sequence quality, per sequence quality scores, per base sequence content, per base GC content, and sequence duplication levels).\n",
      "- The format of your fastq files (e.g., single-end or paired-end).\n",
      "- The software and tools you have access to (e.g., FastQC, Trimmomatic, or Cutadapt).\n",
      "- The specific requirements for your downstream analyses (e.g., minimum quality score, maximum sequence length, etc.).\n",
      "\n",
      "By following these steps and interpreting the FastQC results, you can provide quality metrics on your fastq files and ensure that your downstream analyses are based on high-quality data.\n",
      "./response_easy_q.json\n",
      "Quality Rating: 9/10\n",
      "\n",
      "To provide quality metrics on fastq files, I would advise the student to follow these steps:\n",
      "\n",
      "1. Understand the fastq format: Familiarize yourself with the structure of fastq files, which contain nucleotide sequences and corresponding quality scores for each base.\n",
      "\n",
      "2. Choose a quality metric: Select a suitable quality metric based on the specific requirements of your analysis. Some common quality metrics include Phred score, GC content, and sequence complexity.\n",
      "\n",
      "3. Calculate the chosen quality metric:\n",
      "   a. Phred score: Use the formula Phred score = -10 * log10(error probability) to calculate the Phred score for each base in the fastq file. The error probability can be derived from the quality score, which is a string of ASCII characters representing the quality of each base call.\n",
      "   b. GC content: Calculate the GC content by counting the number of G and C bases in the sequence and dividing by the total number of bases.\n",
      "   c. Sequence complexity: Use the Shannon entropy formula (H = -Σ(p_i * log2(p_i))) to calculate sequence complexity, where p_i is the frequency of the i-th nucleotide in the sequence.\n",
      "\n",
      "4. Analyze the quality metrics: Once you have calculated the quality metrics, analyze the results to identify any potential issues or trends. Compare the quality metrics across different samples or experiments, or investigate the relationship between quality metrics and other variables, such as sequencing depth or library preparation methods.\n",
      "\n",
      "Additional information needed to answer the question:\n",
      "- The specific requirements of the analysis and the desired quality metrics.\n",
      "- The tools and programming languages available for processing the fastq files.\n",
      "- The size and complexity of the fastq files, as this may affect the choice of tools and methods for calculating quality metrics.\n",
      "\n",
      "By following these steps and considering the additional information, the student can provide quality metrics on fastq files and ensure the accuracy and reliability of downstream analyses.\n",
      "./response_hard_q.json\n",
      "Quality Rating: 9/10\n",
      "\n",
      "To assemble, annotate, and analyze SARS-CoV-2 genomes from sequencing data to identify and characterize different variants of the virus, I would advise the student to follow these steps:\n",
      "\n",
      "1. Obtain high-quality sequencing data of SARS-CoV-2 genomes from reliable sources such as public databases like GISAID, NCBI, or EMBL-EBI. Collaborate with research institutions or hospitals if necessary.\n",
      "\n",
      "2. Perform quality control on the raw sequencing data using tools like FastQC, Trimmomatic, or Cutadapt to remove low-quality reads, adapter sequences, and other artifacts.\n",
      "\n",
      "3. Use a genome assembler like SPAdes, Velvet, or Canu to assemble the high-quality reads into contigs. These assemblers use de Bruijn graphs or overlap-layout-consensus algorithms to generate contigs from the sequencing data.\n",
      "\n",
      "4. Annotate the assembled genomes using tools like Prokka, RAST, or SPAdes' built-in annotation pipeline. These tools predict gene locations, coding sequences, and other functional elements in the genome.\n",
      "\n",
      "5. Identify and characterize different variants of the virus by comparing the assembled genomes to a high-quality reference genome. Use variant calling tools like FreeBayes, GATK, or SURVIVOR to identify single nucleotide polymorphisms (SNPs), insertions, and deletions (indels) in the genomes.\n",
      "\n",
      "6. Filter the identified variants based on quality scores, read depth, and other criteria to remove false positives and retain high-confidence variants.\n",
      "\n",
      "7. Analyze the filtered variants to identify and characterize different SARS-CoV-2 variants. Use tools like SnpEff or SnpSift to predict the functional effects of the variants and classify them into known variants or novel variants.\n",
      "\n",
      "8. Construct a phylogenetic tree using the identified variants to understand the evolutionary relationships between different SARS-CoV-2 variants. Use tools like MEGA, RAxML, or FastTree to generate the tree based on the aligned sequences.\n",
      "\n",
      "9. Investigate the functional implications of the identified variants using tools like SIFT, PolyPhen-2, or MutationTaster. These tools predict the potential impact of the variants on protein function and help identify variants that may affect viral fitness, transmissibility, or immune escape.\n",
      "\n",
      "10. Analyze epidemiological data associated with the identified variants to understand their spread and impact on public health. Use tools like Nextstrain or GISAID's EpiFlu to track the emergence and distribution of different variants.\n",
      "\n",
      "Additional information needed to answer the question:\n",
      "\n",
      "- The specific sequencing platform used (e.g., Illumina, Nanopore) to choose the appropriate tools for data processing and analysis.\n",
      "- The availability of a high-quality reference genome for comparison and variant calling.\n",
      "- Access to public databases containing SARS-CoV-2 genomes and associated metadata for epidemiological analysis.\n",
      "- Computational resources (e.g., high-performance computing clusters) to handle the large-scale data processing and analysis.\n",
      "- Expertise in bioinformatics and computational biology to perform the analyses and interpret the results accurately.\n",
      "./response_med_q.json\n",
      "Quality Rating: 9/10\n",
      "\n",
      "To align RNA-seq data against the human reference genome, you can follow these steps:\n",
      "\n",
      "1. Obtain the RNA-seq data in FASTQ format.\n",
      "2. Choose a suitable alignment tool, such as STAR, HISAT2, or TopHat2.\n",
      "3. Install the chosen alignment tool and its dependencies.\n",
      "4. Prepare a reference genome, such as the GRCh38 human genome, in a format compatible with the alignment tool (e.g., FASTA).\n",
      "5. Run the alignment tool with the RNA-seq data and reference genome as input, specifying the desired output format (e.g., SAM, BAM).\n",
      "6. Perform post-alignment processing, such as sorting and indexing the BAM file, and removing duplicates.\n",
      "7. Quantify gene expression using tools like featureCounts or HTSeq-count.\n",
      "8. Perform differential expression analysis using tools like DESeq2 or edgeR.\n",
      "\n",
      "Logic and reasoning:\n",
      "\n",
      "The alignment of RNA-seq data against a reference genome is a crucial step in analyzing gene expression. The alignment tool maps the RNA-seq reads to the reference genome, allowing for the identification of the genomic locations from which the reads originated. This information is essential for quantifying gene expression and identifying differentially expressed genes.\n",
      "\n",
      "The choice of alignment tool depends on the specific requirements of the analysis, such as the size of the RNA-seq dataset and the desired level of accuracy. STAR and HISAT2 are popular tools that provide high-throughput and accurate alignments, while TopHat2 is a legacy tool that has been largely replaced by STAR and HISAT2.\n",
      "\n",
      "Additional information needed:\n",
      "\n",
      "- The specific RNA-seq data format (e.g., FASTQ, BAM).\n",
      "- The desired alignment tool and its dependencies.\n",
      "- The reference genome version (e.g., GRCh38).\n",
      "- The desired output format (e.g., SAM, BAM).\n",
      "- The computational resources available for the alignment and post-alignment processing steps.\n",
      "- The specific research question or analysis goal to provide more targeted advice on the alignment.\n"
     ]
    }
   ],
   "source": [
    "file_pattern = \"./response*.json\"\n",
    "\n",
    "\n",
    "for file_name in glob.glob(file_pattern): #glob lists all the text files in the current working dir.\n",
    "    with open(file_name, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        print(file_name)\n",
    "        print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3301fda-ea04-41bd-827b-b592adece508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
